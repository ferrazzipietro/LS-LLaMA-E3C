{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:dotenv.main:Python-dotenv could not parse statement starting at line 4\n",
      "WARNING:dotenv.main:Python-dotenv could not parse statement starting at line 4\n",
      "WARNING:dotenv.main:Python-dotenv could not parse statement starting at line 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from peft import PeftModel, PeftConfig\n",
    "from dotenv import dotenv_values\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "\n",
    "from utils import DataPreprocessor, DatasetFormatConverter\n",
    "from utils import DataPreprocessor\n",
    "\n",
    "from src.billm import LlamaForTokenClassification\n",
    "\n",
    "WANDB_KEY = dotenv_values(\".env.base\")['WANDB_KEY']\n",
    "LLAMA_TOKEN = dotenv_values(\".env.base\")['LLAMA_TOKEN']\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "adapters = \"ferrazzipietro/LS_Llama-2-7b-hf_adapters_en.layer1_NoQuant_64_64_0.05_8_0.0002\"\n",
    "peft_config = PeftConfig.from_pretrained(adapters)\n",
    "BASE_MODEL_CHECKPOINT = peft_config.base_model_name_or_path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_CHECKPOINT,token =HF_TOKEN)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# seqeval = evaluate.load(\"seqeval\")\n",
    "DATASET_CHEKPOINT=\"ferrazzipietro/e3c-sentences\" \n",
    "TRAIN_LAYER=\"en.layer1\"\n",
    "preprocessor = DataPreprocessor(BASE_MODEL_CHECKPOINT, \n",
    "                                tokenizer)\n",
    "dataset = load_dataset(DATASET_CHEKPOINT) #download_mode=\"force_redownload\"\n",
    "dataset = dataset[TRAIN_LAYER]\n",
    "dataset = dataset.shuffle(seed=1234)  \n",
    "dataset_format_converter = DatasetFormatConverter(dataset)\n",
    "dataset_format_converter.apply()\n",
    "ds = dataset_format_converter.dataset\n",
    "label2id = dataset_format_converter.label2id\n",
    "id2label = dataset_format_converter.get_id2label()\n",
    "label_list = dataset_format_converter.get_label_list()\n",
    "dataset_format_converter.set_tokenizer(tokenizer)\n",
    "dataset_format_converter.set_max_seq_length(256)\n",
    "tokenized_ds = ds.map(lambda x: dataset_format_converter.tokenize_and_align_labels(x), batched=True)# dataset_format_converter.dataset.map(tokenize_and_align_labels, batched=True)\n",
    "train_data, val_data, test_data = preprocessor.split_layer_into_train_val_test_(tokenized_ds, TRAIN_LAYER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+FElEQVR4nO3deVhU5f//8dcAsiogKoykglsquWS4RJorisvXNC3XSs20Ph9w18pWlwqzMrOPaatLaZaltqmJe4t7krlEaq4Jahrgkghy//7wcn6N4Iajg6fn47rOFXOfe+7zPjdTvDpznxmbMcYIAADAojzcXQAAAMD1RNgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWRtgBXCQyMlK9evVydxmW98orr6hChQry9PTU7bff7rY6mjRpoiZNmrjt+DejFStWyGaz6bPPPnN3KfiXIewA+Zg2bZpsNps2bNiQ7/4mTZqoevXq13ycBQsWaOTIkdc8zr/F4sWL9fjjj6tBgwaaOnWqXnrppUv2/+qrr9S4cWOFhobK399fFSpUUOfOnbVo0SJHn4MHD2rkyJFKTk6+ztW7TmRkpP7v//7P3WVc1KxZszRhwgR3lwE4eLm7AMAqUlJS5OFxdf//sGDBAk2aNInAc4WWLVsmDw8Pvf/++/L29r5k31dffVXDhw9X48aNNWLECPn7+2vnzp1asmSJZs+erVatWkk6F3ZGjRqlyMjIq7pStHjx4ms5FUubNWuWtmzZokGDBrm7FEASYQdwGR8fH3eXcNVOnjypgIAAd5dxxQ4fPiw/P7/LBp2cnByNGTNGLVq0yDeUHD58uMA1nDp1Sv7+/petAUDhwdtYgItcuGYnOztbo0aNUuXKleXr66sSJUqoYcOGSkpKkiT16tVLkyZNkiTZbDbHdt7Jkyc1dOhQlS1bVj4+PqpSpYpeffVVGWOcjvv3339rwIABKlmypIoVK6Z77rlHf/zxh2w2m9MVo5EjR8pms2nbtm3q3r27ihcvroYNG0qSNm/erF69eqlChQry9fWV3W7Xww8/rKNHjzod6/wYv/32mx544AEFBQWpVKlSevbZZ2WM0f79+9W+fXsFBgbKbrfrtddeu6K5Ox9OKlasKB8fH0VGRuqpp55SVlaWo4/NZtPUqVN18uRJx1xNmzYt3/H+/PNPZWZmqkGDBvnuDw0NlXRuDUndunUlSb17984z7vm3Kzdu3KhGjRrJ399fTz31lGPfP9fsnF+P8umnn+rFF19UmTJl5Ovrq+bNm2vnzp15apg0aZIqVKggPz8/1atXT999953L1wF99NFHio6Olp+fn0JCQtS1a1ft37/fqc/5c9y2bZuaNm0qf39/3XLLLRo3blye8fbu3at77rlHAQEBCg0N1eDBg/Xtt9/KZrNpxYoVjvG++eYb7d271zGfkZGRTuPk5uZedo527NihTp06yW63y9fXV2XKlFHXrl2VkZHhsvnBvwdXdoBLyMjI0J9//pmnPTs7+7LPHTlypBITE/XII4+oXr16yszM1IYNG/TTTz+pRYsWevTRR3Xw4EElJSXpww8/dHquMUb33HOPli9frj59+uj222/Xt99+q+HDh+uPP/7Q66+/7ujbq1cvffrpp3rwwQd15513auXKlWrbtu1F67r//vtVuXJlvfTSS47glJSUpN9//129e/eW3W7X1q1b9c4772jr1q1as2aNUwiTpC5duqhatWoaO3asvvnmG73wwgsKCQnR22+/rWbNmunll1/WzJkzNWzYMNWtW1eNGjW65Fw98sgjmj59uu677z4NHTpUa9euVWJiorZv36558+ZJkj788EO98847Wrdund577z1J0l133ZXveKGhofLz89NXX32l/v37KyQkJN9+1apV0+jRo/Xcc8+pX79+uvvuu/OMe/ToUbVu3Vpdu3bVAw88oLCwsEuey9ixY+Xh4aFhw4YpIyND48aNU48ePbR27VpHn8mTJyshIUF33323Bg8erD179qhDhw4qXry4ypQpc8nxr9SLL76oZ599Vp07d9YjjzyiI0eO6M0331SjRo20adMmBQcHO/r+9ddfatWqlTp27KjOnTvrs88+0xNPPKEaNWqodevWks6F72bNmik1NVUDBw6U3W7XrFmztHz5cqfjPv3008rIyNCBAwccr9OiRYte1RydOXNGcXFxysrKUv/+/WW32/XHH3/o66+/Vnp6uoKCglwyR/gXMQDymDp1qpF0ye22225zek5ERITp2bOn43GtWrVM27ZtL3mc+Ph4k9+/hvPnzzeSzAsvvODUft999xmbzWZ27txpjDFm48aNRpIZNGiQU79evXoZSeb55593tD3//PNGkunWrVue4506dSpP28cff2wkmVWrVuUZo1+/fo62nJwcU6ZMGWOz2czYsWMd7X/99Zfx8/NzmpP8JCcnG0nmkUcecWofNmyYkWSWLVvmaOvZs6cJCAi45HjnPffcc0aSCQgIMK1btzYvvvii2bhxY55+69evN5LM1KlT8+xr3LixkWSmTJmS777GjRs7Hi9fvtxIMtWqVTNZWVmO9jfeeMNIMr/88osxxpisrCxTokQJU7duXZOdne3oN23aNCPJacyLiYiIuORra8+ePcbT09O8+OKLTu2//PKL8fLycmo/f44zZsxwtGVlZRm73W46derkaHvttdeMJDN//nxH299//22qVq1qJJnly5c72tu2bWsiIiLy1HWlc7Rp0yYjycyZM+eycwFcCd7GAi5h0qRJSkpKyrPVrFnzss8NDg7W1q1btWPHjqs+7oIFC+Tp6akBAwY4tQ8dOlTGGC1cuFCSHHcV/fe//3Xq179//4uO/dhjj+Vp8/Pzc/x8+vRp/fnnn7rzzjslST/99FOe/o888ojjZ09PT9WpU0fGGPXp08fRHhwcrCpVquj333+/aC3SuXOVpCFDhji1Dx06VJL0zTffXPL5FzNq1CjNmjVLtWvX1rfffqunn35a0dHRuuOOO7R9+/YrHsfHx0e9e/e+4v69e/d2Ws9z/mrR+XnYsGGDjh49qr59+8rL6/9fXO/Ro4eKFy9+xce5lLlz5yo3N1edO3fWn3/+6djsdrsqV66c52pM0aJF9cADDzgee3t7q169ek6/u0WLFumWW27RPffc42jz9fVV3759r7q+y83R+Ss33377rU6dOnXV4wMXIuwAl1CvXj3Fxsbm2a7kj9Lo0aOVnp6uW2+9VTVq1NDw4cO1efPmKzru3r17FR4ermLFijm1V6tWzbH//D89PDxUvnx5p36VKlW66NgX9pWkY8eOaeDAgQoLC5Ofn59KlSrl6JffGoly5co5PQ4KCpKvr69KliyZp/2vv/66aC3/PIcLa7bb7QoODnaca0F069ZN3333nf766y8tXrxY3bt316ZNm9SuXTudPn36isa45ZZbrmox8oVzc/61cn4ezp/Phefr5eWVZ21LQe3YsUPGGFWuXFmlSpVy2rZv355ngXaZMmXyvFVZvHhxp9/d3r17VbFixTz9LvVau5jLzVH58uU1ZMgQvffeeypZsqTi4uI0adIk1uugwFizA1wnjRo10q5du/TFF19o8eLFeu+99/T6669rypQpTldGbrR/XsU5r3Pnzvrxxx81fPhw3X777SpatKhyc3PVqlUr5ebm5unv6el5RW2S8iyovpgL/4i6UmBgoFq0aKEWLVqoSJEimj59utauXavGjRtf9rn5zdelXOs8uEJubq5sNpsWLlyYbz0XrqG50TVfyfFee+019erVy/Hvz4ABA5SYmKg1a9a4bF0T/j24sgNcRyEhIerdu7c+/vhj7d+/XzVr1nS6Q+pif+AjIiJ08OBBHT9+3Kn9119/dew//8/c3Fzt3r3bqV9+d/9czF9//aWlS5fqySef1KhRo3TvvfeqRYsWqlChwhWPcS3On8OFb/cdOnRI6enpjnN1lTp16kiSUlNTJV3fkJWf8+dz4e8oJydHe/bscckxKlasKGOMypcvn++VyfNvUV6NiIgI7dq1K08Ayu+15qo5rVGjhp555hmtWrVK3333nf744w9NmTLFJWPj34WwA1wnF962XbRoUVWqVMnpdurzn3GTnp7u1LdNmzY6e/as/ve//zm1v/7667LZbI47ZOLi4iRJb731llO/N99884rrPP9/2Rf+EbtRn4Dbpk2bfI83fvx4SbrknWUXc+rUKa1evTrffefXO1WpUkXSxX8H10udOnVUokQJvfvuu8rJyXG0z5w587Jv+V2pjh07ytPTU6NGjcrzezXG5HltXom4uDj98ccf+vLLLx1tp0+f1rvvvpunb0BAwDW95ZSZmek0N9K54OPh4eH07w9wpXgbC7hOoqKi1KRJE0VHRyskJEQbNmzQZ599poSEBEef6OhoSdKAAQMUFxcnT09Pde3aVe3atVPTpk319NNPa8+ePapVq5YWL16sL774QoMGDVLFihUdz+/UqZMmTJigo0ePOm49/+233yRd2f9hBwYGqlGjRho3bpyys7N1yy23aPHixXmuFl0vtWrVUs+ePfXOO+8oPT1djRs31rp16zR9+nR16NBBTZs2veoxT506pbvuukt33nmnWrVqpbJlyyo9PV3z58/Xd999pw4dOqh27dqSzl0FCQ4O1pQpU1SsWDEFBASofv36+a5tcgVvb2+NHDlS/fv3V7NmzdS5c2ft2bNH06ZNy3dNzMXs3LlTL7zwQp722rVrq23btnrhhRc0YsQIx23txYoV0+7duzVv3jz169dPw4YNu6q6H330Uf3vf/9Tt27dNHDgQJUuXVozZ86Ur6+vJOfXWnR0tD755BMNGTJEdevWVdGiRdWuXbsrPtayZcuUkJCg+++/X7feeqtycnL04YcfytPTU506dbqqugFJ3HoO5Of8refr16/Pd3/jxo0ve+v5Cy+8YOrVq2eCg4ONn5+fqVq1qnnxxRfNmTNnHH1ycnJM//79TalSpYzNZnO6Df348eNm8ODBJjw83BQpUsRUrlzZvPLKKyY3N9fpuCdPnjTx8fEmJCTEFC1a1HTo0MGkpKQYSU63gp+/bfzIkSN5zufAgQPm3nvvNcHBwSYoKMjcf//95uDBgxe9ff3CMS52S3h+85Sf7OxsM2rUKFO+fHlTpEgRU7ZsWTNixAhz+vTpKzpOfuO9++67pkOHDiYiIsL4+PgYf39/U7t2bfPKK6843fZsjDFffPGFiYqKMl5eXk63oV+q/ovden7h7dK7d+/O99b2iRMnOmqrV6+e+eGHH0x0dLRp1arVZc8vIiLioh+J0KdPH0e/zz//3DRs2NAEBASYgIAAU7VqVRMfH29SUlKcziO/c+zZs2ee28d///1307ZtW+Pn52dKlSplhg4daj7//HMjyaxZs8bR78SJE6Z79+4mODjYSHKMc6Vz9Pvvv5uHH37YVKxY0fj6+pqQkBDTtGlTs2TJksvODZAfmzE3cNUcgBsiOTlZtWvX1kcffaQePXq4uxxcgdzcXJUqVUodO3bM962hwmrChAkaPHiwDhw4oFtuucXd5QD5Ys0OcJP7+++/87RNmDBBHh4el/3kYrjH6dOn86ylmTFjho4dO+bSr4twtQtfa6dPn9bbb7+typUrE3RQqLFmB7jJjRs3Ths3blTTpk3l5eWlhQsXauHCherXr5/Kli3r7vKQjzVr1mjw4MG6//77VaJECf300096//33Vb16dd1///3uLu+iOnbsqHLlyun2229XRkaGPvroI/3666+aOXOmu0sDLom3sYCbXFJSkkaNGqVt27bpxIkTKleunB588EE9/fTTTp/Qi8Jjz549GjBggNatW6djx44pJCREbdq00dixYx1fUloYTZgwQe+995727Nmjs2fPKioqSo8//ri6dOni7tKASyLsAAAAS2PNDgAAsDTCDgAAsDTe0Ne5Wz4PHjyoYsWK3fCPjgcAAAVjjNHx48cVHh4uD4+LX78h7Eg6ePAgd60AAHCT2r9//yW/IJawI6lYsWKSzk1WYGCgm6sBAABXIjMzU2XLlnX8Hb8Ywo7+/3e6BAYGEnYAALjJXG4JCguUAQCApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApXm5uwAUPpFPfuPuEq7anrFt3V0CAKCQ4soOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNMIOAACwNLeGncTERNWtW1fFihVTaGioOnTooJSUFKc+TZo0kc1mc9oee+wxpz779u1T27Zt5e/vr9DQUA0fPlw5OTk38lQAAEAh5eXOg69cuVLx8fGqW7eucnJy9NRTT6lly5batm2bAgICHP369u2r0aNHOx77+/s7fj579qzatm0ru92uH3/8UampqXrooYdUpEgRvfTSSzf0fAAAQOHj1rCzaNEip8fTpk1TaGioNm7cqEaNGjna/f39Zbfb8x1j8eLF2rZtm5YsWaKwsDDdfvvtGjNmjJ544gmNHDlS3t7e1/UcAABA4Vao1uxkZGRIkkJCQpzaZ86cqZIlS6p69eoaMWKETp065di3evVq1ahRQ2FhYY62uLg4ZWZmauvWrTemcAAAUGi59crOP+Xm5mrQoEFq0KCBqlev7mjv3r27IiIiFB4ers2bN+uJJ55QSkqK5s6dK0lKS0tzCjqSHI/T0tLyPVZWVpaysrIcjzMzM119OgAAoJAoNGEnPj5eW7Zs0ffff+/U3q9fP8fPNWrUUOnSpdW8eXPt2rVLFStWLNCxEhMTNWrUqGuqFwAA3BwKxdtYCQkJ+vrrr7V8+XKVKVPmkn3r168vSdq5c6ckyW6369ChQ059zj++2DqfESNGKCMjw7Ht37//Wk8BAAAUUm4NO8YYJSQkaN68eVq2bJnKly9/2eckJydLkkqXLi1JiomJ0S+//KLDhw87+iQlJSkwMFBRUVH5juHj46PAwECnDQAAWJNb38aKj4/XrFmz9MUXX6hYsWKONTZBQUHy8/PTrl27NGvWLLVp00YlSpTQ5s2bNXjwYDVq1Eg1a9aUJLVs2VJRUVF68MEHNW7cOKWlpemZZ55RfHy8fHx83Hl6AACgEHDrlZ3JkycrIyNDTZo0UenSpR3bJ598Ikny9vbWkiVL1LJlS1WtWlVDhw5Vp06d9NVXXznG8PT01Ndffy1PT0/FxMTogQce0EMPPeT0uTwAAODfy61Xdowxl9xftmxZrVy58rLjREREaMGCBa4qCwAAWEihWKAMAABwvRB2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApbk17CQmJqpu3boqVqyYQkND1aFDB6WkpDj1OX36tOLj41WiRAkVLVpUnTp10qFDh5z67Nu3T23btpW/v79CQ0M1fPhw5eTk3MhTAQAAhZRbw87KlSsVHx+vNWvWKCkpSdnZ2WrZsqVOnjzp6DN48GB99dVXmjNnjlauXKmDBw+qY8eOjv1nz55V27ZtdebMGf3444+aPn26pk2bpueee84dpwQAAAoZmzHGuLuI844cOaLQ0FCtXLlSjRo1UkZGhkqVKqVZs2bpvvvukyT9+uuvqlatmlavXq0777xTCxcu1P/93//p4MGDCgsLkyRNmTJFTzzxhI4cOSJvb+/LHjczM1NBQUHKyMhQYGDgdT3Hm0Hkk9+4u4SrtmdsW3eXAAC4wa7073ehWrOTkZEhSQoJCZEkbdy4UdnZ2YqNjXX0qVq1qsqVK6fVq1dLklavXq0aNWo4go4kxcXFKTMzU1u3bs33OFlZWcrMzHTaAACANRWasJObm6tBgwapQYMGql69uiQpLS1N3t7eCg4OduobFhamtLQ0R59/Bp3z+8/vy09iYqKCgoIcW9myZV18NgAAoLAoNGEnPj5eW7Zs0ezZs6/7sUaMGKGMjAzHtn///ut+TAAA4B5e7i5AkhISEvT1119r1apVKlOmjKPdbrfrzJkzSk9Pd7q6c+jQIdntdkefdevWOY13/m6t830u5OPjIx8fHxefBQAAKIzcemXHGKOEhATNmzdPy5YtU/ny5Z32R0dHq0iRIlq6dKmjLSUlRfv27VNMTIwkKSYmRr/88osOHz7s6JOUlKTAwEBFRUXdmBMBAACFlluv7MTHx2vWrFn64osvVKxYMccam6CgIPn5+SkoKEh9+vTRkCFDFBISosDAQPXv318xMTG68847JUktW7ZUVFSUHnzwQY0bN05paWl65plnFB8fz9UbAADg3rAzefJkSVKTJk2c2qdOnapevXpJkl5//XV5eHioU6dOysrKUlxcnN566y1HX09PT3399df6z3/+o5iYGAUEBKhnz54aPXr0jToNAABQiBWqz9lxFz5nxxmfswMAuBnclJ+zAwAA4GqEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGle7i7A6iKf/MbdJQAA8K/GlR0AAGBphB0AAGBphB0AAGBphB0AAGBphB0AAGBpBQo7v//+u6vrAAAAuC4KFHYqVaqkpk2b6qOPPtLp06ddXRMAAIDLFCjs/PTTT6pZs6aGDBkiu92uRx99VOvWrXN1bQAAANesQGHn9ttv1xtvvKGDBw/qgw8+UGpqqho2bKjq1atr/PjxOnLkiKvrBAAAKJBrWqDs5eWljh07as6cOXr55Ze1c+dODRs2TGXLltVDDz2k1NRUV9UJAABQINcUdjZs2KD//ve/Kl26tMaPH69hw4Zp165dSkpK0sGDB9W+fXtX1QkAAFAgBfpurPHjx2vq1KlKSUlRmzZtNGPGDLVp00YeHueyU/ny5TVt2jRFRka6slYAAICrVqCwM3nyZD388MPq1auXSpcunW+f0NBQvf/++9dUHAAAwLUqUNjZsWPHZft4e3urZ8+eBRkeAADAZQq0Zmfq1KmaM2dOnvY5c+Zo+vTp11wUAACAqxQo7CQmJqpkyZJ52kNDQ/XSSy9dc1EAAACuUqCws2/fPpUvXz5Pe0REhPbt23fNRQEAALhKgdbshIaGavPmzXnutvr5559VokQJV9QFXJXIJ79xdwlXbc/Ytu4uAQD+FQp0Zadbt24aMGCAli9frrNnz+rs2bNatmyZBg4cqK5du7q6RgAAgAIr0JWdMWPGaM+ePWrevLm8vM4NkZubq4ceeog1OwAAoFApUNjx9vbWJ598ojFjxujnn3+Wn5+fatSooYiICFfXBwAAcE0KFHbOu/XWW3Xrrbe6qhYAAACXK9CanbNnz+r9999X9+7dFRsbq2bNmjltV2rVqlVq166dwsPDZbPZNH/+fKf9vXr1ks1mc9patWrl1OfYsWPq0aOHAgMDFRwcrD59+ujEiRMFOS0AAGBBBbqyM3DgQE2bNk1t27ZV9erVZbPZCnTwkydPqlatWnr44YfVsWPHfPu0atVKU6dOdTz28fFx2t+jRw+lpqYqKSlJ2dnZ6t27t/r166dZs2YVqCYAAGAtBQo7s2fP1qeffqo2bdpc08Fbt26t1q1bX7KPj4+P7HZ7vvu2b9+uRYsWaf369apTp44k6c0331SbNm306quvKjw8/JrqAwAAN78CvY3l7e2tSpUqubqWfK1YsUKhoaGqUqWK/vOf/+jo0aOOfatXr1ZwcLAj6EhSbGysPDw8tHbt2ouOmZWVpczMTKcNAABYU4HCztChQ/XGG2/IGOPqepy0atVKM2bM0NKlS/Xyyy9r5cqVat26tc6ePStJSktLU2hoqNNzvLy8FBISorS0tIuOm5iYqKCgIMdWtmzZ63oeAADAfQr0Ntb333+v5cuXa+HChbrttttUpEgRp/1z5851SXH//IDCGjVqqGbNmqpYsaJWrFih5s2bF3jcESNGaMiQIY7HmZmZBB4AACyqQGEnODhY9957r6truawKFSqoZMmS2rlzp5o3by673a7Dhw879cnJydGxY8cuus5HOrcO6MKFzgAAwJoKFHb+eXfUjXTgwAEdPXpUpUuXliTFxMQoPT1dGzduVHR0tCRp2bJlys3NVf369d1SIwAAKFwK/KGCOTk5WrFihXbt2qXu3burWLFiOnjwoAIDA1W0aNErGuPEiRPauXOn4/Hu3buVnJyskJAQhYSEaNSoUerUqZPsdrt27dqlxx9/XJUqVVJcXJwkqVq1amrVqpX69u2rKVOmKDs7WwkJCeratSt3YgEAAEkFDDt79+5Vq1attG/fPmVlZalFixYqVqyYXn75ZWVlZWnKlClXNM6GDRvUtGlTx+Pz62h69uypyZMna/PmzZo+fbrS09MVHh6uli1basyYMU5vQc2cOVMJCQlq3ry5PDw81KlTJ02cOLEgpwUAACyowB8qWKdOHf38888qUaKEo/3ee+9V3759r3icJk2aXPKOrm+//fayY4SEhPABggAA4KIKFHa+++47/fjjj/L29nZqj4yM1B9//OGSwgAAAFyhQJ+zk5ub6/ism386cOCAihUrds1FAQAAuEqBwk7Lli01YcIEx2ObzaYTJ07o+eefv+avkAAAAHClAr2N9dprrykuLk5RUVE6ffq0unfvrh07dqhkyZL6+OOPXV0jAABAgRUo7JQpU0Y///yzZs+erc2bN+vEiRPq06ePevToIT8/P1fXCAAAUGAF/pwdLy8vPfDAA66sBQAAwOUKFHZmzJhxyf0PPfRQgYoBAABwtQJ/zs4/ZWdn69SpU/L29pa/vz9hBwAAFBoFuhvrr7/+ctpOnDihlJQUNWzYkAXKAACgUClQ2MlP5cqVNXbs2DxXfQAAANzJZWFHOrdo+eDBg64cEgAA4JoUaM3Ol19+6fTYGKPU1FT973//U4MGDVxSGAAAgCsUKOx06NDB6bHNZlOpUqXUrFkzvfbaa66oCwAAwCUKFHZyc3NdXQcAAMB14dI1OwAAAIVNga7sDBky5Ir7jh8/viCHAAAAcIkChZ1NmzZp06ZNys7OVpUqVSRJv/32mzw9PXXHHXc4+tlsNtdUCQAAUEAFCjvt2rVTsWLFNH36dBUvXlzSuQ8a7N27t+6++24NHTrUpUUCAAAUVIHW7Lz22mtKTEx0BB1JKl68uF544QXuxgIAAIVKgcJOZmamjhw5kqf9yJEjOn78+DUXBQAA4CoFCjv33nuvevfurblz5+rAgQM6cOCAPv/8c/Xp00cdO3Z0dY0AAAAFVqA1O1OmTNGwYcPUvXt3ZWdnnxvIy0t9+vTRK6+84tICAQAArkWBwo6/v7/eeustvfLKK9q1a5ckqWLFigoICHBpcQAAANfqmj5UMDU1VampqapcubICAgJkjHFVXQAAAC5RoLBz9OhRNW/eXLfeeqvatGmj1NRUSVKfPn247RwAABQqBQo7gwcPVpEiRbRv3z75+/s72rt06aJFixa5rDgAAIBrVaA1O4sXL9a3336rMmXKOLVXrlxZe/fudUlhAAAArlCgKzsnT550uqJz3rFjx+Tj43PNRQEAALhKgcLO3XffrRkzZjge22w25ebmaty4cWratKnLigMAALhWBXoba9y4cWrevLk2bNigM2fO6PHHH9fWrVt17Ngx/fDDD66uEQAAoMAKdGWnevXq+u2339SwYUO1b99eJ0+eVMeOHbVp0yZVrFjR1TUCAAAU2FVf2cnOzlarVq00ZcoUPf3009ejJgAAAJe56is7RYoU0ebNm69HLQAAAC5XoLexHnjgAb3//vuurgUAAMDlCrRAOScnRx988IGWLFmi6OjoPN+JNX78eJcUBwAAcK2uKuz8/vvvioyM1JYtW3THHXdIkn777TenPjabzXXVAQAAXKOrCjuVK1dWamqqli9fLunc10NMnDhRYWFh16U4AACAa3VVa3Yu/FbzhQsX6uTJky4tCAAAwJUKtED5vAvDDwAAQGFzVWHHZrPlWZPDGh0AAFCYXdWaHWOMevXq5fiyz9OnT+uxxx7LczfW3LlzXVchAADANbiqsNOzZ0+nxw888IBLiwEAAHC1qwo7U6dOvV51AAAAXBfXtEAZAACgsCPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAAS3Nr2Fm1apXatWun8PBw2Ww2zZ8/32m/MUbPPfecSpcuLT8/P8XGxmrHjh1OfY4dO6YePXooMDBQwcHB6tOnj06cOHEDzwIAABRmbg07J0+eVK1atTRp0qR8948bN04TJ07UlClTtHbtWgUEBCguLk6nT5929OnRo4e2bt2qpKQkff3111q1apX69et3o04BAAAUcl7uPHjr1q3VunXrfPcZYzRhwgQ988wzat++vSRpxowZCgsL0/z589W1a1dt375dixYt0vr161WnTh1J0ptvvqk2bdro1VdfVXh4+A07FwAAUDgV2jU7u3fvVlpammJjYx1tQUFBql+/vlavXi1JWr16tYKDgx1BR5JiY2Pl4eGhtWvXXnTsrKwsZWZmOm0AAMCaCm3YSUtLkySFhYU5tYeFhTn2paWlKTQ01Gm/l5eXQkJCHH3yk5iYqKCgIMdWtmxZF1cPAAAKi0Ibdq6nESNGKCMjw7Ht37/f3SUBAIDrpNCGHbvdLkk6dOiQU/uhQ4cc++x2uw4fPuy0PycnR8eOHXP0yY+Pj48CAwOdNgAAYE2FNuyUL19edrtdS5cudbRlZmZq7dq1iomJkSTFxMQoPT1dGzdudPRZtmyZcnNzVb9+/RteMwAAKHzcejfWiRMntHPnTsfj3bt3Kzk5WSEhISpXrpwGDRqkF154QZUrV1b58uX17LPPKjw8XB06dJAkVatWTa1atVLfvn01ZcoUZWdnKyEhQV27duVOLAAAIMnNYWfDhg1q2rSp4/GQIUMkST179tS0adP0+OOP6+TJk+rXr5/S09PVsGFDLVq0SL6+vo7nzJw5UwkJCWrevLk8PDzUqVMnTZw48YafCwAAKJxsxhjj7iLcLTMzU0FBQcrIyHD5+p3IJ79x6Xiwjj1j27q7BAC4qV3p3+9Cu2YHAADAFQg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gp12Bk5cqRsNpvTVrVqVcf+06dPKz4+XiVKlFDRokXVqVMnHTp0yI0VAwCAwqZQhx1Juu2225SamurYvv/+e8e+wYMH66uvvtKcOXO0cuVKHTx4UB07dnRjtQAAoLDxcncBl+Pl5SW73Z6nPSMjQ++//75mzZqlZs2aSZKmTp2qatWqac2aNbrzzjtvdKkAAKAQKvRXdnbs2KHw8HBVqFBBPXr00L59+yRJGzduVHZ2tmJjYx19q1atqnLlymn16tWXHDMrK0uZmZlOGwAAsKZCHXbq16+vadOmadGiRZo8ebJ2796tu+++W8ePH1daWpq8vb0VHBzs9JywsDClpaVdctzExEQFBQU5trJly17HswAAAO5UqN/Gat26tePnmjVrqn79+oqIiNCnn34qPz+/Ao87YsQIDRkyxPE4MzOTwAMAgEUV6is7FwoODtatt96qnTt3ym6368yZM0pPT3fqc+jQoXzX+PyTj4+PAgMDnTYAAGBNN1XYOXHihHbt2qXSpUsrOjpaRYoU0dKlSx37U1JStG/fPsXExLixSgAAUJgU6rexhg0bpnbt2ikiIkIHDx7U888/L09PT3Xr1k1BQUHq06ePhgwZopCQEAUGBqp///6KiYnhTiwAAOBQqMPOgQMH1K1bNx09elSlSpVSw4YNtWbNGpUqVUqS9Prrr8vDw0OdOnVSVlaW4uLi9NZbb7m5agAAUJjYjDHG3UW4W2ZmpoKCgpSRkeHy9TuRT37j0vFgHXvGtnV3CQBwU7vSv9831ZodAACAq0XYAQAAlkbYAQAAlkbYAQAAllao78YCrOxmXbzOwmoANxuu7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEvzcncBAG4ukU9+4+4SrtqesW3dXQIAN+LKDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDS+GwuA5fF9XsC/G1d2AACApRF2AACApRF2AACApVkm7EyaNEmRkZHy9fVV/fr1tW7dOneXBAAACgFLLFD+5JNPNGTIEE2ZMkX169fXhAkTFBcXp5SUFIWGhrq7PAC4aiyqxsXw2rh6lriyM378ePXt21e9e/dWVFSUpkyZIn9/f33wwQfuLg0AALjZTX9l58yZM9q4caNGjBjhaPPw8FBsbKxWr17txsoA4N+FKw4orG76sPPnn3/q7NmzCgsLc2oPCwvTr7/+mu9zsrKylJWV5XickZEhScrMzHR5fblZp1w+JgDANa7Hf/evt5vx78r1mufz4xpjLtnvpg87BZGYmKhRo0blaS9btqwbqgEAuEvQBHdX8O9wvef5+PHjCgoKuuj+mz7slCxZUp6enjp06JBT+6FDh2S32/N9zogRIzRkyBDH49zcXB07dkwlSpSQzWaTdC4tli1bVvv371dgYOD1OwEw1zcQc31jMd83DnN94xSmuTbG6Pjx4woPD79kv5s+7Hh7eys6OlpLly5Vhw4dJJ0LL0uXLlVCQkK+z/Hx8ZGPj49TW3BwcL59AwMD3f7L/Ldgrm8c5vrGYr5vHOb6xiksc32pKzrn3fRhR5KGDBminj17qk6dOqpXr54mTJigkydPqnfv3u4uDQAAuJklwk6XLl105MgRPffcc0pLS9Ptt9+uRYsW5Vm0DAAA/n0sEXYkKSEh4aJvWxWEj4+Pnn/++Txvd8H1mOsbh7m+sZjvG4e5vnFuxrm2mcvdrwUAAHATs8QnKAMAAFwMYQcAAFgaYQcAAFgaYQcAAFgaYScfkyZNUmRkpHx9fVW/fn2tW7fO3SXdlFatWqV27dopPDxcNptN8+fPd9pvjNFzzz2n0qVLy8/PT7GxsdqxY4dTn2PHjqlHjx4KDAxUcHCw+vTpoxMnTtzAsyj8EhMTVbduXRUrVkyhoaHq0KGDUlJSnPqcPn1a8fHxKlGihIoWLapOnTrl+dTxffv2qW3btvL391doaKiGDx+unJycG3kqN4XJkyerZs2ajg9Ui4mJ0cKFCx37mevrZ+zYsbLZbBo0aJCjjfl2jZEjR8pmszltVatWdey/6efZwMns2bONt7e3+eCDD8zWrVtN3759TXBwsDl06JC7S7vpLFiwwDz99NNm7ty5RpKZN2+e0/6xY8eaoKAgM3/+fPPzzz+be+65x5QvX978/fffjj6tWrUytWrVMmvWrDHfffedqVSpkunWrdsNPpPCLS4uzkydOtVs2bLFJCcnmzZt2phy5cqZEydOOPo89thjpmzZsmbp0qVmw4YN5s477zR33XWXY39OTo6pXr26iY2NNZs2bTILFiwwJUuWNCNGjHDHKRVqX375pfnmm2/Mb7/9ZlJSUsxTTz1lihQpYrZs2WKMYa6vl3Xr1pnIyEhTs2ZNM3DgQEc78+0azz//vLnttttMamqqYzty5Ihj/80+z4SdC9SrV8/Ex8c7Hp89e9aEh4ebxMREN1Z187sw7OTm5hq73W5eeeUVR1t6errx8fExH3/8sTHGmG3bthlJZv369Y4+CxcuNDabzfzxxx83rPabzeHDh40ks3LlSmPMuXktUqSImTNnjqPP9u3bjSSzevVqY8y5YOrh4WHS0tIcfSZPnmwCAwNNVlbWjT2Bm1Dx4sXNe++9x1xfJ8ePHzeVK1c2SUlJpnHjxo6ww3y7zvPPP29q1aqV7z4rzDNvY/3DmTNntHHjRsXGxjraPDw8FBsbq9WrV7uxMuvZvXu30tLSnOY6KChI9evXd8z16tWrFRwcrDp16jj6xMbGysPDQ2vXrr3hNd8sMjIyJEkhISGSpI0bNyo7O9tprqtWrapy5co5zXWNGjWcPnU8Li5OmZmZ2rp16w2s/uZy9uxZzZ49WydPnlRMTAxzfZ3Ex8erbdu2TvMq8dp2tR07dig8PFwVKlRQjx49tG/fPknWmGfLfIKyK/z55586e/Zsnq+ZCAsL06+//uqmqqwpLS1NkvKd6/P70tLSFBoa6rTfy8tLISEhjj5wlpubq0GDBqlBgwaqXr26pHPz6O3tnefLbi+c6/x+F+f3wdkvv/yimJgYnT59WkWLFtW8efMUFRWl5ORk5trFZs+erZ9++knr16/Ps4/XtuvUr19f06ZNU5UqVZSamqpRo0bp7rvv1pYtWywxz4QdwELi4+O1ZcsWff/99+4uxdKqVKmi5ORkZWRk6LPPPlPPnj21cuVKd5dlOfv379fAgQOVlJQkX19fd5djaa1bt3b8XLNmTdWvX18RERH69NNP5efn58bKXIO3sf6hZMmS8vT0zLPC/NChQ7Lb7W6qyprOz+el5tput+vw4cNO+3NycnTs2DF+H/lISEjQ119/reXLl6tMmTKOdrvdrjNnzig9Pd2p/4Vznd/v4vw+OPP29lalSpUUHR2txMRE1apVS2+88QZz7WIbN27U4cOHdccdd8jLy0teXl5auXKlJk6cKC8vL4WFhTHf10lwcLBuvfVW7dy50xKva8LOP3h7eys6OlpLly51tOXm5mrp0qWKiYlxY2XWU758edntdqe5zszM1Nq1ax1zHRMTo/T0dG3cuNHRZ9myZcrNzVX9+vVveM2FlTFGCQkJmjdvnpYtW6by5cs77Y+OjlaRIkWc5jolJUX79u1zmutffvnFKVwmJSUpMDBQUVFRN+ZEbmK5ubnKyspirl2sefPm+uWXX5ScnOzY6tSpox49ejh+Zr6vjxMnTmjXrl0qXbq0NV7X7l4hXdjMnj3b+Pj4mGnTpplt27aZfv36meDgYKcV5rgyx48fN5s2bTKbNm0yksz48ePNpk2bzN69e40x5249Dw4ONl988YXZvHmzad++fb63nteuXdusXbvWfP/996Zy5crcen6B//znPyYoKMisWLHC6bbRU6dOOfo89thjply5cmbZsmVmw4YNJiYmxsTExDj2n79ttGXLliY5OdksWrTIlCpVqtDcNlqYPPnkk2blypVm9+7dZvPmzebJJ580NpvNLF682BjDXF9v/7wbyxjm21WGDh1qVqxYYXbv3m1++OEHExsba0qWLGkOHz5sjLn555mwk48333zTlCtXznh7e5t69eqZNWvWuLukm9Ly5cuNpDxbz549jTHnbj9/9tlnTVhYmPHx8THNmzc3KSkpTmMcPXrUdOvWzRQtWtQEBgaa3r17m+PHj7vhbAqv/OZYkpk6daqjz99//23++9//muLFixt/f39z7733mtTUVKdx9uzZY1q3bm38/PxMyZIlzdChQ012dvYNPpvC7+GHHzYRERHG29vblCpVyjRv3twRdIxhrq+3C8MO8+0aXbp0MaVLlzbe3t7mlltuMV26dDE7d+507L/Z59lmjDHuuaYEAABw/bFmBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphB0Ch06tXL3Xo0MHl46alpalFixYKCAjI8w3O18v1OhcAV46wA/xLFYY/wnv27JHNZlNycvINOd7rr7+u1NRUJScn67fffsu3z6lTpzRixAhVrFhRvr6+KlWqlBo3bqwvvvjC0ScyMlITJky4omO+8cYbmjZtmguqB1BQXu4uAABulF27dik6OlqVK1e+aJ/HHntMa9eu1ZtvvqmoqCgdPXpUP/74o44ePXpVxzp79qxsNpuCgoKutWwA14grOwDytWXLFrVu3VpFixZVWFiYHnzwQf3555+O/U2aNNGAAQP0+OOPKyQkRHa7XSNHjnQa49dff1XDhg3l6+urqKgoLVmyRDabTfPnz5ckxze0165dWzabTU2aNHF6/quvvqrSpUurRIkSio+PV3Z29iVrnjx5sipWrChvb29VqVJFH374oWNfZGSkPv/8c82YMUM2m029evXKd4wvv/xSTz31lNq0aaPIyEhFR0erf//+evjhhx3nvXfvXg0ePFg2m002m02SNG3aNAUHB+vLL79UVFSUfHx8tG/fvjxX0Fwxb2fOnFFCQoJKly4tX19fRUREKDEx8ZJzA/ybEXYA5JGenq5mzZqpdu3a2rBhgxYtWqRDhw6pc+fOTv2mT5+ugIAArV27VuPGjdPo0aOVlJQk6dyVjQ4dOsjf319r167VO++8o6efftrp+evWrZMkLVmyRKmpqZo7d65j3/Lly7Vr1y4tX75c06dP17Rp0y75dtC8efM0cOBADR06VFu2bNGjjz6q3r17a/ny5ZKk9evXq1WrVurcubNSU1P1xhtv5DuO3W7XggULdPz48Xz3z507V2XKlNHo0aOVmpqq1NRUx75Tp07p5Zdf1nvvvaetW7cqNDQ03zGudd4mTpyoL7/8Up9++qlSUlI0c+ZMRUZGXnRugH89d38TKQD36Nmzp2nfvn2++8aMGWNatmzp1LZ//34jyfHN9I0bNzYNGzZ06lO3bl3zxBNPGGOMWbhwofHy8nL6ZuSkpCQjycybN88YY8zu3buNJLNp06Y8tUVERJicnBxH2/3332+6dOly0fO56667TN++fZ3a7r//ftOmTRvH4/bt25uePXtedAxjjFm5cqUpU6aMKVKkiKlTp44ZNGiQ+f777536REREmNdff92pberUqUaSSU5OznMu/5xnV8xb//79TbNmzUxubu4lzwXAOVzZAZDHzz//rOXLl6to0aKOrWrVqpLOrXs5r2bNmk7PK126tA4fPixJSklJUdmyZWW32x3769Wrd8U13HbbbfL09Mx37Pxs375dDRo0cGpr0KCBtm/ffsXHlKRGjRrp999/19KlS3Xfffdp69atuvvuuzVmzJjLPtfb2zvPnOTnWuetV69eSk5OVpUqVTRgwAAtXrz4Sk4N+Nci7ADI48SJE2rXrp2Sk5Odth07dqhRo0aOfkWKFHF6ns1mU25urktquJ5jX8mx7777bj3xxBNavHixRo8erTFjxujMmTOXfJ6fn59jDc/lxv+nqz23O+64Q7t379aYMWP0999/q3Pnzrrvvvuu+PnAvw1hB0Aed9xxh7Zu3arIyEhVqlTJaQsICLiiMapUqaL9+/fr0KFDjrb169c79fH29pZ0bp3KtapWrZp++OEHp7YffvhBUVFR1zx2VFSUcnJydPr0aUnn6nZFzfm5knmTpMDAQHXp0kXvvvuuPvnkE33++ec6duzYdakJuNlx6znwL5aRkZHnM27O3/n07rvvqlu3bo67hnbu3KnZs2frvffec3p76WJatGihihUrqmfPnho3bpyOHz+uZ555RpIcVz9CQ0Pl5+enRYsWqUyZMvL19S3wrdrDhw9X586dVbt2bcXGxuqrr77S3LlztWTJkqsap0mTJurWrZvq1KmjEiVKaNu2bXrqqafUtGlTBQYGSjp3Z9eqVavUtWtX+fj4qGTJkgWqOT9XMm/jx49X6dKlVbt2bXl4eGjOnDmy2+037IMSgZsNV3aAf7EVK1aodu3aTtuoUaMUHh6uH374QWfPnlXLli1Vo0YNDRo0SMHBwfLwuLL/bHh6emr+/Pk6ceKE6tatq0ceecRxV5Gvr68kycvLSxMnTtTbb7+t8PBwtW/fvsDn0qFDB73xxht69dVXddttt+ntt9/W1KlT89zOfjlxcXGaPn26WrZsqWrVqql///6Ki4vTp59+6ugzevRo7dmzRxUrVlSpUqUKXHN+rmTeihUrpnHjxqlOnTqqW7eu9uzZowULFlzx7wb4t7EZY4y7iwDw7/DDDz+oYcOG2rlzpypWrOjucm4azBtwbQg7AK6befPmqWjRoqpcubJ27typgQMHqnjx4vr+++/dXVqhxrwBrsWaHQDXzfHjx/XEE09o3759KlmypGJjY/Xaa6+5u6xCj3kDXIsrOwAAwNJYzQYAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACzt/wG38pXGOIr4WQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the lengths of the strings\n",
    "lengths = [len(sentence) for sentence in train_data['sentence']]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(lengths, bins=10)\n",
    "plt.xlabel('Length of Strings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of String Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]\n",
      "Some weights of LlamaForTokenClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "/home/pferrazzi/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                )\n",
    "\n",
    "model = LlamaForTokenClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=len(label2id), id2label=id2label, label2id=label2id,\n",
    "    token = HF_TOKEN,\n",
    "    cache_dir='/data/disk1/share/pferrazzi/.cache',\n",
    "    device_map='auto',\n",
    "    quantization_config = bnb_config)\n",
    "model = PeftModel.from_pretrained(model, adapters, token = HF_TOKEN)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    print(results)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses: 100%|██████████| 6/6 [00:01<00:00,  5.33it/s]\n"
     ]
    }
   ],
   "source": [
    "class OutputGeneration():\n",
    "    def __init__(self, model, tokenizer, label2id):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2id = label2id\n",
    "    \n",
    "    def _create_prediction_list(self, model_output):\n",
    "        model_output_logits = model_output.logits.cpu().detach().float().numpy()\n",
    "        preds = np.argmax(model_output_logits, axis=2)\n",
    "        preds_list = []\n",
    "        for pred in preds:\n",
    "            preds_list.append([self.label2id[label] for label in pred])\n",
    "        return preds_list\n",
    "\n",
    "    def _generate_batch(self, input_sentences, model, tokenizer):\n",
    "        encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "        model_inputs = encodeds.to('cuda')\n",
    "        generated_ids = model(**model_inputs)\n",
    "        preds = self._create_prediction_list(generated_ids)\n",
    "        return preds\n",
    "    \n",
    "\n",
    "    def add_output_column(self, data, model, tokenizer, batch_size:int) -> None:\n",
    "        \"\"\"\n",
    "        Adds a column with the response of the model to the actual query.\n",
    "        \n",
    "        params:\n",
    "        model: the model to use to generate the response\n",
    "        tokenizer: the tokenizer to use to generate the response\n",
    "        batch_size: the batch size to use to process the examples. Increasing this makes it faster but requires more GPU. Default is 8.\n",
    "        \"\"\"\n",
    "        responses_col = []\n",
    "        total_rows = len(data)\n",
    "        indexes = [i for i in range(len(data)) if i % batch_size == 0]\n",
    "        max_index = data.shape[0]\n",
    "\n",
    "        with tqdm(total=total_rows, desc=\"generating responses\") as pbar:\n",
    "            for i, idx in enumerate(indexes[:-1]):\n",
    "                indici = list(range(idx, indexes[i+1]))\n",
    "                tmp = self._generate_batch(data.select(indici)['sentence'], model, tokenizer)\n",
    "                responses_col.extend(tmp)\n",
    "                pbar.update(batch_size)\n",
    "            indici = list(range(indexes[len(indexes[:-1])], max_index))\n",
    "            tmp = self._generate_batch(data.select(indici)['sentence'], model, tokenizer)\n",
    "            responses_col.extend(tmp)\n",
    "            pbar.update(batch_size)\n",
    "        \n",
    "        data = data.add_column('model_responses', responses_col)\n",
    "        return data\n",
    "   \n",
    "output_generation = OutputGeneration(model, tokenizer, id2label)\n",
    "tmp = output_generation.add_output_column(train_data.select(range(6)), model, tokenizer, 3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss={'logits': tensor([[[ 5.6104e-01, -3.7344e+00, -5.5957e-01],\n",
       "         [ 6.6797e-01, -1.0869e+00, -2.2871e+00],\n",
       "         [-2.3242e+00, -2.1172e+00,  1.1387e+00],\n",
       "         [ 2.2754e+00,  1.2021e+00, -1.8037e+00],\n",
       "         [ 6.5869e-01,  1.9824e+00, -2.8145e+00],\n",
       "         [ 2.4980e+00,  3.2275e-01, -3.0859e+00],\n",
       "         [ 1.8848e+00, -1.2773e+00, -3.1465e+00],\n",
       "         [ 1.1963e+00, -3.0713e-01, -9.5654e-01],\n",
       "         [ 3.3926e+00, -1.6904e+00, -1.4746e+00],\n",
       "         [ 1.3389e+00,  5.6689e-01,  1.6436e+00],\n",
       "         [ 1.0381e+00, -7.4316e-01, -5.7678e-02],\n",
       "         [ 1.0088e+00,  2.6099e-01, -8.0713e-01],\n",
       "         [ 1.1246e-02, -1.0391e+00,  4.9048e-01],\n",
       "         [-3.0054e-01, -4.4414e+00, -2.6831e-01],\n",
       "         [-8.7500e-01,  3.0000e+00, -1.0010e+00],\n",
       "         [-9.9658e-01,  2.9434e+00, -1.0312e+00],\n",
       "         [-1.0449e+00,  2.9062e+00, -1.1006e+00],\n",
       "         [-1.0439e+00,  2.9473e+00, -1.0967e+00],\n",
       "         [-1.0664e+00,  2.9902e+00, -1.0869e+00],\n",
       "         [-1.0947e+00,  3.0039e+00, -1.0439e+00],\n",
       "         [-1.1230e+00,  2.9941e+00, -1.0244e+00],\n",
       "         [-1.1230e+00,  2.9629e+00, -1.0596e+00],\n",
       "         [-1.1006e+00,  2.9355e+00, -1.1035e+00],\n",
       "         [-1.0820e+00,  2.9238e+00, -1.1416e+00],\n",
       "         [-1.1025e+00,  2.9941e+00, -1.1328e+00],\n",
       "         [-1.1318e+00,  3.0547e+00, -1.0879e+00],\n",
       "         [-1.1777e+00,  3.1250e+00, -1.0508e+00],\n",
       "         [-1.1592e+00,  3.1738e+00, -1.0088e+00],\n",
       "         [-1.1445e+00,  3.2227e+00, -9.8975e-01],\n",
       "         [-1.1055e+00,  3.2500e+00, -9.7803e-01],\n",
       "         [-1.0938e+00,  3.2051e+00, -1.0000e+00],\n",
       "         [-1.1113e+00,  3.1270e+00, -1.0332e+00],\n",
       "         [-1.1270e+00,  3.0762e+00, -1.0322e+00],\n",
       "         [-1.1348e+00,  3.1152e+00, -1.0049e+00],\n",
       "         [-1.0938e+00,  3.1445e+00, -9.7754e-01],\n",
       "         [-1.0547e+00,  3.2051e+00, -9.4531e-01],\n",
       "         [-1.0361e+00,  3.1855e+00, -9.4678e-01],\n",
       "         [-1.0674e+00,  3.1113e+00, -9.8633e-01],\n",
       "         [-1.1328e+00,  3.0332e+00, -1.0439e+00],\n",
       "         [-1.1436e+00,  3.0352e+00, -1.0439e+00],\n",
       "         [-1.1152e+00,  3.1133e+00, -9.8730e-01],\n",
       "         [-1.0400e+00,  3.2598e+00, -9.1113e-01],\n",
       "         [-9.9658e-01,  3.3438e+00, -8.7354e-01],\n",
       "         [-1.0088e+00,  3.3496e+00, -8.8184e-01],\n",
       "         [-1.0371e+00,  3.2715e+00, -9.1797e-01],\n",
       "         [-1.0879e+00,  3.1855e+00, -1.0117e+00],\n",
       "         [-1.0996e+00,  3.1445e+00, -1.0625e+00],\n",
       "         [-1.0205e+00,  3.2305e+00, -9.8877e-01],\n",
       "         [-9.4238e-01,  3.3242e+00, -9.1211e-01],\n",
       "         [-9.4141e-01,  3.3574e+00, -8.6816e-01],\n",
       "         [-9.8926e-01,  3.2930e+00, -8.9746e-01],\n",
       "         [-1.0928e+00,  3.1738e+00, -1.0156e+00],\n",
       "         [-1.1445e+00,  3.0938e+00, -1.0762e+00],\n",
       "         [-1.1045e+00,  3.1035e+00, -1.0879e+00],\n",
       "         [-9.8779e-01,  3.2227e+00, -9.9170e-01],\n",
       "         [-9.2383e-01,  3.3438e+00, -8.7256e-01],\n",
       "         [-9.2822e-01,  3.3984e+00, -7.7637e-01],\n",
       "         [-9.8877e-01,  3.3418e+00, -7.8955e-01],\n",
       "         [-1.0752e+00,  3.2031e+00, -8.6768e-01],\n",
       "         [-1.1396e+00,  3.1074e+00, -9.6094e-01],\n",
       "         [-1.1025e+00,  3.1348e+00, -9.6436e-01],\n",
       "         [-1.0498e+00,  3.1953e+00, -9.4629e-01],\n",
       "         [-1.0117e+00,  3.2559e+00, -8.7646e-01],\n",
       "         [-1.0303e+00,  3.2578e+00, -8.4326e-01],\n",
       "         [-1.0723e+00,  3.2031e+00, -8.6523e-01],\n",
       "         [-1.0986e+00,  3.1602e+00, -8.9111e-01],\n",
       "         [-1.0801e+00,  3.1445e+00, -8.9502e-01],\n",
       "         [-1.0312e+00,  3.1934e+00, -8.8184e-01],\n",
       "         [-9.9121e-01,  3.2695e+00, -8.3936e-01],\n",
       "         [-9.7461e-01,  3.3281e+00, -8.0225e-01],\n",
       "         [-1.0068e+00,  3.3242e+00, -8.0566e-01],\n",
       "         [-1.0332e+00,  3.2793e+00, -8.3301e-01],\n",
       "         [-1.0732e+00,  3.2129e+00, -8.8379e-01],\n",
       "         [-1.0996e+00,  3.1094e+00, -9.5459e-01],\n",
       "         [-1.1211e+00,  3.0098e+00, -1.0254e+00],\n",
       "         [-1.1475e+00,  2.9336e+00, -1.0576e+00],\n",
       "         [-1.1748e+00,  2.9141e+00, -1.0596e+00],\n",
       "         [-1.1826e+00,  2.9668e+00, -1.0293e+00]],\n",
       "\n",
       "        [[ 5.6104e-01, -3.7344e+00, -5.5957e-01],\n",
       "         [ 8.9990e-01,  1.0752e+00, -1.0577e-01],\n",
       "         [ 2.9199e-01,  2.1523e+00, -3.6743e-01],\n",
       "         [-2.4866e-01,  7.6709e-01, -1.3467e+00],\n",
       "         [ 8.8330e-01,  3.6963e-01, -7.8064e-02],\n",
       "         [ 2.6318e-01,  2.2637e+00, -1.0830e+00],\n",
       "         [-6.4941e-02,  2.2539e+00, -2.9004e+00],\n",
       "         [ 1.8984e+00, -4.7272e-02, -2.9980e+00],\n",
       "         [ 1.9824e+00,  2.0762e+00, -4.9609e+00],\n",
       "         [ 1.6875e+00, -1.6125e-01, -8.8379e-01],\n",
       "         [-1.3223e+00,  1.2920e+00, -1.2266e+00],\n",
       "         [ 3.1445e-01,  1.7395e-01, -5.9863e-01],\n",
       "         [ 1.7070e+00,  5.7080e-01, -9.5654e-01],\n",
       "         [-2.5787e-03,  5.8740e-01, -3.0215e+00],\n",
       "         [ 3.1465e+00, -8.7158e-01, -2.5098e+00],\n",
       "         [ 1.7832e+00,  2.3496e+00,  1.0469e+00],\n",
       "         [ 2.2598e+00, -8.9209e-01, -1.6416e+00],\n",
       "         [ 2.2695e+00, -1.4141e+00, -1.6328e+00],\n",
       "         [-4.9146e-01, -7.0361e-01,  5.6689e-01],\n",
       "         [ 1.1719e+00, -1.0049e+00,  2.0156e+00],\n",
       "         [-1.1689e+00, -1.8691e+00,  4.6021e-01],\n",
       "         [-7.4609e-01,  1.5173e-01, -1.9600e+00],\n",
       "         [ 4.1836e+00,  5.6641e-01, -3.0527e+00],\n",
       "         [ 5.4102e-01, -3.0792e-02,  3.9575e-01],\n",
       "         [ 1.7148e+00, -6.8701e-01,  1.3062e-01],\n",
       "         [ 1.8721e+00,  2.0664e+00, -1.7314e+00],\n",
       "         [ 3.3223e+00,  3.5791e-01, -3.3203e+00],\n",
       "         [ 1.2627e+00,  1.9697e+00, -3.4531e+00],\n",
       "         [ 3.9082e+00,  1.4746e-01, -2.4316e+00],\n",
       "         [ 1.8086e+00,  6.7236e-01, -2.4072e-01],\n",
       "         [-3.2788e-01,  6.6357e-01,  9.5850e-01],\n",
       "         [ 2.1816e+00,  1.0439e+00, -1.4873e+00],\n",
       "         [ 3.6602e+00,  3.5596e-01, -3.1777e+00],\n",
       "         [ 1.1973e+00,  2.5898e+00,  8.1982e-01],\n",
       "         [ 1.8926e+00, -1.5186e+00, -1.7305e+00],\n",
       "         [ 2.6973e+00, -7.2656e-01, -1.1748e+00],\n",
       "         [ 2.7637e+00,  9.4482e-01, -7.8076e-01],\n",
       "         [-7.7686e-01,  6.5967e-01, -1.4294e-01],\n",
       "         [ 9.7852e-01, -5.7471e-01,  1.9268e+00],\n",
       "         [-6.1157e-02, -8.1152e-01, -5.5127e-01],\n",
       "         [ 2.2344e+00, -1.7322e-01, -7.5781e-01],\n",
       "         [ 3.1953e+00, -1.3984e+00, -2.3633e+00],\n",
       "         [ 1.4883e+00, -1.3018e+00,  3.4424e-01],\n",
       "         [ 2.9062e+00,  5.3955e-01, -1.8916e+00],\n",
       "         [ 1.9287e+00, -1.3350e+00, -2.1133e+00],\n",
       "         [ 1.7725e+00,  2.5610e-01, -1.9141e+00],\n",
       "         [ 8.5254e-01, -2.1348e+00, -1.2920e+00],\n",
       "         [ 1.3555e+00, -1.1289e+00,  5.7666e-01],\n",
       "         [ 2.7461e+00, -9.5996e-01, -1.1787e+00],\n",
       "         [ 1.2383e+00, -4.7388e-01, -1.6807e+00],\n",
       "         [ 2.1777e-01,  5.0146e-01,  1.0869e+00],\n",
       "         [ 1.6758e+00, -2.2266e-01,  2.3301e+00],\n",
       "         [-2.0020e+00, -1.0693e+00, -1.5225e+00],\n",
       "         [ 3.6328e+00, -1.6445e+00, -1.7607e+00],\n",
       "         [ 2.9180e+00, -1.1191e+00, -1.9229e+00],\n",
       "         [ 2.4277e+00, -4.4043e-01, -2.9961e+00],\n",
       "         [ 2.2754e+00,  9.0479e-01, -1.6533e+00],\n",
       "         [-2.6270e+00, -7.8955e-01, -5.4150e-01],\n",
       "         [ 3.9185e-01,  4.6094e-01, -7.8369e-01],\n",
       "         [ 6.0730e-02,  1.0635e+00, -1.9971e+00],\n",
       "         [ 3.5195e+00, -4.0918e-01, -1.6338e+00],\n",
       "         [ 1.8057e+00,  2.2168e+00,  1.5781e+00],\n",
       "         [ 2.7109e+00,  5.0244e-01, -1.2549e+00],\n",
       "         [ 2.3457e+00, -1.1016e+00,  1.0876e-01],\n",
       "         [-1.1865e+00, -1.7148e+00,  1.8779e+00],\n",
       "         [ 1.2412e+00, -4.5044e-01,  1.8955e+00],\n",
       "         [ 1.7910e+00, -9.9869e-03,  2.6816e+00],\n",
       "         [-8.9648e-01,  1.3184e+00, -9.0527e-01],\n",
       "         [ 1.6523e+00,  8.2764e-01,  1.9324e-01],\n",
       "         [ 1.6963e+00,  9.2590e-02, -1.7002e+00],\n",
       "         [ 2.3145e-01,  1.1660e+00, -3.5645e-01],\n",
       "         [ 5.1953e-01,  3.1567e-01, -6.2988e-01],\n",
       "         [ 1.9463e+00,  6.5869e-01, -1.6572e+00],\n",
       "         [ 4.4849e-01, -1.0859e+00,  1.2732e-01],\n",
       "         [ 1.8477e+00, -3.7476e-01,  1.5498e+00],\n",
       "         [ 2.8066e+00,  6.0791e-01,  1.8721e+00],\n",
       "         [-1.4541e+00, -7.5293e-01, -4.3188e-01],\n",
       "         [ 1.5615e+00, -1.2334e+00, -1.1699e+00]]], device='cuda:1',\n",
       "       dtype=torch.float16, grad_fn=<ViewBackward0>)}, logits=tensor([[[ 5.6104e-01, -3.7344e+00, -5.5957e-01],\n",
       "         [ 6.6797e-01, -1.0869e+00, -2.2871e+00],\n",
       "         [-2.3242e+00, -2.1172e+00,  1.1387e+00],\n",
       "         [ 2.2754e+00,  1.2021e+00, -1.8037e+00],\n",
       "         [ 6.5869e-01,  1.9824e+00, -2.8145e+00],\n",
       "         [ 2.4980e+00,  3.2275e-01, -3.0859e+00],\n",
       "         [ 1.8848e+00, -1.2773e+00, -3.1465e+00],\n",
       "         [ 1.1963e+00, -3.0713e-01, -9.5654e-01],\n",
       "         [ 3.3926e+00, -1.6904e+00, -1.4746e+00],\n",
       "         [ 1.3389e+00,  5.6689e-01,  1.6436e+00],\n",
       "         [ 1.0381e+00, -7.4316e-01, -5.7678e-02],\n",
       "         [ 1.0088e+00,  2.6099e-01, -8.0713e-01],\n",
       "         [ 1.1246e-02, -1.0391e+00,  4.9048e-01],\n",
       "         [-3.0054e-01, -4.4414e+00, -2.6831e-01],\n",
       "         [-8.7500e-01,  3.0000e+00, -1.0010e+00],\n",
       "         [-9.9658e-01,  2.9434e+00, -1.0312e+00],\n",
       "         [-1.0449e+00,  2.9062e+00, -1.1006e+00],\n",
       "         [-1.0439e+00,  2.9473e+00, -1.0967e+00],\n",
       "         [-1.0664e+00,  2.9902e+00, -1.0869e+00],\n",
       "         [-1.0947e+00,  3.0039e+00, -1.0439e+00],\n",
       "         [-1.1230e+00,  2.9941e+00, -1.0244e+00],\n",
       "         [-1.1230e+00,  2.9629e+00, -1.0596e+00],\n",
       "         [-1.1006e+00,  2.9355e+00, -1.1035e+00],\n",
       "         [-1.0820e+00,  2.9238e+00, -1.1416e+00],\n",
       "         [-1.1025e+00,  2.9941e+00, -1.1328e+00],\n",
       "         [-1.1318e+00,  3.0547e+00, -1.0879e+00],\n",
       "         [-1.1777e+00,  3.1250e+00, -1.0508e+00],\n",
       "         [-1.1592e+00,  3.1738e+00, -1.0088e+00],\n",
       "         [-1.1445e+00,  3.2227e+00, -9.8975e-01],\n",
       "         [-1.1055e+00,  3.2500e+00, -9.7803e-01],\n",
       "         [-1.0938e+00,  3.2051e+00, -1.0000e+00],\n",
       "         [-1.1113e+00,  3.1270e+00, -1.0332e+00],\n",
       "         [-1.1270e+00,  3.0762e+00, -1.0322e+00],\n",
       "         [-1.1348e+00,  3.1152e+00, -1.0049e+00],\n",
       "         [-1.0938e+00,  3.1445e+00, -9.7754e-01],\n",
       "         [-1.0547e+00,  3.2051e+00, -9.4531e-01],\n",
       "         [-1.0361e+00,  3.1855e+00, -9.4678e-01],\n",
       "         [-1.0674e+00,  3.1113e+00, -9.8633e-01],\n",
       "         [-1.1328e+00,  3.0332e+00, -1.0439e+00],\n",
       "         [-1.1436e+00,  3.0352e+00, -1.0439e+00],\n",
       "         [-1.1152e+00,  3.1133e+00, -9.8730e-01],\n",
       "         [-1.0400e+00,  3.2598e+00, -9.1113e-01],\n",
       "         [-9.9658e-01,  3.3438e+00, -8.7354e-01],\n",
       "         [-1.0088e+00,  3.3496e+00, -8.8184e-01],\n",
       "         [-1.0371e+00,  3.2715e+00, -9.1797e-01],\n",
       "         [-1.0879e+00,  3.1855e+00, -1.0117e+00],\n",
       "         [-1.0996e+00,  3.1445e+00, -1.0625e+00],\n",
       "         [-1.0205e+00,  3.2305e+00, -9.8877e-01],\n",
       "         [-9.4238e-01,  3.3242e+00, -9.1211e-01],\n",
       "         [-9.4141e-01,  3.3574e+00, -8.6816e-01],\n",
       "         [-9.8926e-01,  3.2930e+00, -8.9746e-01],\n",
       "         [-1.0928e+00,  3.1738e+00, -1.0156e+00],\n",
       "         [-1.1445e+00,  3.0938e+00, -1.0762e+00],\n",
       "         [-1.1045e+00,  3.1035e+00, -1.0879e+00],\n",
       "         [-9.8779e-01,  3.2227e+00, -9.9170e-01],\n",
       "         [-9.2383e-01,  3.3438e+00, -8.7256e-01],\n",
       "         [-9.2822e-01,  3.3984e+00, -7.7637e-01],\n",
       "         [-9.8877e-01,  3.3418e+00, -7.8955e-01],\n",
       "         [-1.0752e+00,  3.2031e+00, -8.6768e-01],\n",
       "         [-1.1396e+00,  3.1074e+00, -9.6094e-01],\n",
       "         [-1.1025e+00,  3.1348e+00, -9.6436e-01],\n",
       "         [-1.0498e+00,  3.1953e+00, -9.4629e-01],\n",
       "         [-1.0117e+00,  3.2559e+00, -8.7646e-01],\n",
       "         [-1.0303e+00,  3.2578e+00, -8.4326e-01],\n",
       "         [-1.0723e+00,  3.2031e+00, -8.6523e-01],\n",
       "         [-1.0986e+00,  3.1602e+00, -8.9111e-01],\n",
       "         [-1.0801e+00,  3.1445e+00, -8.9502e-01],\n",
       "         [-1.0312e+00,  3.1934e+00, -8.8184e-01],\n",
       "         [-9.9121e-01,  3.2695e+00, -8.3936e-01],\n",
       "         [-9.7461e-01,  3.3281e+00, -8.0225e-01],\n",
       "         [-1.0068e+00,  3.3242e+00, -8.0566e-01],\n",
       "         [-1.0332e+00,  3.2793e+00, -8.3301e-01],\n",
       "         [-1.0732e+00,  3.2129e+00, -8.8379e-01],\n",
       "         [-1.0996e+00,  3.1094e+00, -9.5459e-01],\n",
       "         [-1.1211e+00,  3.0098e+00, -1.0254e+00],\n",
       "         [-1.1475e+00,  2.9336e+00, -1.0576e+00],\n",
       "         [-1.1748e+00,  2.9141e+00, -1.0596e+00],\n",
       "         [-1.1826e+00,  2.9668e+00, -1.0293e+00]],\n",
       "\n",
       "        [[ 5.6104e-01, -3.7344e+00, -5.5957e-01],\n",
       "         [ 8.9990e-01,  1.0752e+00, -1.0577e-01],\n",
       "         [ 2.9199e-01,  2.1523e+00, -3.6743e-01],\n",
       "         [-2.4866e-01,  7.6709e-01, -1.3467e+00],\n",
       "         [ 8.8330e-01,  3.6963e-01, -7.8064e-02],\n",
       "         [ 2.6318e-01,  2.2637e+00, -1.0830e+00],\n",
       "         [-6.4941e-02,  2.2539e+00, -2.9004e+00],\n",
       "         [ 1.8984e+00, -4.7272e-02, -2.9980e+00],\n",
       "         [ 1.9824e+00,  2.0762e+00, -4.9609e+00],\n",
       "         [ 1.6875e+00, -1.6125e-01, -8.8379e-01],\n",
       "         [-1.3223e+00,  1.2920e+00, -1.2266e+00],\n",
       "         [ 3.1445e-01,  1.7395e-01, -5.9863e-01],\n",
       "         [ 1.7070e+00,  5.7080e-01, -9.5654e-01],\n",
       "         [-2.5787e-03,  5.8740e-01, -3.0215e+00],\n",
       "         [ 3.1465e+00, -8.7158e-01, -2.5098e+00],\n",
       "         [ 1.7832e+00,  2.3496e+00,  1.0469e+00],\n",
       "         [ 2.2598e+00, -8.9209e-01, -1.6416e+00],\n",
       "         [ 2.2695e+00, -1.4141e+00, -1.6328e+00],\n",
       "         [-4.9146e-01, -7.0361e-01,  5.6689e-01],\n",
       "         [ 1.1719e+00, -1.0049e+00,  2.0156e+00],\n",
       "         [-1.1689e+00, -1.8691e+00,  4.6021e-01],\n",
       "         [-7.4609e-01,  1.5173e-01, -1.9600e+00],\n",
       "         [ 4.1836e+00,  5.6641e-01, -3.0527e+00],\n",
       "         [ 5.4102e-01, -3.0792e-02,  3.9575e-01],\n",
       "         [ 1.7148e+00, -6.8701e-01,  1.3062e-01],\n",
       "         [ 1.8721e+00,  2.0664e+00, -1.7314e+00],\n",
       "         [ 3.3223e+00,  3.5791e-01, -3.3203e+00],\n",
       "         [ 1.2627e+00,  1.9697e+00, -3.4531e+00],\n",
       "         [ 3.9082e+00,  1.4746e-01, -2.4316e+00],\n",
       "         [ 1.8086e+00,  6.7236e-01, -2.4072e-01],\n",
       "         [-3.2788e-01,  6.6357e-01,  9.5850e-01],\n",
       "         [ 2.1816e+00,  1.0439e+00, -1.4873e+00],\n",
       "         [ 3.6602e+00,  3.5596e-01, -3.1777e+00],\n",
       "         [ 1.1973e+00,  2.5898e+00,  8.1982e-01],\n",
       "         [ 1.8926e+00, -1.5186e+00, -1.7305e+00],\n",
       "         [ 2.6973e+00, -7.2656e-01, -1.1748e+00],\n",
       "         [ 2.7637e+00,  9.4482e-01, -7.8076e-01],\n",
       "         [-7.7686e-01,  6.5967e-01, -1.4294e-01],\n",
       "         [ 9.7852e-01, -5.7471e-01,  1.9268e+00],\n",
       "         [-6.1157e-02, -8.1152e-01, -5.5127e-01],\n",
       "         [ 2.2344e+00, -1.7322e-01, -7.5781e-01],\n",
       "         [ 3.1953e+00, -1.3984e+00, -2.3633e+00],\n",
       "         [ 1.4883e+00, -1.3018e+00,  3.4424e-01],\n",
       "         [ 2.9062e+00,  5.3955e-01, -1.8916e+00],\n",
       "         [ 1.9287e+00, -1.3350e+00, -2.1133e+00],\n",
       "         [ 1.7725e+00,  2.5610e-01, -1.9141e+00],\n",
       "         [ 8.5254e-01, -2.1348e+00, -1.2920e+00],\n",
       "         [ 1.3555e+00, -1.1289e+00,  5.7666e-01],\n",
       "         [ 2.7461e+00, -9.5996e-01, -1.1787e+00],\n",
       "         [ 1.2383e+00, -4.7388e-01, -1.6807e+00],\n",
       "         [ 2.1777e-01,  5.0146e-01,  1.0869e+00],\n",
       "         [ 1.6758e+00, -2.2266e-01,  2.3301e+00],\n",
       "         [-2.0020e+00, -1.0693e+00, -1.5225e+00],\n",
       "         [ 3.6328e+00, -1.6445e+00, -1.7607e+00],\n",
       "         [ 2.9180e+00, -1.1191e+00, -1.9229e+00],\n",
       "         [ 2.4277e+00, -4.4043e-01, -2.9961e+00],\n",
       "         [ 2.2754e+00,  9.0479e-01, -1.6533e+00],\n",
       "         [-2.6270e+00, -7.8955e-01, -5.4150e-01],\n",
       "         [ 3.9185e-01,  4.6094e-01, -7.8369e-01],\n",
       "         [ 6.0730e-02,  1.0635e+00, -1.9971e+00],\n",
       "         [ 3.5195e+00, -4.0918e-01, -1.6338e+00],\n",
       "         [ 1.8057e+00,  2.2168e+00,  1.5781e+00],\n",
       "         [ 2.7109e+00,  5.0244e-01, -1.2549e+00],\n",
       "         [ 2.3457e+00, -1.1016e+00,  1.0876e-01],\n",
       "         [-1.1865e+00, -1.7148e+00,  1.8779e+00],\n",
       "         [ 1.2412e+00, -4.5044e-01,  1.8955e+00],\n",
       "         [ 1.7910e+00, -9.9869e-03,  2.6816e+00],\n",
       "         [-8.9648e-01,  1.3184e+00, -9.0527e-01],\n",
       "         [ 1.6523e+00,  8.2764e-01,  1.9324e-01],\n",
       "         [ 1.6963e+00,  9.2590e-02, -1.7002e+00],\n",
       "         [ 2.3145e-01,  1.1660e+00, -3.5645e-01],\n",
       "         [ 5.1953e-01,  3.1567e-01, -6.2988e-01],\n",
       "         [ 1.9463e+00,  6.5869e-01, -1.6572e+00],\n",
       "         [ 4.4849e-01, -1.0859e+00,  1.2732e-01],\n",
       "         [ 1.8477e+00, -3.7476e-01,  1.5498e+00],\n",
       "         [ 2.8066e+00,  6.0791e-01,  1.8721e+00],\n",
       "         [-1.4541e+00, -7.5293e-01, -4.3188e-01],\n",
       "         [ 1.5615e+00, -1.2334e+00, -1.1699e+00]]], device='cuda:1',\n",
       "       dtype=torch.float16, grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [train_data['sentence'][0] , train_data['sentence'][5]]\n",
    "input_sentences = examples\n",
    "encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "model_inputs = encodeds.to('cuda')\n",
    "generated_ids = model(**model_inputs)\n",
    "\n",
    "#gen = OutputGeneration(model, tokenizer, id2label)\n",
    "#pl = gen._create_prediction_list(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5610, -3.7344, -0.5596],\n",
       "        [ 0.6680, -1.0869, -2.2871],\n",
       "        [-2.3242, -2.1172,  1.1387],\n",
       "        [ 2.2754,  1.2021, -1.8037],\n",
       "        [ 0.6587,  1.9824, -2.8145],\n",
       "        [ 2.4980,  0.3228, -3.0859],\n",
       "        [ 1.8848, -1.2773, -3.1465],\n",
       "        [ 1.1963, -0.3071, -0.9565],\n",
       "        [ 3.3926, -1.6904, -1.4746],\n",
       "        [ 1.3389,  0.5669,  1.6436],\n",
       "        [ 1.0381, -0.7432, -0.0577],\n",
       "        [ 1.0088,  0.2610, -0.8071],\n",
       "        [ 0.0112, -1.0391,  0.4905],\n",
       "        [-0.3005, -4.4414, -0.2683],\n",
       "        [-0.8750,  3.0000, -1.0010],\n",
       "        [-0.9966,  2.9434, -1.0312],\n",
       "        [-1.0449,  2.9062, -1.1006],\n",
       "        [-1.0439,  2.9473, -1.0967],\n",
       "        [-1.0664,  2.9902, -1.0869],\n",
       "        [-1.0947,  3.0039, -1.0439],\n",
       "        [-1.1230,  2.9941, -1.0244],\n",
       "        [-1.1230,  2.9629, -1.0596],\n",
       "        [-1.1006,  2.9355, -1.1035],\n",
       "        [-1.0820,  2.9238, -1.1416],\n",
       "        [-1.1025,  2.9941, -1.1328],\n",
       "        [-1.1318,  3.0547, -1.0879],\n",
       "        [-1.1777,  3.1250, -1.0508],\n",
       "        [-1.1592,  3.1738, -1.0088],\n",
       "        [-1.1445,  3.2227, -0.9897],\n",
       "        [-1.1055,  3.2500, -0.9780],\n",
       "        [-1.0938,  3.2051, -1.0000],\n",
       "        [-1.1113,  3.1270, -1.0332],\n",
       "        [-1.1270,  3.0762, -1.0322],\n",
       "        [-1.1348,  3.1152, -1.0049],\n",
       "        [-1.0938,  3.1445, -0.9775],\n",
       "        [-1.0547,  3.2051, -0.9453],\n",
       "        [-1.0361,  3.1855, -0.9468],\n",
       "        [-1.0674,  3.1113, -0.9863],\n",
       "        [-1.1328,  3.0332, -1.0439],\n",
       "        [-1.1436,  3.0352, -1.0439],\n",
       "        [-1.1152,  3.1133, -0.9873],\n",
       "        [-1.0400,  3.2598, -0.9111],\n",
       "        [-0.9966,  3.3438, -0.8735],\n",
       "        [-1.0088,  3.3496, -0.8818],\n",
       "        [-1.0371,  3.2715, -0.9180],\n",
       "        [-1.0879,  3.1855, -1.0117],\n",
       "        [-1.0996,  3.1445, -1.0625],\n",
       "        [-1.0205,  3.2305, -0.9888],\n",
       "        [-0.9424,  3.3242, -0.9121],\n",
       "        [-0.9414,  3.3574, -0.8682],\n",
       "        [-0.9893,  3.2930, -0.8975],\n",
       "        [-1.0928,  3.1738, -1.0156],\n",
       "        [-1.1445,  3.0938, -1.0762],\n",
       "        [-1.1045,  3.1035, -1.0879],\n",
       "        [-0.9878,  3.2227, -0.9917],\n",
       "        [-0.9238,  3.3438, -0.8726],\n",
       "        [-0.9282,  3.3984, -0.7764],\n",
       "        [-0.9888,  3.3418, -0.7896],\n",
       "        [-1.0752,  3.2031, -0.8677],\n",
       "        [-1.1396,  3.1074, -0.9609],\n",
       "        [-1.1025,  3.1348, -0.9644],\n",
       "        [-1.0498,  3.1953, -0.9463],\n",
       "        [-1.0117,  3.2559, -0.8765],\n",
       "        [-1.0303,  3.2578, -0.8433],\n",
       "        [-1.0723,  3.2031, -0.8652],\n",
       "        [-1.0986,  3.1602, -0.8911],\n",
       "        [-1.0801,  3.1445, -0.8950],\n",
       "        [-1.0312,  3.1934, -0.8818],\n",
       "        [-0.9912,  3.2695, -0.8394],\n",
       "        [-0.9746,  3.3281, -0.8022],\n",
       "        [-1.0068,  3.3242, -0.8057],\n",
       "        [-1.0332,  3.2793, -0.8330],\n",
       "        [-1.0732,  3.2129, -0.8838],\n",
       "        [-1.0996,  3.1094, -0.9546],\n",
       "        [-1.1211,  3.0098, -1.0254],\n",
       "        [-1.1475,  2.9336, -1.0576],\n",
       "        [-1.1748,  2.9141, -1.0596],\n",
       "        [-1.1826,  2.9668, -1.0293]], device='cuda:1', dtype=torch.float16,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids.logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their child acquired walking at the age of 14 months.\n",
      "n words in sentence: 10\n",
      "len_ sentence: 53\n",
      "n tokens with labels: 14\n",
      "n  created labels: 78\n",
      "Pertinent laboratory studies included a hemoglobin level of 10 g/dL, platelet count was normal, blood urea of 1,2 g/l (0,18-0,45 g/L), and a creatinine level of 68 mg/L (7-13 mg/L).\n",
      "n words in sentence: 30\n",
      "len_ sentence: 181\n",
      "n tokens with labels: 78\n",
      "n  created labels: 78\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate([0,5]):\n",
    "    print((train_data[s]['sentence']))\n",
    "    print(f\"n words in sentence: {len(train_data[s]['sentence'].split())}\")\n",
    "    print(f\"len_ sentence: {len(train_data[s]['sentence'])}\")\n",
    "    print(f\"n tokens with labels: {len(train_data[s]['labels'])}\")\n",
    "    print(f\"n  created labels: {len(generated_ids['logits'][i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'LlamaForTokenClassification' is not supported for token-classification. Supported models are ['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BioGptForTokenClassification', 'BloomForTokenClassification', 'BrosForTokenClassification', 'CamembertForTokenClassification', 'CanineForTokenClassification', 'ConvBertForTokenClassification', 'Data2VecTextForTokenClassification', 'DebertaForTokenClassification', 'DebertaV2ForTokenClassification', 'DistilBertForTokenClassification', 'ElectraForTokenClassification', 'ErnieForTokenClassification', 'ErnieMForTokenClassification', 'EsmForTokenClassification', 'FalconForTokenClassification', 'FlaubertForTokenClassification', 'FNetForTokenClassification', 'FunnelForTokenClassification', 'GPT2ForTokenClassification', 'GPT2ForTokenClassification', 'GPTBigCodeForTokenClassification', 'GPTNeoForTokenClassification', 'GPTNeoXForTokenClassification', 'IBertForTokenClassification', 'LayoutLMForTokenClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv3ForTokenClassification', 'LiltForTokenClassification', 'LongformerForTokenClassification', 'LukeForTokenClassification', 'MarkupLMForTokenClassification', 'MegaForTokenClassification', 'MegatronBertForTokenClassification', 'MobileBertForTokenClassification', 'MPNetForTokenClassification', 'MptForTokenClassification', 'MraForTokenClassification', 'MT5ForTokenClassification', 'NezhaForTokenClassification', 'NystromformerForTokenClassification', 'PhiForTokenClassification', 'QDQBertForTokenClassification', 'RemBertForTokenClassification', 'RobertaForTokenClassification', 'RobertaPreLayerNormForTokenClassification', 'RoCBertForTokenClassification', 'RoFormerForTokenClassification', 'SqueezeBertForTokenClassification', 'T5ForTokenClassification', 'UMT5ForTokenClassification', 'XLMForTokenClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaXLForTokenClassification', 'XLNetForTokenClassification', 'XmodForTokenClassification', 'YosoForTokenClassification'].\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (14) must match the existing size (4096) at non-singleton dimension 2.  Target sizes: [1, 32, 14, 14].  Tensor sizes: [1, 1, 4096, 14]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m token_classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[1;32m      5\u001b[0m                             tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, \n\u001b[1;32m      6\u001b[0m                             aggregation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtoken_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m l \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m tqdm(token_classifier(KeyDataset(train_data\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m24\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m))):\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:248\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset_mapping:\n\u001b[1;32m    246\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m offset_mapping\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1234\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1149\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1148\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1149\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:285\u001b[0m, in \u001b[0;36mTokenClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     logits \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m: logits,\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecial_tokens_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: special_tokens_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[1;32m    295\u001b[0m }\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/billm/modeling_llama.py:269\u001b[0m, in \u001b[0;36mLlamaForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 269\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    282\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/billm/modeling_llama.py:132\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    121\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    122\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    123\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m         cache_position,\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbi_attention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_bidirectional\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:671\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    667\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# In case we are not compiling, we may set `causal_mask` to None, which is required to dispatch to SDPA's Flash Attention 2 backend, rather\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# relying on the `is_causal` argument.\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    681\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (14) must match the existing size (4096) at non-singleton dimension 2.  Target sizes: [1, 32, 14, 14].  Tensor sizes: [1, 1, 4096, 14]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\", model=model, \n",
    "                            tokenizer=tokenizer, \n",
    "                            aggregation_strategy=\"simple\", batch_size=12)\n",
    "token_classifier(train_data[0]['sentence'])\n",
    "l = []\n",
    "for out in tqdm(token_classifier(KeyDataset(train_data.select(range(24)), \"sentence\"))):\n",
    "    l.append(out)\n",
    "\n",
    "tmp = train_data.select(range(24)).add_column('model_output', l)\n",
    "tmp[6]['model_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Their', 'child', 'acquired', 'walking', 'at', 'the', 'age', 'of', '14', 'months.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁Their',\n",
       " '▁child',\n",
       " '▁acquired',\n",
       " '▁walking',\n",
       " '▁at',\n",
       " '▁the',\n",
       " '▁age',\n",
       " '▁of',\n",
       " '▁',\n",
       " '1',\n",
       " '4',\n",
       " '▁months',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data[0]['tokens'])\n",
    "example = train_data[0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'LlamaForTokenClassification' is not supported for ner. Supported models are ['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BioGptForTokenClassification', 'BloomForTokenClassification', 'BrosForTokenClassification', 'CamembertForTokenClassification', 'CanineForTokenClassification', 'ConvBertForTokenClassification', 'Data2VecTextForTokenClassification', 'DebertaForTokenClassification', 'DebertaV2ForTokenClassification', 'DistilBertForTokenClassification', 'ElectraForTokenClassification', 'ErnieForTokenClassification', 'ErnieMForTokenClassification', 'EsmForTokenClassification', 'FalconForTokenClassification', 'FlaubertForTokenClassification', 'FNetForTokenClassification', 'FunnelForTokenClassification', 'GPT2ForTokenClassification', 'GPT2ForTokenClassification', 'GPTBigCodeForTokenClassification', 'GPTNeoForTokenClassification', 'GPTNeoXForTokenClassification', 'IBertForTokenClassification', 'LayoutLMForTokenClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv3ForTokenClassification', 'LiltForTokenClassification', 'LongformerForTokenClassification', 'LukeForTokenClassification', 'MarkupLMForTokenClassification', 'MegaForTokenClassification', 'MegatronBertForTokenClassification', 'MobileBertForTokenClassification', 'MPNetForTokenClassification', 'MptForTokenClassification', 'MraForTokenClassification', 'MT5ForTokenClassification', 'NezhaForTokenClassification', 'NystromformerForTokenClassification', 'PhiForTokenClassification', 'QDQBertForTokenClassification', 'RemBertForTokenClassification', 'RobertaForTokenClassification', 'RobertaPreLayerNormForTokenClassification', 'RoCBertForTokenClassification', 'RoFormerForTokenClassification', 'SqueezeBertForTokenClassification', 'T5ForTokenClassification', 'UMT5ForTokenClassification', 'XLMForTokenClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaXLForTokenClassification', 'XLNetForTokenClassification', 'XmodForTokenClassification', 'YosoForTokenClassification'].\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "24it [00:04,  4.83it/s]                      \n",
      "Flattening the indices: 100%|██████████| 24/24 [00:00<00:00, 3808.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 24,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.657,\n",
       "  'start': 7,\n",
       "  'word': 'assessment found'},\n",
       " {'end': 38,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.794,\n",
       "  'start': 32,\n",
       "  'word': 'score'},\n",
       " {'end': 44,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.6616,\n",
       "  'start': 40,\n",
       "  'word': 'GCS)'},\n",
       " {'end': 48, 'entity_group': 'B', 'score': 0.6094, 'start': 47, 'word': ''},\n",
       " {'end': 52, 'entity_group': 'I', 'score': 0.585, 'start': 51, 'word': '1'},\n",
       " {'end': 53, 'entity_group': 'B', 'score': 0.572, 'start': 52, 'word': '5'},\n",
       " {'end': 66,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.824,\n",
       "  'start': 55,\n",
       "  'word': 'eye opening'},\n",
       " {'end': 70, 'entity_group': 'B', 'score': 0.708, 'start': 69, 'word': ''},\n",
       " {'end': 72, 'entity_group': 'B', 'score': 0.4004, 'start': 71, 'word': ','},\n",
       " {'end': 88,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.628,\n",
       "  'start': 76,\n",
       "  'word': 'bal response'},\n",
       " {'end': 93, 'entity_group': 'B', 'score': 0.6816, 'start': 91, 'word': '2'},\n",
       " {'end': 100,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.623,\n",
       "  'start': 94,\n",
       "  'word': 'motor'},\n",
       " {'end': 114, 'entity_group': 'B', 'score': 0.7153, 'start': 112, 'word': '5'},\n",
       " {'end': 135,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.6855,\n",
       "  'start': 132,\n",
       "  'word': 're'},\n",
       " {'end': 148,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.829,\n",
       "  'start': 141,\n",
       "  'word': 'pupils'},\n",
       " {'end': 169,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8335,\n",
       "  'start': 157,\n",
       "  'word': 'feeling-mot'},\n",
       " {'end': 171,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.6196,\n",
       "  'start': 169,\n",
       "  'word': 'or'},\n",
       " {'end': 179,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.65,\n",
       "  'start': 171,\n",
       "  'word': 'deficit'},\n",
       " {'end': 192,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.7686,\n",
       "  'start': 187,\n",
       "  'word': 'oste'},\n",
       " {'end': 209,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.6143,\n",
       "  'start': 194,\n",
       "  'word': 'endinous reflex'},\n",
       " {'end': 211,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.6772,\n",
       "  'start': 209,\n",
       "  'word': 'es'},\n",
       " {'end': 221,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.5474,\n",
       "  'start': 212,\n",
       "  'word': 'slightly'},\n",
       " {'end': 225,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.6074,\n",
       "  'start': 221,\n",
       "  'word': 'pol'},\n",
       " {'end': 231,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.6665,\n",
       "  'start': 225,\n",
       "  'word': 'ypneic'},\n",
       " {'end': 235, 'entity_group': 'B', 'score': 0.9023, 'start': 234, 'word': ''},\n",
       " {'end': 245, 'entity_group': 'I', 'score': 0.6304, 'start': 244, 'word': '/'},\n",
       " {'end': 248,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.498,\n",
       "  'start': 245,\n",
       "  'word': 'min'},\n",
       " {'end': 251, 'entity_group': 'I', 'score': 0.346, 'start': 249, 'word': 'p'},\n",
       " {'end': 254,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8604,\n",
       "  'start': 251,\n",
       "  'word': 'uls'},\n",
       " {'end': 258, 'entity_group': 'B', 'score': 0.4985, 'start': 256, 'word': 'o'},\n",
       " {'end': 282,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8027,\n",
       "  'start': 263,\n",
       "  'word': 'saturation (SpO 2)'},\n",
       " {'end': 286, 'entity_group': 'B', 'score': 0.6333, 'start': 285, 'word': ''},\n",
       " {'end': 304,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.61,\n",
       "  'start': 292,\n",
       "  'word': 'ambient air'},\n",
       " {'end': 308, 'entity_group': 'B', 'score': 0.737, 'start': 305, 'word': 'he'},\n",
       " {'end': 318,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.867,\n",
       "  'start': 312,\n",
       "  'word': 'tachy'},\n",
       " {'end': 324,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.7837,\n",
       "  'start': 322,\n",
       "  'word': 'ic'},\n",
       " {'end': 328, 'entity_group': 'B', 'score': 0.5366, 'start': 327, 'word': ''},\n",
       " {'end': 335, 'entity_group': 'B', 'score': 0.499, 'start': 333, 'word': 'pm'},\n",
       " {'end': 352,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8047,\n",
       "  'start': 339,\n",
       "  'word': 'hypertensive'},\n",
       " {'end': 356, 'entity_group': 'B', 'score': 0.4436, 'start': 355, 'word': ''},\n",
       " {'end': 360, 'entity_group': 'I', 'score': 0.843, 'start': 359, 'word': '/'},\n",
       " {'end': 366,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.684,\n",
       "  'start': 362,\n",
       "  'word': 'mmH'},\n",
       " {'end': 367, 'entity_group': 'B', 'score': 0.419, 'start': 366, 'word': 'g'},\n",
       " {'end': 379,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.745,\n",
       "  'start': 372,\n",
       "  'word': 'capill'},\n",
       " {'end': 393,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.541,\n",
       "  'start': 388,\n",
       "  'word': 'gluc'},\n",
       " {'end': 396,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.617,\n",
       "  'start': 393,\n",
       "  'word': 'ose'},\n",
       " {'end': 400, 'entity_group': 'B', 'score': 0.7466, 'start': 399, 'word': ''},\n",
       " {'end': 402, 'entity_group': 'I', 'score': 0.541, 'start': 401, 'word': '.'},\n",
       " {'end': 407,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.7344,\n",
       "  'start': 404,\n",
       "  'word': 'g/'},\n",
       " {'end': 408, 'entity_group': 'B', 'score': 0.5786, 'start': 407, 'word': 'L'},\n",
       " {'end': 415, 'entity_group': 'B', 'score': 0.676, 'start': 413, 'word': 'g'},\n",
       " {'end': 424,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.673,\n",
       "  'start': 417,\n",
       "  'word': 'cosuria'},\n",
       " {'end': 434,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.5312,\n",
       "  'start': 431,\n",
       "  'word': 'ur'},\n",
       " {'end': 451,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.7393,\n",
       "  'start': 443,\n",
       "  'word': 'ick test'},\n",
       " {'end': 469,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8726,\n",
       "  'start': 459,\n",
       "  'word': 'ketonuria'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "token_classifier = pipeline(\"ner\", model=model, \n",
    "                            tokenizer=tokenizer, \n",
    "                            aggregation_strategy=\"simple\", batch_size=12)\n",
    "\n",
    "\n",
    "#token_classifier(train_data[0]['tokens'])\n",
    "l = []\n",
    "for out in tqdm(token_classifier(KeyDataset(train_data.select(range(24)), \"sentence\"))):\n",
    "    l.append(out)\n",
    "\n",
    "tmp = train_data.select(range(24)).add_column('model_output', l)\n",
    "tmp[6]['model_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import evaluate\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "data = load_dataset(\"csv\", data_files=\"data/evaluation/train_data_LS_Mistral-7B-v0.1_adapters_en.layer1_NoQuant_16_32_0.01_2_0.0002.csv\")\n",
    "def helper(example):\n",
    "    example['model_output'] = ast.literal_eval(example['model_output'].replace('\\n', ','))\n",
    "    return example\n",
    "data = data.map(lambda x: helper(x))\n",
    "\n",
    "def compute_metrics(logits, labels):\n",
    "    model_output_logits = logits.cpu().detach().float().numpy()    \n",
    "    predictions = np.argmax(model_output_logits, axis=1)\n",
    "    print(predictions)\n",
    "    print(type(predictions))\n",
    "    print(type(labels))\n",
    "    lista = []\n",
    "    for i in range(len(labels)):\n",
    "        print('pred: ', predictions[i], 'label: ', labels[i])\n",
    "        if labels[i] != -100:\n",
    "         lista.append(label_list[predictions[i]])\n",
    "    print('lista: ', lista)\n",
    "\n",
    "    print( [label_list[prediction] for i, prediction in enumerate(predictions) if labels[i] != -100 ] )\n",
    "\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"soverall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B', 'I']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'O',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'I',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'I',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _create_prediction_list(self, model_output):\n",
    "        model_output_logits = model_output.logits.cpu().detach().float().numpy()\n",
    "        preds = np.argmax(model_output_logits, axis=2)\n",
    "        preds_list = []\n",
    "        for pred in preds:\n",
    "            preds_list.append([self.id2label[label] for label in pred])\n",
    "        return preds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "generated_ids['logits'][0]\n",
    "print(type(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "53\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0]['labels']))\n",
    "print(len(train_data[0]['sentence']))\n",
    "print(len(generated_ids['logits'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'entities', 'original_text', 'original_id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = train_data.select(range(2))\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "53\n",
      "Their child acquired walking at the age of 14 months.\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 2, 1, 1, 0, 0, 0, 0, 0, -100, -100, 0, -100]\n",
      "[-100, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'B': 1, 'I': 2}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((examples[0]['ner_tags']))\n",
    "print(len(examples[0]['sentence']))\n",
    "print((examples[0]['sentence']))\n",
    "print((examples[0]['labels']))\n",
    "#print(len(examples['logits'][0]))\n",
    "print(labels[0])\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1520/1520 [00:00<00:00, 13777.85 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET_CHEKPOINT) #download_mode=\"force_redownload\"\n",
    "dataset = dataset[TRAIN_LAYER]\n",
    "dataset = dataset.shuffle(seed=1234)  \n",
    "dataset_format_converter = DatasetFormatConverter(dataset)\n",
    "dataset_format_converter.apply()\n",
    "ds = dataset_format_converter.dataset\n",
    "label2id = dataset_format_converter.label2id\n",
    "id2label = dataset_format_converter.get_id2label()\n",
    "label_list = dataset_format_converter.get_label_list()\n",
    "dataset = ds.map(lambda x: tokenize_and_align_labels(x), batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentece:  Their child acquired walking at the age of 14 months. \n",
      "labels:  [-100, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "sentece:  An abdominal ultrasound examination was reported as normal. \n",
      "labels:  [-100, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2]\n",
      "sentece:  Her blood pressure was 100/70 mmHg with a pulse rate of 98 beats/min, respiratory rate about 16/min and oral temperature of 37°C. \n",
      "labels:  [-100, 0, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2]\n",
      "sentece:  Emergency neck computed tomography angiography showed a contrast-enhanced abscess cavity posterior to the left retropharyngeal space, and a low-density area surrounded by an area without contrast enhancement in the posterior neck. \n",
      "labels:  [-100, 0, 0, 1, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2]\n",
      "sentece:  The mitotic rate was extremely high (19 mitosis/10 high power field), and atypical mitotic figures were also present. \n",
      "labels:  [-100, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "sentece:  Pertinent laboratory studies included a hemoglobin level of 10 g/dL, platelet count was normal, blood urea of 1,2 g/l (0,18-0,45 g/L), and a creatinine level of 68 mg/L (7-13 mg/L). \n",
      "labels:  [-100, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "sentece:  Initial assessment found Glasgow score (GCS) of 12/15 (eye opening at 5, verbal response at 2, motor response at 5), symmetrical and reactive pupils, without feeling-motor deficit, normal osteotendinous reflexes, slightly polypneic at 24 cycles/min, pulsed oxygen saturation (SpO 2) at 97% in ambient air, he was tachycardic at 115 bpm and hypertensive at 160/95 mmHg, his capillary blood glucose at 2.24 g/L, and glycosuria on the urine dipstick test without ketonuria. \n",
      "labels:  [-100, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 1, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2]\n",
      "sentece:  Lab results showed haemoglobin 10.9 g/dl, packed cell volume 35%, and positive malaria parasites. \n",
      "labels:  [-100, 0, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = preprocessor.split_layer_into_train_val_test_(dataset, TRAIN_LAYER)\n",
    "for i in range(8):\n",
    "    print('sentece: ', train_data[i]['sentence'], '\\nlabels: ', train_data[i]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[1, 1094, 534, 2920, 1475, 9271, 12423, 687, 20976, 403, 5745, 390, 4123, 28723], [1, 21127, 277, 4475, 8289, 302, 272, 16594, 28765, 6642, 369, 23096, 8894, 654, 5278, 354, 264, 9194, 302, 1581, 6752, 1716, 404, 325, 5072, 28731, 325, 5072, 28770, 28781, 28725, 8204, 28740, 28774, 28725, 8204, 28740, 28734, 28725, 8204, 28750, 28750, 304, 19966, 5278, 354, 8204, 28781, 28782, 28731, 8735, 288, 334, 7016, 9237, 3000, 678, 628, 305, 1082, 721, 806, 23096, 297, 2088, 434, 352, 28723]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2], [-100, 0, 1, 2, 2, 0, 1, 2, 2, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2]]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, words_label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        label_ids = []\n",
    "        for k, word_idx in enumerate(word_ids): \n",
    "            same_word_as_previous  = False if (word_idx != word_ids[k-1] or k==0) else True\n",
    "            if word_idx is None:\n",
    "                token_label = -100\n",
    "            elif words_label[word_idx] == label2id['O']:\n",
    "                token_label = label2id['O']\n",
    "            elif same_word_as_previous:\n",
    "                token_label = label2id['I']\n",
    "            elif not same_word_as_previous:\n",
    "                token_label = words_label[word_idx]\n",
    "            label_ids.append(token_label)\n",
    "            # if word_idx is not None:#  and k>12:\n",
    "            #     print(\"word_label: \", words_label[word_idx])\n",
    "            # print(tokenizer.decode(tokenized_inputs[i].ids[k]), \": \",word_idx,  \"\\nassigned_token_label:\",  label_ids[k], '\\n')\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "tokenize_and_align_labels(ds.select(range(2, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([2, 76, 4096])\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0 2 1 1 0 0 1 0 0 1 0\n",
      " 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  2 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  2 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 76 is out of bounds for axis 0 with size 76",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#gen = OutputGeneration(model, tokenizer, id2label)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#pl = gen._create_prediction_list(generated_ids)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(logits, labels)\u001b[0m\n\u001b[1;32m     17\u001b[0m lista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels)):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel: \u001b[39m\u001b[38;5;124m'\u001b[39m, labels[i])\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels[i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:\n\u001b[1;32m     21\u001b[0m      lista\u001b[38;5;241m.\u001b[39mappend(label_list[predictions[i]])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 76 is out of bounds for axis 0 with size 76"
     ]
    }
   ],
   "source": [
    "# examples = [train_data['sentence'][0] , train_data['sentence'][5]]\n",
    "# input_sentences = examples\n",
    "# encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "# model_inputs = encodeds.to('cuda')\n",
    "# generated_ids = model(**model_inputs)\n",
    "# model_output_logits = generated_ids.logits.cpu().detach().float().numpy()\n",
    "examples = [train_data['sentence'][0], train_data['sentence'][5]]\n",
    "input_sentences = examples\n",
    "encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "model_inputs = encodeds.to('cuda')\n",
    "generated_ids = model(**model_inputs)\n",
    "#gen = OutputGeneration(model, tokenizer, id2label)\n",
    "#pl = gen._create_prediction_list(generated_ids)\n",
    "compute_metrics(generated_ids['logits'][0],   train_data[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -100,\n",
       " -100,\n",
       " 0,\n",
       " -100]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence', 'entities', 'original_text', 'original_id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'B', 'O', 'B', 'O', 'B']\n",
      "['An', 'abdominal', 'ultrasound', 'examination', 'was', 'reported', 'as', 'normal.']\n",
      "{'input_ids': [1, 1094, 534, 2920, 1475, 9271, 12423, 687, 20976, 403, 5745, 390, 4123, 28723], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "<s> An abdominal ultrasound examination was reported as normal.\n",
      "[{'end': 8, 'entity_group': 'B', 'score': 0.648, 'start': 5, 'word': 'dom'}, {'end': 15, 'entity_group': 'B', 'score': 0.928, 'start': 12, 'word': 'ul'}, {'end': 35, 'entity_group': 'B', 'score': 0.9463, 'start': 23, 'word': 'examination'}, {'end': 48, 'entity_group': 'B', 'score': 0.8286, 'start': 39, 'word': 'reported'}, {'end': 58, 'entity_group': 'B', 'score': 0.6094, 'start': 51, 'word': 'normal'}]\n"
     ]
    }
   ],
   "source": [
    "example = tmp[1]\n",
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "print(labels)\n",
    "print(example['tokens'])\n",
    "print(tokenizer(example['sentence']))\n",
    "print(tokenizer.decode(tokenizer(example['sentence'])['input_ids']))\n",
    "print(example['model_output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
