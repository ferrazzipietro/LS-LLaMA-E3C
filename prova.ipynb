{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class DatasetFormatConverter():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.label2id = { \"O\": 0, \"B\": 1, \"I\": 2}\n",
    "\n",
    "    def get_id2label(self):\n",
    "        id2label = {v: k for k, v in self.label2id.items()}\n",
    "        return id2label\n",
    "    \n",
    "    def get_label2id(self):\n",
    "        return self.label2id\n",
    "    \n",
    "    def get_label_list(self):\n",
    "        return list(self.label2id.keys())\n",
    "    \n",
    "    def _reformat_entities_dict(self, enitities_dicts_list):\n",
    "        return [{item.get('text') : item.get('offsets')} for item in enitities_dicts_list]\n",
    "    \n",
    "    def _generate_char_based_labels_list(self, example):\n",
    "        labels = [\"O\"] * len(example[\"sentence\"])\n",
    "        for entity in example['entities']:\n",
    "            # print('entity: ', entity)\n",
    "            start = entity[\"offsets\"][0]\n",
    "            end = entity[\"offsets\"][1]\n",
    "            type = entity[\"type\"]\n",
    "            labels[start] = f\"B-{type}\"\n",
    "            for i in range(start+1, end):\n",
    "                # print('char: ', example[\"sentence\"][i])\n",
    "                labels[i] = f\"I-{type}\"\n",
    "        return labels\n",
    "    \n",
    "    def _contains_punctuation(self, word):\n",
    "        return any(char in string.punctuation for char in word)\n",
    "\n",
    "    def _is_only_punctuation(self, word):\n",
    "        return all(char in string.punctuation for char in word)\n",
    "    \n",
    "    def _remove_punctuation_and_count(self, text, punctuation_to_remove = '!\"#&\\'(),-./:;<=>?@[\\\\]^_`|'):\n",
    "        \"\"\"\n",
    "        Remove punctuation from the beginning and end of the text and count how many characters were removed.\n",
    "        \"\"\"\n",
    "        count_beginning = len(text) - len(text.lstrip(punctuation_to_remove))\n",
    "        count_end = len(text) - len(text.rstrip(punctuation_to_remove))\n",
    "        word_no_punct = text.strip(punctuation_to_remove)\n",
    "        return word_no_punct, count_beginning, count_end\n",
    "\n",
    "    def _entities_from_dict_to_labels_list(self, example, word_level=True, token_level=False, tokenizer=None):\n",
    "        if word_level and token_level:\n",
    "            raise ValueError(\"Only one of word_level and token_level can be True\")\n",
    "        if not word_level and not token_level:\n",
    "            raise ValueError(\"One of word_level and token_level must be True\")\n",
    "        if token_level and tokenizer is None:\n",
    "            raise ValueError(\"tokenizer must be provided if token_level is True\")\n",
    "        if word_level:\n",
    "            words = example[\"sentence\"].split()\n",
    "        elif token_level:\n",
    "            raise NotImplementedError\n",
    "        labels = [0] * len(words)\n",
    "        # print(example[\"entities\"])\n",
    "        chars_based_labels = self._generate_char_based_labels_list(example)\n",
    "        word_starting_position = 0\n",
    "        for i, word in enumerate(words):\n",
    "            # print(f'processing word: {word}\\n starting position: {word_starting_position}\\n encompassing labels {chars_based_labels[word_starting_position:word_starting_position+len(word)]}')\n",
    "            if self._is_only_punctuation(word):\n",
    "                word_starting_position = word_starting_position + len(word) + 1\n",
    "                continue\n",
    "            if self._contains_punctuation(word):\n",
    "                _, count_beginning, count_end = self._remove_punctuation_and_count(word)\n",
    "                # print(f'remove punctuation from word: {word}\\n count beginning: {count_beginning}\\n count end: {count_end}')\n",
    "            else:\n",
    "                count_beginning, count_end = 0, 0\n",
    "            word_length = len(word)\n",
    "            start_word = word_starting_position + count_beginning\n",
    "            end_word = word_starting_position + word_length - count_end\n",
    "            chars_labels_of_this_word = chars_based_labels[start_word : end_word]\n",
    "            if (chars_labels_of_this_word[0].startswith(\"B-\") or chars_labels_of_this_word[0].startswith(\"I-\")) \\\n",
    "                and all([label.startswith(\"I-\") for label in chars_labels_of_this_word[1:]]):\n",
    "                labels[i] = self.label2id.get(chars_labels_of_this_word[0][0], -1)\n",
    "            word_starting_position = word_starting_position + word_length + 1\n",
    "        # print(labels)\n",
    "        example['words'] = words\n",
    "        example['word_level_labels'] = labels\n",
    "        return example\n",
    "\n",
    "    def apply(self):\n",
    "        self.dataset = self.dataset.map(self._entities_from_dict_to_labels_list)\n",
    "        self.dataset = self.dataset.rename_column(\"word_level_labels\", \"ner_tags\")\n",
    "        self.dataset = self.dataset.rename_column(\"words\", \"tokens\")\n",
    "\n",
    "    def set_tokenizer(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def set_max_seq_length(self, max_seq_length):\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    # def tokenize_and_align_labels(self, examples): COPIED FROM HF, WRONG\n",
    "    #     \"\"\"\n",
    "    #     \"\"\"\n",
    "    #     tokenized_inputs = self.tokenizer(examples[\"tokens\"], is_split_into_words=True, padding='longest', max_length=self.max_seq_length, truncation=True)\n",
    "\n",
    "    #     labels = []\n",
    "    #     for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "    #         word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "    #         previous_word_idx = None\n",
    "    #         label_ids = []\n",
    "    #         for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "    #             if word_idx is None:\n",
    "    #                 label_ids.append(-100)\n",
    "    #             elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "    #                 label_ids.append(label[word_idx])\n",
    "    #             else:\n",
    "    #                 label_ids.append(-100)\n",
    "    #             previous_word_idx = word_idx\n",
    "    #         labels.append(label_ids)\n",
    "    #     tokenized_inputs[\"labels\"] = labels\n",
    "    #     return tokenized_inputs\n",
    "\n",
    "    def tokenize_and_align_labels(self, examples):\n",
    "        tokenized_inputs = self.tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "        labels = []\n",
    "        for i, words_label in enumerate(examples[f\"ner_tags\"]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "            label_ids = []\n",
    "            for k, word_idx in enumerate(word_ids): \n",
    "                same_word_as_previous  = False if (word_idx != word_ids[k-1] or k==0) else True\n",
    "                if word_idx is None:\n",
    "                    token_label = -100\n",
    "                elif words_label[word_idx] == self.label2id['O']:\n",
    "                    token_label = self.label2id['O']\n",
    "                elif same_word_as_previous:\n",
    "                    token_label = self.label2id['I']\n",
    "                elif not same_word_as_previous:\n",
    "                    token_label = words_label[word_idx]\n",
    "                label_ids.append(token_label)\n",
    "                # if word_idx is not None:#  and k>12:\n",
    "                #     print(\"word_label: \", words_label[word_idx])\n",
    "                # print(tokenizer.decode(tokenized_inputs[i].ids[k]), \": \",word_idx,  \"\\nassigned_token_label:\",  label_ids[k], '\\n')\n",
    "            labels.append(label_ids)\n",
    "\n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "        return tokenized_inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from peft import PeftModel, PeftConfig\n",
    "from dotenv import dotenv_values\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# from utils import DataPreprocessor, DatasetFormatConverter\n",
    "from src.billm.modeling_mistral import MistralForTokenClassification\n",
    "\n",
    "WANDB_KEY = dotenv_values(\".env.base\")['WANDB_KEY']\n",
    "LLAMA_TOKEN = dotenv_values(\".env.base\")['LLAMA_TOKEN']\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "adapters = \"ferrazzipietro/LS_Mistral-7B-v0.1_adapters_en.layer1_NoQuant_16_32_0.01_2_0.0002\"\n",
    "peft_config = PeftConfig.from_pretrained(adapters)\n",
    "BASE_MODEL_CHECKPOINT = peft_config.base_model_name_or_path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_CHECKPOINT,token =HF_TOKEN)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# seqeval = evaluate.load(\"seqeval\")\n",
    "DATASET_CHEKPOINT=\"ferrazzipietro/e3c-sentences\" \n",
    "TRAIN_LAYER=\"en.layer1\"\n",
    "preprocessor = DataPreprocessor(BASE_MODEL_CHECKPOINT, \n",
    "                                tokenizer)\n",
    "dataset = load_dataset(DATASET_CHEKPOINT) #download_mode=\"force_redownload\"\n",
    "dataset = dataset[TRAIN_LAYER]\n",
    "dataset = dataset.shuffle(seed=1234)  \n",
    "dataset_format_converter = DatasetFormatConverter(dataset)\n",
    "dataset_format_converter.apply()\n",
    "ds = dataset_format_converter.dataset\n",
    "label2id = dataset_format_converter.label2id\n",
    "id2label = dataset_format_converter.get_id2label()\n",
    "label_list = dataset_format_converter.get_label_list()\n",
    "dataset_format_converter.set_tokenizer(tokenizer)\n",
    "dataset_format_converter.set_max_seq_length(256)\n",
    "tokenized_ds = ds.map(lambda x: dataset_format_converter.tokenize_and_align_labels(x), batched=True)# dataset_format_converter.dataset.map(tokenize_and_align_labels, batched=True)\n",
    "train_data, val_data, test_data = preprocessor.split_layer_into_train_val_test_(tokenized_ds, TRAIN_LAYER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(lambda x: dataset_format_converter.tokenize_and_align_labels(x), batched=True)# dataset_format_converter.dataset.map(tokenize_and_align_labels, batched=True)\n",
    "train_data, val_data, test_data = preprocessor.split_layer_into_train_val_test_(tokenized_ds, TRAIN_LAYER)\n",
    "train_data[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1520 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1520/1520 [00:00<00:00, 12776.36 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-100, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, words_label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        label_ids = []\n",
    "        for k, word_idx in enumerate(word_ids): \n",
    "            same_word_as_previous  = False if (word_idx != word_ids[k-1] or k==0) else True\n",
    "            if word_idx is None:\n",
    "                token_label = -100\n",
    "            elif words_label[word_idx] == label2id['O']:\n",
    "                token_label = label2id['O']\n",
    "            elif same_word_as_previous:\n",
    "                token_label = label2id['I']\n",
    "            elif not same_word_as_previous:\n",
    "                token_label = words_label[word_idx]\n",
    "            label_ids.append(token_label)\n",
    "            # if word_idx is not None:#  and k>12:\n",
    "            #     print(\"word_label: \", words_label[word_idx])\n",
    "            # print(tokenizer.decode(tokenized_inputs[i].ids[k]), \": \",word_idx,  \"\\nassigned_token_label:\",  label_ids[k], '\\n')\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "tokenized_ds = ds.map(lambda x: tokenize_and_align_labels(x), batched=True)# dataset_format_converter.dataset.map(tokenize_and_align_labels, batched=True)\n",
    "train_data, val_data, test_data = preprocessor.split_layer_into_train_val_test_(tokenized_ds, TRAIN_LAYER)\n",
    "train_data[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:BiLLM:Here is the Bi-MistralModel! BiLLM_START_INDEX=0\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]\n",
      "Some weights of MistralForTokenClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-v0.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "/home/pferrazzi/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                )\n",
    "\n",
    "model = MistralForTokenClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=len(label2id), id2label=id2label, label2id=label2id,\n",
    "    token = HF_TOKEN,\n",
    "    cache_dir='/data/disk1/share/pferrazzi/.cache',\n",
    "    device_map='auto',\n",
    "    quantization_config = bnb_config)\n",
    "model = PeftModel.from_pretrained(model, adapters, token = HF_TOKEN)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([3, 48, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses:  50%|█████     | 3/6 [00:00<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([3, 76, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses: 100%|██████████| 6/6 [00:01<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len= 6 [['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'I', 'B', 'B', 'O', 'B', 'B', 'O', 'O', 'B', 'B', 'O', 'O'], ['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'O', 'B', 'O', 'B', 'O'], ['I', 'O', 'O', 'B', 'B', 'B', 'B', 'I', 'B', 'B', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'O', 'I', 'I', 'B', 'O', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'O', 'O'], ['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'I', 'B', 'O', 'B', 'I', 'B', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'O', 'I', 'B', 'B', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'B', 'B', 'O'], ['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'O', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'O'], ['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'O', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'O', 'I', 'I', 'B', 'B', 'O', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class OutputGeneration():\n",
    "    def __init__(self, model, tokenizer, id2label):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.id2label = label2id\n",
    "    \n",
    "    def _create_prediction_list(self, model_output):\n",
    "        model_output_logits = model_output.logits.cpu().detach().float().numpy()\n",
    "        preds = np.argmax(model_output_logits, axis=2)\n",
    "        preds_list = []\n",
    "        for pred in preds:\n",
    "            preds_list.append([self.label2id[label] for label in pred])\n",
    "        return preds_list\n",
    "\n",
    "    def _generate_batch(self, input_sentences, model, tokenizer):\n",
    "        encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "        model_inputs = encodeds.to('cuda')\n",
    "        generated_ids = model(**model_inputs)\n",
    "        preds = self._create_prediction_list(generated_ids)\n",
    "        return preds\n",
    "    \n",
    "\n",
    "    def add_output_column(self, data, model, tokenizer, batch_size:int) -> None:\n",
    "        \"\"\"\n",
    "        Adds a column with the response of the model to the actual query.\n",
    "        \n",
    "        params:\n",
    "        model: the model to use to generate the response\n",
    "        tokenizer: the tokenizer to use to generate the response\n",
    "        batch_size: the batch size to use to process the examples. Increasing this makes it faster but requires more GPU. Default is 8.\n",
    "        \"\"\"\n",
    "        responses_col = []\n",
    "        total_rows = len(data)\n",
    "        indexes = [i for i in range(len(data)) if i % batch_size == 0]\n",
    "        max_index = data.shape[0]\n",
    "\n",
    "        with tqdm(total=total_rows, desc=\"generating responses\") as pbar:\n",
    "            for i, idx in enumerate(indexes[:-1]):\n",
    "                indici = list(range(idx, indexes[i+1]))\n",
    "                tmp = self._generate_batch(data.select(indici)['sentence'], model, tokenizer)\n",
    "                responses_col.extend(tmp)\n",
    "                pbar.update(batch_size)\n",
    "            indici = list(range(indexes[len(indexes[:-1])], max_index))\n",
    "            tmp = self._generate_batch(data.select(indici)['sentence'], model, tokenizer)\n",
    "            responses_col.extend(tmp)\n",
    "            pbar.update(batch_size)\n",
    "        \n",
    "        print('len=', len(responses_col), responses_col)\n",
    "        data = data.add_column('model_responses', responses_col)\n",
    "        return data\n",
    "   \n",
    "output_generation = OutputGeneration(model, tokenizer, id2label)\n",
    "tmp = output_generation.add_output_column(train_data.select(range(6)), model, tokenizer, 3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([2, 76, 4096])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OutputGeneration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m encodeds\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n\u001b[0;32m----> 6\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[43mOutputGeneration\u001b[49m(model, tokenizer, id2label)\n\u001b[1;32m      7\u001b[0m pl \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39m_create_prediction_list(generated_ids)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OutputGeneration' is not defined"
     ]
    }
   ],
   "source": [
    "examples = [train_data['sentence'][0], train_data['sentence'][5]]\n",
    "input_sentences = examples\n",
    "encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "model_inputs = encodeds.to('cuda')\n",
    "generated_ids = model(**model_inputs)\n",
    "gen = OutputGeneration(model, tokenizer, id2label)\n",
    "pl = gen._create_prediction_list(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: Their child acquired walking at the age of 14 months.\n",
      "predicted labels: ['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'I', 'O', 'I', 'B', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'O', 'O', 'O']\n",
      "tokens Encoding(num_tokens=76, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "n processed tokens 76\n",
      "n tokens 13\n",
      "mask:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "sentence: Pertinent laboratory studies included a hemoglobin level of 10 g/dL, platelet count was normal, blood urea of 1,2 g/l (0,18-0,45 g/L), and a creatinine level of 68 mg/L (7-13 mg/L).\n",
      "predicted labels: ['O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'I', 'O', 'B', 'O', 'O', 'O', 'B', 'B', 'O', 'B', 'B', 'O', 'O', 'I', 'O', 'O', 'B', 'B', 'O', 'B', 'O', 'B', 'O', 'B', 'B', 'O', 'I', 'I', 'B', 'B', 'O', 'I', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'B', 'B', 'O', 'B', 'B', 'I', 'I', 'O', 'B', 'O', 'B', 'I', 'B', 'B', 'I', 'B', 'B', 'O', 'O']\n",
      "tokens Encoding(num_tokens=76, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "n processed tokens 76\n",
      "n tokens 75\n",
      "mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(examples)):\n",
    "    print(\"sentence:\", examples[i])\n",
    "    print(\"predicted labels:\", pl[i])\n",
    "    print(\"tokens\", encodeds[i])\n",
    "    print(\"n processed tokens\", len(encodeds[i]))\n",
    "    print(\"n tokens\", len(tokenizer.tokenize(examples[i])))\n",
    "    print(\"mask: \", encodeds[i].attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "48\n",
      "8\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(encodeds[1]))\n",
    "print(len(tmp[1]['model_responses']))\n",
    "print(len(tmp[1]['original_id']))\n",
    "print(len(tokenizer(tmp[1]['sentence'], return_tensors='pt')['input_ids'].squeeze(0).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0 1 0 0 1 1 0 0 0 1 0 0 1 2 2 2 0 0 0 1 1 0 0 0 0 0 0 0 1 2 2]'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ner_tags'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'MistralForTokenClassification' is not supported for token-classification. Supported models are ['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BioGptForTokenClassification', 'BloomForTokenClassification', 'BrosForTokenClassification', 'CamembertForTokenClassification', 'CanineForTokenClassification', 'ConvBertForTokenClassification', 'Data2VecTextForTokenClassification', 'DebertaForTokenClassification', 'DebertaV2ForTokenClassification', 'DistilBertForTokenClassification', 'ElectraForTokenClassification', 'ErnieForTokenClassification', 'ErnieMForTokenClassification', 'EsmForTokenClassification', 'FalconForTokenClassification', 'FlaubertForTokenClassification', 'FNetForTokenClassification', 'FunnelForTokenClassification', 'GPT2ForTokenClassification', 'GPT2ForTokenClassification', 'GPTBigCodeForTokenClassification', 'GPTNeoForTokenClassification', 'GPTNeoXForTokenClassification', 'IBertForTokenClassification', 'LayoutLMForTokenClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv3ForTokenClassification', 'LiltForTokenClassification', 'LongformerForTokenClassification', 'LukeForTokenClassification', 'MarkupLMForTokenClassification', 'MegaForTokenClassification', 'MegatronBertForTokenClassification', 'MobileBertForTokenClassification', 'MPNetForTokenClassification', 'MptForTokenClassification', 'MraForTokenClassification', 'MT5ForTokenClassification', 'NezhaForTokenClassification', 'NystromformerForTokenClassification', 'PhiForTokenClassification', 'QDQBertForTokenClassification', 'RemBertForTokenClassification', 'RobertaForTokenClassification', 'RobertaPreLayerNormForTokenClassification', 'RoCBertForTokenClassification', 'RoFormerForTokenClassification', 'SqueezeBertForTokenClassification', 'T5ForTokenClassification', 'UMT5ForTokenClassification', 'XLMForTokenClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaXLForTokenClassification', 'XLNetForTokenClassification', 'XmodForTokenClassification', 'YosoForTokenClassification'].\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([12, 166, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:04<00:04,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([12, 43, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.52it/s]                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 32,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.615,\n",
       "  'start': 18,\n",
       "  'word': 'found Glasgow'},\n",
       " {'end': 41, 'entity_group': 'I', 'score': 0.9956, 'start': 38, 'word': '(G'},\n",
       " {'end': 43, 'entity_group': 'B', 'score': 0.5854, 'start': 41, 'word': 'CS'},\n",
       " {'end': 48, 'entity_group': 'B', 'score': 0.768, 'start': 44, 'word': 'of '},\n",
       " {'end': 51, 'entity_group': 'B', 'score': 0.99, 'start': 50, 'word': '/'},\n",
       " {'end': 55, 'entity_group': 'I', 'score': 0.983, 'start': 53, 'word': '('},\n",
       " {'end': 58, 'entity_group': 'B', 'score': 0.961, 'start': 55, 'word': 'eye'},\n",
       " {'end': 69,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.724,\n",
       "  'start': 58,\n",
       "  'word': 'opening at'},\n",
       " {'end': 71, 'entity_group': 'I', 'score': 0.995, 'start': 70, 'word': '5'},\n",
       " {'end': 76,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.907,\n",
       "  'start': 71,\n",
       "  'word': ', ver'},\n",
       " {'end': 91,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.803,\n",
       "  'start': 76,\n",
       "  'word': 'bal response at'},\n",
       " {'end': 93, 'entity_group': 'I', 'score': 0.818, 'start': 92, 'word': '2'},\n",
       " {'end': 112,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.9326,\n",
       "  'start': 93,\n",
       "  'word': ', motor response at'},\n",
       " {'end': 114, 'entity_group': 'B', 'score': 0.5415, 'start': 113, 'word': '5'},\n",
       " {'end': 148,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8906,\n",
       "  'start': 116,\n",
       "  'word': 'symmetrical and reactive pupils'},\n",
       " {'end': 166,\n",
       "  'entity_group': 'B',\n",
       "  'score': 1.0,\n",
       "  'start': 157,\n",
       "  'word': 'feeling-'},\n",
       " {'end': 169,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.659,\n",
       "  'start': 166,\n",
       "  'word': 'mot'},\n",
       " {'end': 179,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.972,\n",
       "  'start': 169,\n",
       "  'word': 'or deficit'},\n",
       " {'end': 189, 'entity_group': 'I', 'score': 0.844, 'start': 187, 'word': 'o'},\n",
       " {'end': 192,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.998,\n",
       "  'start': 189,\n",
       "  'word': 'ste'},\n",
       " {'end': 194, 'entity_group': 'I', 'score': 0.848, 'start': 192, 'word': 'ot'},\n",
       " {'end': 211,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.9556,\n",
       "  'start': 194,\n",
       "  'word': 'endinous reflexes'},\n",
       " {'end': 231,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8765,\n",
       "  'start': 212,\n",
       "  'word': 'slightly polypneic'},\n",
       " {'end': 237,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8477,\n",
       "  'start': 234,\n",
       "  'word': '24'},\n",
       " {'end': 245,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.59,\n",
       "  'start': 237,\n",
       "  'word': 'cycles/'},\n",
       " {'end': 254,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.98,\n",
       "  'start': 249,\n",
       "  'word': 'puls'},\n",
       " {'end': 256,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.5996,\n",
       "  'start': 254,\n",
       "  'word': 'ed'},\n",
       " {'end': 276, 'entity_group': 'B', 'score': 0.8115, 'start': 274, 'word': '('},\n",
       " {'end': 279, 'entity_group': 'B', 'score': 0.9854, 'start': 278, 'word': 'O'},\n",
       " {'end': 281, 'entity_group': 'B', 'score': 1.0, 'start': 280, 'word': '2'},\n",
       " {'end': 285, 'entity_group': 'B', 'score': 0.505, 'start': 282, 'word': 'at'},\n",
       " {'end': 288, 'entity_group': 'B', 'score': 0.902, 'start': 286, 'word': '97'},\n",
       " {'end': 308,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.9224,\n",
       "  'start': 305,\n",
       "  'word': 'he'},\n",
       " {'end': 317,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.676,\n",
       "  'start': 312,\n",
       "  'word': 'tach'},\n",
       " {'end': 328,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.905,\n",
       "  'start': 317,\n",
       "  'word': 'ycardic at '},\n",
       " {'end': 331, 'entity_group': 'B', 'score': 0.699, 'start': 330, 'word': '5'},\n",
       " {'end': 333, 'entity_group': 'I', 'score': 0.9126, 'start': 331, 'word': 'b'},\n",
       " {'end': 346,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.687,\n",
       "  'start': 339,\n",
       "  'word': 'hypert'},\n",
       " {'end': 357,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.956,\n",
       "  'start': 346,\n",
       "  'word': 'ensive at 1'},\n",
       " {'end': 360, 'entity_group': 'B', 'score': 0.986, 'start': 358, 'word': '0/'},\n",
       " {'end': 365,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.826,\n",
       "  'start': 361,\n",
       "  'word': '5 mm'},\n",
       " {'end': 379,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.8223,\n",
       "  'start': 372,\n",
       "  'word': 'capill'},\n",
       " {'end': 393,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.7593,\n",
       "  'start': 388,\n",
       "  'word': 'gluc'},\n",
       " {'end': 404, 'entity_group': 'I', 'score': 0.991, 'start': 402, 'word': '24'},\n",
       " {'end': 415, 'entity_group': 'I', 'score': 0.992, 'start': 413, 'word': 'g'},\n",
       " {'end': 417, 'entity_group': 'B', 'score': 0.997, 'start': 415, 'word': 'ly'},\n",
       " {'end': 420,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.6543,\n",
       "  'start': 417,\n",
       "  'word': 'cos'},\n",
       " {'end': 441,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.999,\n",
       "  'start': 437,\n",
       "  'word': 'dip'},\n",
       " {'end': 461, 'entity_group': 'B', 'score': 0.9844, 'start': 459, 'word': 'k'},\n",
       " {'end': 465,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.9014,\n",
       "  'start': 461,\n",
       "  'word': 'eton'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\", model=model, \n",
    "                            tokenizer=tokenizer, \n",
    "                            aggregation_strategy=\"simple\", batch_size=12)\n",
    "\n",
    "l = []\n",
    "for out in tqdm(token_classifier(KeyDataset(train_data.select(range(24)), \"sentence\"))):\n",
    "    l.append(out)\n",
    "\n",
    "tmp = train_data.select(range(24)).add_column('model_output', l)\n",
    "tmp[6]['model_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Their', 'child', 'acquired', 'walking', 'at', 'the', 'age', 'of', '14', 'months.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁Their',\n",
       " '▁child',\n",
       " '▁acquired',\n",
       " '▁walking',\n",
       " '▁at',\n",
       " '▁the',\n",
       " '▁age',\n",
       " '▁of',\n",
       " '▁',\n",
       " '1',\n",
       " '4',\n",
       " '▁months',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data[0]['tokens'])\n",
    "example = train_data[0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'MistralForTokenClassification' is not supported for ner. Supported models are ['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BioGptForTokenClassification', 'BloomForTokenClassification', 'BrosForTokenClassification', 'CamembertForTokenClassification', 'CanineForTokenClassification', 'ConvBertForTokenClassification', 'Data2VecTextForTokenClassification', 'DebertaForTokenClassification', 'DebertaV2ForTokenClassification', 'DistilBertForTokenClassification', 'ElectraForTokenClassification', 'ErnieForTokenClassification', 'ErnieMForTokenClassification', 'EsmForTokenClassification', 'FalconForTokenClassification', 'FlaubertForTokenClassification', 'FNetForTokenClassification', 'FunnelForTokenClassification', 'GPT2ForTokenClassification', 'GPT2ForTokenClassification', 'GPTBigCodeForTokenClassification', 'GPTNeoForTokenClassification', 'GPTNeoXForTokenClassification', 'IBertForTokenClassification', 'LayoutLMForTokenClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv3ForTokenClassification', 'LiltForTokenClassification', 'LongformerForTokenClassification', 'LukeForTokenClassification', 'MarkupLMForTokenClassification', 'MegaForTokenClassification', 'MegatronBertForTokenClassification', 'MobileBertForTokenClassification', 'MPNetForTokenClassification', 'MptForTokenClassification', 'MraForTokenClassification', 'MT5ForTokenClassification', 'NezhaForTokenClassification', 'NystromformerForTokenClassification', 'PhiForTokenClassification', 'QDQBertForTokenClassification', 'RemBertForTokenClassification', 'RobertaForTokenClassification', 'RobertaPreLayerNormForTokenClassification', 'RoCBertForTokenClassification', 'RoFormerForTokenClassification', 'SqueezeBertForTokenClassification', 'T5ForTokenClassification', 'UMT5ForTokenClassification', 'XLMForTokenClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaXLForTokenClassification', 'XLNetForTokenClassification', 'XmodForTokenClassification', 'YosoForTokenClassification'].\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([12, 166, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([12, 43, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.56it/s]                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 32,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.615,\n",
       "  'start': 18,\n",
       "  'word': 'found Glasgow'},\n",
       " {'end': 41, 'entity_group': 'I', 'score': 0.9956, 'start': 38, 'word': '(G'},\n",
       " {'end': 43, 'entity_group': 'B', 'score': 0.5854, 'start': 41, 'word': 'CS'},\n",
       " {'end': 48, 'entity_group': 'B', 'score': 0.768, 'start': 44, 'word': 'of '},\n",
       " {'end': 51, 'entity_group': 'B', 'score': 0.99, 'start': 50, 'word': '/'},\n",
       " {'end': 55, 'entity_group': 'I', 'score': 0.983, 'start': 53, 'word': '('},\n",
       " {'end': 58, 'entity_group': 'B', 'score': 0.961, 'start': 55, 'word': 'eye'},\n",
       " {'end': 69,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.724,\n",
       "  'start': 58,\n",
       "  'word': 'opening at'},\n",
       " {'end': 71, 'entity_group': 'I', 'score': 0.995, 'start': 70, 'word': '5'},\n",
       " {'end': 76,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.907,\n",
       "  'start': 71,\n",
       "  'word': ', ver'},\n",
       " {'end': 91,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.803,\n",
       "  'start': 76,\n",
       "  'word': 'bal response at'},\n",
       " {'end': 93, 'entity_group': 'I', 'score': 0.818, 'start': 92, 'word': '2'},\n",
       " {'end': 112,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.9326,\n",
       "  'start': 93,\n",
       "  'word': ', motor response at'},\n",
       " {'end': 114, 'entity_group': 'B', 'score': 0.5415, 'start': 113, 'word': '5'},\n",
       " {'end': 148,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8906,\n",
       "  'start': 116,\n",
       "  'word': 'symmetrical and reactive pupils'},\n",
       " {'end': 166,\n",
       "  'entity_group': 'B',\n",
       "  'score': 1.0,\n",
       "  'start': 157,\n",
       "  'word': 'feeling-'},\n",
       " {'end': 169,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.659,\n",
       "  'start': 166,\n",
       "  'word': 'mot'},\n",
       " {'end': 179,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.972,\n",
       "  'start': 169,\n",
       "  'word': 'or deficit'},\n",
       " {'end': 189, 'entity_group': 'I', 'score': 0.844, 'start': 187, 'word': 'o'},\n",
       " {'end': 192,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.998,\n",
       "  'start': 189,\n",
       "  'word': 'ste'},\n",
       " {'end': 194, 'entity_group': 'I', 'score': 0.848, 'start': 192, 'word': 'ot'},\n",
       " {'end': 211,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.9556,\n",
       "  'start': 194,\n",
       "  'word': 'endinous reflexes'},\n",
       " {'end': 231,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8765,\n",
       "  'start': 212,\n",
       "  'word': 'slightly polypneic'},\n",
       " {'end': 237,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8477,\n",
       "  'start': 234,\n",
       "  'word': '24'},\n",
       " {'end': 245,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.59,\n",
       "  'start': 237,\n",
       "  'word': 'cycles/'},\n",
       " {'end': 254,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.98,\n",
       "  'start': 249,\n",
       "  'word': 'puls'},\n",
       " {'end': 256,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.5996,\n",
       "  'start': 254,\n",
       "  'word': 'ed'},\n",
       " {'end': 276, 'entity_group': 'B', 'score': 0.8115, 'start': 274, 'word': '('},\n",
       " {'end': 279, 'entity_group': 'B', 'score': 0.9854, 'start': 278, 'word': 'O'},\n",
       " {'end': 281, 'entity_group': 'B', 'score': 1.0, 'start': 280, 'word': '2'},\n",
       " {'end': 285, 'entity_group': 'B', 'score': 0.505, 'start': 282, 'word': 'at'},\n",
       " {'end': 288, 'entity_group': 'B', 'score': 0.902, 'start': 286, 'word': '97'},\n",
       " {'end': 308,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.9224,\n",
       "  'start': 305,\n",
       "  'word': 'he'},\n",
       " {'end': 317,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.676,\n",
       "  'start': 312,\n",
       "  'word': 'tach'},\n",
       " {'end': 328,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.905,\n",
       "  'start': 317,\n",
       "  'word': 'ycardic at '},\n",
       " {'end': 331, 'entity_group': 'B', 'score': 0.699, 'start': 330, 'word': '5'},\n",
       " {'end': 333, 'entity_group': 'I', 'score': 0.9126, 'start': 331, 'word': 'b'},\n",
       " {'end': 346,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.687,\n",
       "  'start': 339,\n",
       "  'word': 'hypert'},\n",
       " {'end': 357,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.956,\n",
       "  'start': 346,\n",
       "  'word': 'ensive at 1'},\n",
       " {'end': 360, 'entity_group': 'B', 'score': 0.986, 'start': 358, 'word': '0/'},\n",
       " {'end': 365,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.826,\n",
       "  'start': 361,\n",
       "  'word': '5 mm'},\n",
       " {'end': 379,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.8223,\n",
       "  'start': 372,\n",
       "  'word': 'capill'},\n",
       " {'end': 393,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.7593,\n",
       "  'start': 388,\n",
       "  'word': 'gluc'},\n",
       " {'end': 404, 'entity_group': 'I', 'score': 0.991, 'start': 402, 'word': '24'},\n",
       " {'end': 415, 'entity_group': 'I', 'score': 0.992, 'start': 413, 'word': 'g'},\n",
       " {'end': 417, 'entity_group': 'B', 'score': 0.997, 'start': 415, 'word': 'ly'},\n",
       " {'end': 420,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.6543,\n",
       "  'start': 417,\n",
       "  'word': 'cos'},\n",
       " {'end': 441,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.999,\n",
       "  'start': 437,\n",
       "  'word': 'dip'},\n",
       " {'end': 461, 'entity_group': 'B', 'score': 0.9844, 'start': 459, 'word': 'k'},\n",
       " {'end': 465,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.9014,\n",
       "  'start': 461,\n",
       "  'word': 'eton'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "token_classifier = pipeline(\"ner\", model=model, \n",
    "                            tokenizer=tokenizer, \n",
    "                            aggregation_strategy=\"simple\", batch_size=12)\n",
    "\n",
    "\n",
    "#token_classifier(train_data[0]['tokens'])\n",
    "l = []\n",
    "for out in tqdm(token_classifier(KeyDataset(train_data.select(range(24)), \"sentence\"))):\n",
    "    l.append(out)\n",
    "\n",
    "tmp = train_data.select(range(24)).add_column('model_output', l)\n",
    "tmp[6]['model_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import evaluate\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "data = load_dataset(\"csv\", data_files=\"data/evaluation/train_data_LS_Mistral-7B-v0.1_adapters_en.layer1_NoQuant_16_32_0.01_2_0.0002.csv\")\n",
    "def helper(example):\n",
    "    example['model_output'] = ast.literal_eval(example['model_output'].replace('\\n', ','))\n",
    "    return example\n",
    "data = data.map(lambda x: helper(x))\n",
    "\n",
    "def compute_metrics(logits, labels):\n",
    "    model_output_logits = logits.cpu().detach().float().numpy()    \n",
    "    predictions = np.argmax(model_output_logits, axis=1)\n",
    "    print(predictions)\n",
    "    print(type(predictions))\n",
    "    print(type(labels))\n",
    "    lista = []\n",
    "    for i in range(len(labels)):\n",
    "        print('pred: ', predictions[i], 'label: ', labels[i])\n",
    "        if labels[i] != -100:\n",
    "         lista.append(label_list[predictions[i]])\n",
    "    print('lista: ', lista)\n",
    "\n",
    "    print( [label_list[prediction] for i, prediction in enumerate(predictions) if labels[i] != -100 ] )\n",
    "\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"soverall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B', 'I']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'O',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'I',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'I',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _create_prediction_list(self, model_output):\n",
    "        model_output_logits = model_output.logits.cpu().detach().float().numpy()\n",
    "        preds = np.argmax(model_output_logits, axis=2)\n",
    "        preds_list = []\n",
    "        for pred in preds:\n",
    "            preds_list.append([self.id2label[label] for label in pred])\n",
    "        return preds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "generated_ids['logits'][0]\n",
    "print(type(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "53\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0]['labels']))\n",
    "print(len(train_data[0]['sentence']))\n",
    "print(len(generated_ids['logits'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'entities', 'original_text', 'original_id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = train_data.select(range(2))\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "53\n",
      "Their child acquired walking at the age of 14 months.\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 2, 1, 1, 0, 0, 0, 0, 0, -100, -100, 0, -100]\n",
      "[-100, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'B': 1, 'I': 2}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((examples[0]['ner_tags']))\n",
    "print(len(examples[0]['sentence']))\n",
    "print((examples[0]['sentence']))\n",
    "print((examples[0]['labels']))\n",
    "#print(len(examples['logits'][0]))\n",
    "print(labels[0])\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1520/1520 [00:00<00:00, 13777.85 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET_CHEKPOINT) #download_mode=\"force_redownload\"\n",
    "dataset = dataset[TRAIN_LAYER]\n",
    "dataset = dataset.shuffle(seed=1234)  \n",
    "dataset_format_converter = DatasetFormatConverter(dataset)\n",
    "dataset_format_converter.apply()\n",
    "ds = dataset_format_converter.dataset\n",
    "label2id = dataset_format_converter.label2id\n",
    "id2label = dataset_format_converter.get_id2label()\n",
    "label_list = dataset_format_converter.get_label_list()\n",
    "dataset = ds.map(lambda x: tokenize_and_align_labels(x), batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentece:  Their child acquired walking at the age of 14 months. \n",
      "labels:  [-100, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "sentece:  An abdominal ultrasound examination was reported as normal. \n",
      "labels:  [-100, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2]\n",
      "sentece:  Her blood pressure was 100/70 mmHg with a pulse rate of 98 beats/min, respiratory rate about 16/min and oral temperature of 37°C. \n",
      "labels:  [-100, 0, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2]\n",
      "sentece:  Emergency neck computed tomography angiography showed a contrast-enhanced abscess cavity posterior to the left retropharyngeal space, and a low-density area surrounded by an area without contrast enhancement in the posterior neck. \n",
      "labels:  [-100, 0, 0, 1, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2]\n",
      "sentece:  The mitotic rate was extremely high (19 mitosis/10 high power field), and atypical mitotic figures were also present. \n",
      "labels:  [-100, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "sentece:  Pertinent laboratory studies included a hemoglobin level of 10 g/dL, platelet count was normal, blood urea of 1,2 g/l (0,18-0,45 g/L), and a creatinine level of 68 mg/L (7-13 mg/L). \n",
      "labels:  [-100, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "sentece:  Initial assessment found Glasgow score (GCS) of 12/15 (eye opening at 5, verbal response at 2, motor response at 5), symmetrical and reactive pupils, without feeling-motor deficit, normal osteotendinous reflexes, slightly polypneic at 24 cycles/min, pulsed oxygen saturation (SpO 2) at 97% in ambient air, he was tachycardic at 115 bpm and hypertensive at 160/95 mmHg, his capillary blood glucose at 2.24 g/L, and glycosuria on the urine dipstick test without ketonuria. \n",
      "labels:  [-100, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 1, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2]\n",
      "sentece:  Lab results showed haemoglobin 10.9 g/dl, packed cell volume 35%, and positive malaria parasites. \n",
      "labels:  [-100, 0, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = preprocessor.split_layer_into_train_val_test_(dataset, TRAIN_LAYER)\n",
    "for i in range(8):\n",
    "    print('sentece: ', train_data[i]['sentence'], '\\nlabels: ', train_data[i]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[1, 1094, 534, 2920, 1475, 9271, 12423, 687, 20976, 403, 5745, 390, 4123, 28723], [1, 21127, 277, 4475, 8289, 302, 272, 16594, 28765, 6642, 369, 23096, 8894, 654, 5278, 354, 264, 9194, 302, 1581, 6752, 1716, 404, 325, 5072, 28731, 325, 5072, 28770, 28781, 28725, 8204, 28740, 28774, 28725, 8204, 28740, 28734, 28725, 8204, 28750, 28750, 304, 19966, 5278, 354, 8204, 28781, 28782, 28731, 8735, 288, 334, 7016, 9237, 3000, 678, 628, 305, 1082, 721, 806, 23096, 297, 2088, 434, 352, 28723]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2], [-100, 0, 1, 2, 2, 0, 1, 2, 2, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2]]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, words_label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        label_ids = []\n",
    "        for k, word_idx in enumerate(word_ids): \n",
    "            same_word_as_previous  = False if (word_idx != word_ids[k-1] or k==0) else True\n",
    "            if word_idx is None:\n",
    "                token_label = -100\n",
    "            elif words_label[word_idx] == label2id['O']:\n",
    "                token_label = label2id['O']\n",
    "            elif same_word_as_previous:\n",
    "                token_label = label2id['I']\n",
    "            elif not same_word_as_previous:\n",
    "                token_label = words_label[word_idx]\n",
    "            label_ids.append(token_label)\n",
    "            # if word_idx is not None:#  and k>12:\n",
    "            #     print(\"word_label: \", words_label[word_idx])\n",
    "            # print(tokenizer.decode(tokenized_inputs[i].ids[k]), \": \",word_idx,  \"\\nassigned_token_label:\",  label_ids[k], '\\n')\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "tokenize_and_align_labels(ds.select(range(2, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([2, 76, 4096])\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0 2 1 1 0 0 1 0 0 1 0\n",
      " 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  2 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  2 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 76 is out of bounds for axis 0 with size 76",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#gen = OutputGeneration(model, tokenizer, id2label)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#pl = gen._create_prediction_list(generated_ids)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(logits, labels)\u001b[0m\n\u001b[1;32m     17\u001b[0m lista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels)):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel: \u001b[39m\u001b[38;5;124m'\u001b[39m, labels[i])\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels[i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:\n\u001b[1;32m     21\u001b[0m      lista\u001b[38;5;241m.\u001b[39mappend(label_list[predictions[i]])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 76 is out of bounds for axis 0 with size 76"
     ]
    }
   ],
   "source": [
    "# examples = [train_data['sentence'][0] , train_data['sentence'][5]]\n",
    "# input_sentences = examples\n",
    "# encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "# model_inputs = encodeds.to('cuda')\n",
    "# generated_ids = model(**model_inputs)\n",
    "# model_output_logits = generated_ids.logits.cpu().detach().float().numpy()\n",
    "examples = [train_data['sentence'][0], train_data['sentence'][5]]\n",
    "input_sentences = examples\n",
    "encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "model_inputs = encodeds.to('cuda')\n",
    "generated_ids = model(**model_inputs)\n",
    "#gen = OutputGeneration(model, tokenizer, id2label)\n",
    "#pl = gen._create_prediction_list(generated_ids)\n",
    "compute_metrics(generated_ids['logits'][0],   train_data[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -100,\n",
       " -100,\n",
       " 0,\n",
       " -100]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence', 'entities', 'original_text', 'original_id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'B', 'O', 'B', 'O', 'B']\n",
      "['An', 'abdominal', 'ultrasound', 'examination', 'was', 'reported', 'as', 'normal.']\n",
      "{'input_ids': [1, 1094, 534, 2920, 1475, 9271, 12423, 687, 20976, 403, 5745, 390, 4123, 28723], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "<s> An abdominal ultrasound examination was reported as normal.\n",
      "[{'end': 8, 'entity_group': 'B', 'score': 0.648, 'start': 5, 'word': 'dom'}, {'end': 15, 'entity_group': 'B', 'score': 0.928, 'start': 12, 'word': 'ul'}, {'end': 35, 'entity_group': 'B', 'score': 0.9463, 'start': 23, 'word': 'examination'}, {'end': 48, 'entity_group': 'B', 'score': 0.8286, 'start': 39, 'word': 'reported'}, {'end': 58, 'entity_group': 'B', 'score': 0.6094, 'start': 51, 'word': 'normal'}]\n"
     ]
    }
   ],
   "source": [
    "example = tmp[1]\n",
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "print(labels)\n",
    "print(example['tokens'])\n",
    "print(tokenizer(example['sentence']))\n",
    "print(tokenizer.decode(tokenizer(example['sentence'])['input_ids']))\n",
    "print(example['model_output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
