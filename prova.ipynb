{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from peft import PeftModel, PeftConfig\n",
    "from dotenv import dotenv_values\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import DataPreprocessor, DatasetFormatConverter\n",
    "from utils import DataPreprocessor\n",
    "\n",
    "from src.billm import LlamaForTokenClassification\n",
    "\n",
    "WANDB_KEY = dotenv_values(\".env.base\")['WANDB_KEY']\n",
    "LLAMA_TOKEN = dotenv_values(\".env.base\")['LLAMA_TOKEN']\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "adapters = \"ferrazzipietro/LS_Llama-2-7b-hf_adapters_en.layer1_NoQuant_64_64_0.05_8_0.0002\"\n",
    "peft_config = PeftConfig.from_pretrained(adapters)\n",
    "BASE_MODEL_CHECKPOINT = peft_config.base_model_name_or_path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_CHECKPOINT,token =HF_TOKEN)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# seqeval = evaluate.load(\"seqeval\")\n",
    "DATASET_CHEKPOINT=\"ferrazzipietro/e3c-sentences\" \n",
    "TRAIN_LAYER=\"en.layer1\"\n",
    "preprocessor = DataPreprocessor(BASE_MODEL_CHECKPOINT, \n",
    "                                tokenizer)\n",
    "dataset = load_dataset(DATASET_CHEKPOINT) #download_mode=\"force_redownload\"\n",
    "dataset = dataset[TRAIN_LAYER]\n",
    "dataset = dataset.shuffle(seed=1234)  \n",
    "dataset_format_converter = DatasetFormatConverter(dataset)\n",
    "dataset_format_converter.apply()\n",
    "ds = dataset_format_converter.dataset\n",
    "label2id = dataset_format_converter.label2id\n",
    "id2label = dataset_format_converter.get_id2label()\n",
    "label_list = dataset_format_converter.get_label_list()\n",
    "dataset_format_converter.set_tokenizer(tokenizer)\n",
    "dataset_format_converter.set_max_seq_length(256)\n",
    "tokenized_ds = ds.map(lambda x: dataset_format_converter.tokenize_and_align_labels(x), batched=True)# dataset_format_converter.dataset.map(tokenize_and_align_labels, batched=True)\n",
    "train_data, val_data, test_data = preprocessor.split_layer_into_train_val_test_(tokenized_ds, TRAIN_LAYER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]\n",
      "Some weights of LlamaForTokenClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "/home/pferrazzi/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                )\n",
    "\n",
    "model = LlamaForTokenClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=len(label2id), id2label=id2label, label2id=label2id,\n",
    "    token = HF_TOKEN,\n",
    "    cache_dir='/data/disk1/share/pferrazzi/.cache',\n",
    "    device_map='auto',\n",
    "    quantization_config = bnb_config)\n",
    "model = PeftModel.from_pretrained(model, adapters, token = HF_TOKEN)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses: 100%|██████████| 6/6 [00:01<00:00,  5.33it/s]\n"
     ]
    }
   ],
   "source": [
    "class OutputGeneration():\n",
    "    def __init__(self, model, tokenizer, label2id):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2id = label2id\n",
    "    \n",
    "    def _create_prediction_list(self, model_output):\n",
    "        model_output_logits = model_output.logits.cpu().detach().float().numpy()\n",
    "        preds = np.argmax(model_output_logits, axis=2)\n",
    "        preds_list = []\n",
    "        for pred in preds:\n",
    "            preds_list.append([self.label2id[label] for label in pred])\n",
    "        return preds_list\n",
    "\n",
    "    def _generate_batch(self, input_sentences, model, tokenizer):\n",
    "        encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "        model_inputs = encodeds.to('cuda')\n",
    "        generated_ids = model(**model_inputs)\n",
    "        preds = self._create_prediction_list(generated_ids)\n",
    "        return preds\n",
    "    \n",
    "\n",
    "    def add_output_column(self, data, model, tokenizer, batch_size:int) -> None:\n",
    "        \"\"\"\n",
    "        Adds a column with the response of the model to the actual query.\n",
    "        \n",
    "        params:\n",
    "        model: the model to use to generate the response\n",
    "        tokenizer: the tokenizer to use to generate the response\n",
    "        batch_size: the batch size to use to process the examples. Increasing this makes it faster but requires more GPU. Default is 8.\n",
    "        \"\"\"\n",
    "        responses_col = []\n",
    "        total_rows = len(data)\n",
    "        indexes = [i for i in range(len(data)) if i % batch_size == 0]\n",
    "        max_index = data.shape[0]\n",
    "\n",
    "        with tqdm(total=total_rows, desc=\"generating responses\") as pbar:\n",
    "            for i, idx in enumerate(indexes[:-1]):\n",
    "                indici = list(range(idx, indexes[i+1]))\n",
    "                tmp = self._generate_batch(data.select(indici)['sentence'], model, tokenizer)\n",
    "                responses_col.extend(tmp)\n",
    "                pbar.update(batch_size)\n",
    "            indici = list(range(indexes[len(indexes[:-1])], max_index))\n",
    "            tmp = self._generate_batch(data.select(indici)['sentence'], model, tokenizer)\n",
    "            responses_col.extend(tmp)\n",
    "            pbar.update(batch_size)\n",
    "        \n",
    "        data = data.add_column('model_responses', responses_col)\n",
    "        return data\n",
    "   \n",
    "output_generation = OutputGeneration(model, tokenizer, id2label)\n",
    "tmp = output_generation.add_output_column(train_data.select(range(6)), model, tokenizer, 3) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss={'logits': tensor([[[ 5.6104e-01, -3.7344e+00, -5.5957e-01],\n",
       "         [ 6.6797e-01, -1.0869e+00, -2.2871e+00],\n",
       "         [-2.3242e+00, -2.1172e+00,  1.1387e+00],\n",
       "         [ 2.2754e+00,  1.2021e+00, -1.8037e+00],\n",
       "         [ 6.5869e-01,  1.9824e+00, -2.8145e+00],\n",
       "         [ 2.4980e+00,  3.2275e-01, -3.0859e+00],\n",
       "         [ 1.8848e+00, -1.2773e+00, -3.1465e+00],\n",
       "         [ 1.1963e+00, -3.0713e-01, -9.5654e-01],\n",
       "         [ 3.3926e+00, -1.6904e+00, -1.4746e+00],\n",
       "         [ 1.3389e+00,  5.6689e-01,  1.6436e+00],\n",
       "         [ 1.0381e+00, -7.4316e-01, -5.7678e-02],\n",
       "         [ 1.0088e+00,  2.6099e-01, -8.0713e-01],\n",
       "         [ 1.1246e-02, -1.0391e+00,  4.9048e-01],\n",
       "         [-3.0054e-01, -4.4414e+00, -2.6831e-01],\n",
       "         [-8.7500e-01,  3.0000e+00, -1.0010e+00],\n",
       "         [-9.9658e-01,  2.9434e+00, -1.0312e+00],\n",
       "         [-1.0449e+00,  2.9062e+00, -1.1006e+00],\n",
       "         [-1.0439e+00,  2.9473e+00, -1.0967e+00],\n",
       "         [-1.0664e+00,  2.9902e+00, -1.0869e+00],\n",
       "         [-1.0947e+00,  3.0039e+00, -1.0439e+00],\n",
       "         [-1.1230e+00,  2.9941e+00, -1.0244e+00],\n",
       "         [-1.1230e+00,  2.9629e+00, -1.0596e+00],\n",
       "         [-1.1006e+00,  2.9355e+00, -1.1035e+00],\n",
       "         [-1.0820e+00,  2.9238e+00, -1.1416e+00],\n",
       "         [-1.1025e+00,  2.9941e+00, -1.1328e+00],\n",
       "         [-1.1318e+00,  3.0547e+00, -1.0879e+00],\n",
       "         [-1.1777e+00,  3.1250e+00, -1.0508e+00],\n",
       "         [-1.1592e+00,  3.1738e+00, -1.0088e+00],\n",
       "         [-1.1445e+00,  3.2227e+00, -9.8975e-01],\n",
       "         [-1.1055e+00,  3.2500e+00, -9.7803e-01],\n",
       "         [-1.0938e+00,  3.2051e+00, -1.0000e+00],\n",
       "         [-1.1113e+00,  3.1270e+00, -1.0332e+00],\n",
       "         [-1.1270e+00,  3.0762e+00, -1.0322e+00],\n",
       "         [-1.1348e+00,  3.1152e+00, -1.0049e+00],\n",
       "         [-1.0938e+00,  3.1445e+00, -9.7754e-01],\n",
       "         [-1.0547e+00,  3.2051e+00, -9.4531e-01],\n",
       "         [-1.0361e+00,  3.1855e+00, -9.4678e-01],\n",
       "         [-1.0674e+00,  3.1113e+00, -9.8633e-01],\n",
       "         [-1.1328e+00,  3.0332e+00, -1.0439e+00],\n",
       "         [-1.1436e+00,  3.0352e+00, -1.0439e+00],\n",
       "         [-1.1152e+00,  3.1133e+00, -9.8730e-01],\n",
       "         [-1.0400e+00,  3.2598e+00, -9.1113e-01],\n",
       "         [-9.9658e-01,  3.3438e+00, -8.7354e-01],\n",
       "         [-1.0088e+00,  3.3496e+00, -8.8184e-01],\n",
       "         [-1.0371e+00,  3.2715e+00, -9.1797e-01],\n",
       "         [-1.0879e+00,  3.1855e+00, -1.0117e+00],\n",
       "         [-1.0996e+00,  3.1445e+00, -1.0625e+00],\n",
       "         [-1.0205e+00,  3.2305e+00, -9.8877e-01],\n",
       "         [-9.4238e-01,  3.3242e+00, -9.1211e-01],\n",
       "         [-9.4141e-01,  3.3574e+00, -8.6816e-01],\n",
       "         [-9.8926e-01,  3.2930e+00, -8.9746e-01],\n",
       "         [-1.0928e+00,  3.1738e+00, -1.0156e+00],\n",
       "         [-1.1445e+00,  3.0938e+00, -1.0762e+00],\n",
       "         [-1.1045e+00,  3.1035e+00, -1.0879e+00],\n",
       "         [-9.8779e-01,  3.2227e+00, -9.9170e-01],\n",
       "         [-9.2383e-01,  3.3438e+00, -8.7256e-01],\n",
       "         [-9.2822e-01,  3.3984e+00, -7.7637e-01],\n",
       "         [-9.8877e-01,  3.3418e+00, -7.8955e-01],\n",
       "         [-1.0752e+00,  3.2031e+00, -8.6768e-01],\n",
       "         [-1.1396e+00,  3.1074e+00, -9.6094e-01],\n",
       "         [-1.1025e+00,  3.1348e+00, -9.6436e-01],\n",
       "         [-1.0498e+00,  3.1953e+00, -9.4629e-01],\n",
       "         [-1.0117e+00,  3.2559e+00, -8.7646e-01],\n",
       "         [-1.0303e+00,  3.2578e+00, -8.4326e-01],\n",
       "         [-1.0723e+00,  3.2031e+00, -8.6523e-01],\n",
       "         [-1.0986e+00,  3.1602e+00, -8.9111e-01],\n",
       "         [-1.0801e+00,  3.1445e+00, -8.9502e-01],\n",
       "         [-1.0312e+00,  3.1934e+00, -8.8184e-01],\n",
       "         [-9.9121e-01,  3.2695e+00, -8.3936e-01],\n",
       "         [-9.7461e-01,  3.3281e+00, -8.0225e-01],\n",
       "         [-1.0068e+00,  3.3242e+00, -8.0566e-01],\n",
       "         [-1.0332e+00,  3.2793e+00, -8.3301e-01],\n",
       "         [-1.0732e+00,  3.2129e+00, -8.8379e-01],\n",
       "         [-1.0996e+00,  3.1094e+00, -9.5459e-01],\n",
       "         [-1.1211e+00,  3.0098e+00, -1.0254e+00],\n",
       "         [-1.1475e+00,  2.9336e+00, -1.0576e+00],\n",
       "         [-1.1748e+00,  2.9141e+00, -1.0596e+00],\n",
       "         [-1.1826e+00,  2.9668e+00, -1.0293e+00]],\n",
       "\n",
       "        [[ 5.6104e-01, -3.7344e+00, -5.5957e-01],\n",
       "         [ 8.9990e-01,  1.0752e+00, -1.0577e-01],\n",
       "         [ 2.9199e-01,  2.1523e+00, -3.6743e-01],\n",
       "         [-2.4866e-01,  7.6709e-01, -1.3467e+00],\n",
       "         [ 8.8330e-01,  3.6963e-01, -7.8064e-02],\n",
       "         [ 2.6318e-01,  2.2637e+00, -1.0830e+00],\n",
       "         [-6.4941e-02,  2.2539e+00, -2.9004e+00],\n",
       "         [ 1.8984e+00, -4.7272e-02, -2.9980e+00],\n",
       "         [ 1.9824e+00,  2.0762e+00, -4.9609e+00],\n",
       "         [ 1.6875e+00, -1.6125e-01, -8.8379e-01],\n",
       "         [-1.3223e+00,  1.2920e+00, -1.2266e+00],\n",
       "         [ 3.1445e-01,  1.7395e-01, -5.9863e-01],\n",
       "         [ 1.7070e+00,  5.7080e-01, -9.5654e-01],\n",
       "         [-2.5787e-03,  5.8740e-01, -3.0215e+00],\n",
       "         [ 3.1465e+00, -8.7158e-01, -2.5098e+00],\n",
       "         [ 1.7832e+00,  2.3496e+00,  1.0469e+00],\n",
       "         [ 2.2598e+00, -8.9209e-01, -1.6416e+00],\n",
       "         [ 2.2695e+00, -1.4141e+00, -1.6328e+00],\n",
       "         [-4.9146e-01, -7.0361e-01,  5.6689e-01],\n",
       "         [ 1.1719e+00, -1.0049e+00,  2.0156e+00],\n",
       "         [-1.1689e+00, -1.8691e+00,  4.6021e-01],\n",
       "         [-7.4609e-01,  1.5173e-01, -1.9600e+00],\n",
       "         [ 4.1836e+00,  5.6641e-01, -3.0527e+00],\n",
       "         [ 5.4102e-01, -3.0792e-02,  3.9575e-01],\n",
       "         [ 1.7148e+00, -6.8701e-01,  1.3062e-01],\n",
       "         [ 1.8721e+00,  2.0664e+00, -1.7314e+00],\n",
       "         [ 3.3223e+00,  3.5791e-01, -3.3203e+00],\n",
       "         [ 1.2627e+00,  1.9697e+00, -3.4531e+00],\n",
       "         [ 3.9082e+00,  1.4746e-01, -2.4316e+00],\n",
       "         [ 1.8086e+00,  6.7236e-01, -2.4072e-01],\n",
       "         [-3.2788e-01,  6.6357e-01,  9.5850e-01],\n",
       "         [ 2.1816e+00,  1.0439e+00, -1.4873e+00],\n",
       "         [ 3.6602e+00,  3.5596e-01, -3.1777e+00],\n",
       "         [ 1.1973e+00,  2.5898e+00,  8.1982e-01],\n",
       "         [ 1.8926e+00, -1.5186e+00, -1.7305e+00],\n",
       "         [ 2.6973e+00, -7.2656e-01, -1.1748e+00],\n",
       "         [ 2.7637e+00,  9.4482e-01, -7.8076e-01],\n",
       "         [-7.7686e-01,  6.5967e-01, -1.4294e-01],\n",
       "         [ 9.7852e-01, -5.7471e-01,  1.9268e+00],\n",
       "         [-6.1157e-02, -8.1152e-01, -5.5127e-01],\n",
       "         [ 2.2344e+00, -1.7322e-01, -7.5781e-01],\n",
       "         [ 3.1953e+00, -1.3984e+00, -2.3633e+00],\n",
       "         [ 1.4883e+00, -1.3018e+00,  3.4424e-01],\n",
       "         [ 2.9062e+00,  5.3955e-01, -1.8916e+00],\n",
       "         [ 1.9287e+00, -1.3350e+00, -2.1133e+00],\n",
       "         [ 1.7725e+00,  2.5610e-01, -1.9141e+00],\n",
       "         [ 8.5254e-01, -2.1348e+00, -1.2920e+00],\n",
       "         [ 1.3555e+00, -1.1289e+00,  5.7666e-01],\n",
       "         [ 2.7461e+00, -9.5996e-01, -1.1787e+00],\n",
       "         [ 1.2383e+00, -4.7388e-01, -1.6807e+00],\n",
       "         [ 2.1777e-01,  5.0146e-01,  1.0869e+00],\n",
       "         [ 1.6758e+00, -2.2266e-01,  2.3301e+00],\n",
       "         [-2.0020e+00, -1.0693e+00, -1.5225e+00],\n",
       "         [ 3.6328e+00, -1.6445e+00, -1.7607e+00],\n",
       "         [ 2.9180e+00, -1.1191e+00, -1.9229e+00],\n",
       "         [ 2.4277e+00, -4.4043e-01, -2.9961e+00],\n",
       "         [ 2.2754e+00,  9.0479e-01, -1.6533e+00],\n",
       "         [-2.6270e+00, -7.8955e-01, -5.4150e-01],\n",
       "         [ 3.9185e-01,  4.6094e-01, -7.8369e-01],\n",
       "         [ 6.0730e-02,  1.0635e+00, -1.9971e+00],\n",
       "         [ 3.5195e+00, -4.0918e-01, -1.6338e+00],\n",
       "         [ 1.8057e+00,  2.2168e+00,  1.5781e+00],\n",
       "         [ 2.7109e+00,  5.0244e-01, -1.2549e+00],\n",
       "         [ 2.3457e+00, -1.1016e+00,  1.0876e-01],\n",
       "         [-1.1865e+00, -1.7148e+00,  1.8779e+00],\n",
       "         [ 1.2412e+00, -4.5044e-01,  1.8955e+00],\n",
       "         [ 1.7910e+00, -9.9869e-03,  2.6816e+00],\n",
       "         [-8.9648e-01,  1.3184e+00, -9.0527e-01],\n",
       "         [ 1.6523e+00,  8.2764e-01,  1.9324e-01],\n",
       "         [ 1.6963e+00,  9.2590e-02, -1.7002e+00],\n",
       "         [ 2.3145e-01,  1.1660e+00, -3.5645e-01],\n",
       "         [ 5.1953e-01,  3.1567e-01, -6.2988e-01],\n",
       "         [ 1.9463e+00,  6.5869e-01, -1.6572e+00],\n",
       "         [ 4.4849e-01, -1.0859e+00,  1.2732e-01],\n",
       "         [ 1.8477e+00, -3.7476e-01,  1.5498e+00],\n",
       "         [ 2.8066e+00,  6.0791e-01,  1.8721e+00],\n",
       "         [-1.4541e+00, -7.5293e-01, -4.3188e-01],\n",
       "         [ 1.5615e+00, -1.2334e+00, -1.1699e+00]]], device='cuda:1',\n",
       "       dtype=torch.float16, grad_fn=<ViewBackward0>)}, logits=tensor([[[ 5.6104e-01, -3.7344e+00, -5.5957e-01],\n",
       "         [ 6.6797e-01, -1.0869e+00, -2.2871e+00],\n",
       "         [-2.3242e+00, -2.1172e+00,  1.1387e+00],\n",
       "         [ 2.2754e+00,  1.2021e+00, -1.8037e+00],\n",
       "         [ 6.5869e-01,  1.9824e+00, -2.8145e+00],\n",
       "         [ 2.4980e+00,  3.2275e-01, -3.0859e+00],\n",
       "         [ 1.8848e+00, -1.2773e+00, -3.1465e+00],\n",
       "         [ 1.1963e+00, -3.0713e-01, -9.5654e-01],\n",
       "         [ 3.3926e+00, -1.6904e+00, -1.4746e+00],\n",
       "         [ 1.3389e+00,  5.6689e-01,  1.6436e+00],\n",
       "         [ 1.0381e+00, -7.4316e-01, -5.7678e-02],\n",
       "         [ 1.0088e+00,  2.6099e-01, -8.0713e-01],\n",
       "         [ 1.1246e-02, -1.0391e+00,  4.9048e-01],\n",
       "         [-3.0054e-01, -4.4414e+00, -2.6831e-01],\n",
       "         [-8.7500e-01,  3.0000e+00, -1.0010e+00],\n",
       "         [-9.9658e-01,  2.9434e+00, -1.0312e+00],\n",
       "         [-1.0449e+00,  2.9062e+00, -1.1006e+00],\n",
       "         [-1.0439e+00,  2.9473e+00, -1.0967e+00],\n",
       "         [-1.0664e+00,  2.9902e+00, -1.0869e+00],\n",
       "         [-1.0947e+00,  3.0039e+00, -1.0439e+00],\n",
       "         [-1.1230e+00,  2.9941e+00, -1.0244e+00],\n",
       "         [-1.1230e+00,  2.9629e+00, -1.0596e+00],\n",
       "         [-1.1006e+00,  2.9355e+00, -1.1035e+00],\n",
       "         [-1.0820e+00,  2.9238e+00, -1.1416e+00],\n",
       "         [-1.1025e+00,  2.9941e+00, -1.1328e+00],\n",
       "         [-1.1318e+00,  3.0547e+00, -1.0879e+00],\n",
       "         [-1.1777e+00,  3.1250e+00, -1.0508e+00],\n",
       "         [-1.1592e+00,  3.1738e+00, -1.0088e+00],\n",
       "         [-1.1445e+00,  3.2227e+00, -9.8975e-01],\n",
       "         [-1.1055e+00,  3.2500e+00, -9.7803e-01],\n",
       "         [-1.0938e+00,  3.2051e+00, -1.0000e+00],\n",
       "         [-1.1113e+00,  3.1270e+00, -1.0332e+00],\n",
       "         [-1.1270e+00,  3.0762e+00, -1.0322e+00],\n",
       "         [-1.1348e+00,  3.1152e+00, -1.0049e+00],\n",
       "         [-1.0938e+00,  3.1445e+00, -9.7754e-01],\n",
       "         [-1.0547e+00,  3.2051e+00, -9.4531e-01],\n",
       "         [-1.0361e+00,  3.1855e+00, -9.4678e-01],\n",
       "         [-1.0674e+00,  3.1113e+00, -9.8633e-01],\n",
       "         [-1.1328e+00,  3.0332e+00, -1.0439e+00],\n",
       "         [-1.1436e+00,  3.0352e+00, -1.0439e+00],\n",
       "         [-1.1152e+00,  3.1133e+00, -9.8730e-01],\n",
       "         [-1.0400e+00,  3.2598e+00, -9.1113e-01],\n",
       "         [-9.9658e-01,  3.3438e+00, -8.7354e-01],\n",
       "         [-1.0088e+00,  3.3496e+00, -8.8184e-01],\n",
       "         [-1.0371e+00,  3.2715e+00, -9.1797e-01],\n",
       "         [-1.0879e+00,  3.1855e+00, -1.0117e+00],\n",
       "         [-1.0996e+00,  3.1445e+00, -1.0625e+00],\n",
       "         [-1.0205e+00,  3.2305e+00, -9.8877e-01],\n",
       "         [-9.4238e-01,  3.3242e+00, -9.1211e-01],\n",
       "         [-9.4141e-01,  3.3574e+00, -8.6816e-01],\n",
       "         [-9.8926e-01,  3.2930e+00, -8.9746e-01],\n",
       "         [-1.0928e+00,  3.1738e+00, -1.0156e+00],\n",
       "         [-1.1445e+00,  3.0938e+00, -1.0762e+00],\n",
       "         [-1.1045e+00,  3.1035e+00, -1.0879e+00],\n",
       "         [-9.8779e-01,  3.2227e+00, -9.9170e-01],\n",
       "         [-9.2383e-01,  3.3438e+00, -8.7256e-01],\n",
       "         [-9.2822e-01,  3.3984e+00, -7.7637e-01],\n",
       "         [-9.8877e-01,  3.3418e+00, -7.8955e-01],\n",
       "         [-1.0752e+00,  3.2031e+00, -8.6768e-01],\n",
       "         [-1.1396e+00,  3.1074e+00, -9.6094e-01],\n",
       "         [-1.1025e+00,  3.1348e+00, -9.6436e-01],\n",
       "         [-1.0498e+00,  3.1953e+00, -9.4629e-01],\n",
       "         [-1.0117e+00,  3.2559e+00, -8.7646e-01],\n",
       "         [-1.0303e+00,  3.2578e+00, -8.4326e-01],\n",
       "         [-1.0723e+00,  3.2031e+00, -8.6523e-01],\n",
       "         [-1.0986e+00,  3.1602e+00, -8.9111e-01],\n",
       "         [-1.0801e+00,  3.1445e+00, -8.9502e-01],\n",
       "         [-1.0312e+00,  3.1934e+00, -8.8184e-01],\n",
       "         [-9.9121e-01,  3.2695e+00, -8.3936e-01],\n",
       "         [-9.7461e-01,  3.3281e+00, -8.0225e-01],\n",
       "         [-1.0068e+00,  3.3242e+00, -8.0566e-01],\n",
       "         [-1.0332e+00,  3.2793e+00, -8.3301e-01],\n",
       "         [-1.0732e+00,  3.2129e+00, -8.8379e-01],\n",
       "         [-1.0996e+00,  3.1094e+00, -9.5459e-01],\n",
       "         [-1.1211e+00,  3.0098e+00, -1.0254e+00],\n",
       "         [-1.1475e+00,  2.9336e+00, -1.0576e+00],\n",
       "         [-1.1748e+00,  2.9141e+00, -1.0596e+00],\n",
       "         [-1.1826e+00,  2.9668e+00, -1.0293e+00]],\n",
       "\n",
       "        [[ 5.6104e-01, -3.7344e+00, -5.5957e-01],\n",
       "         [ 8.9990e-01,  1.0752e+00, -1.0577e-01],\n",
       "         [ 2.9199e-01,  2.1523e+00, -3.6743e-01],\n",
       "         [-2.4866e-01,  7.6709e-01, -1.3467e+00],\n",
       "         [ 8.8330e-01,  3.6963e-01, -7.8064e-02],\n",
       "         [ 2.6318e-01,  2.2637e+00, -1.0830e+00],\n",
       "         [-6.4941e-02,  2.2539e+00, -2.9004e+00],\n",
       "         [ 1.8984e+00, -4.7272e-02, -2.9980e+00],\n",
       "         [ 1.9824e+00,  2.0762e+00, -4.9609e+00],\n",
       "         [ 1.6875e+00, -1.6125e-01, -8.8379e-01],\n",
       "         [-1.3223e+00,  1.2920e+00, -1.2266e+00],\n",
       "         [ 3.1445e-01,  1.7395e-01, -5.9863e-01],\n",
       "         [ 1.7070e+00,  5.7080e-01, -9.5654e-01],\n",
       "         [-2.5787e-03,  5.8740e-01, -3.0215e+00],\n",
       "         [ 3.1465e+00, -8.7158e-01, -2.5098e+00],\n",
       "         [ 1.7832e+00,  2.3496e+00,  1.0469e+00],\n",
       "         [ 2.2598e+00, -8.9209e-01, -1.6416e+00],\n",
       "         [ 2.2695e+00, -1.4141e+00, -1.6328e+00],\n",
       "         [-4.9146e-01, -7.0361e-01,  5.6689e-01],\n",
       "         [ 1.1719e+00, -1.0049e+00,  2.0156e+00],\n",
       "         [-1.1689e+00, -1.8691e+00,  4.6021e-01],\n",
       "         [-7.4609e-01,  1.5173e-01, -1.9600e+00],\n",
       "         [ 4.1836e+00,  5.6641e-01, -3.0527e+00],\n",
       "         [ 5.4102e-01, -3.0792e-02,  3.9575e-01],\n",
       "         [ 1.7148e+00, -6.8701e-01,  1.3062e-01],\n",
       "         [ 1.8721e+00,  2.0664e+00, -1.7314e+00],\n",
       "         [ 3.3223e+00,  3.5791e-01, -3.3203e+00],\n",
       "         [ 1.2627e+00,  1.9697e+00, -3.4531e+00],\n",
       "         [ 3.9082e+00,  1.4746e-01, -2.4316e+00],\n",
       "         [ 1.8086e+00,  6.7236e-01, -2.4072e-01],\n",
       "         [-3.2788e-01,  6.6357e-01,  9.5850e-01],\n",
       "         [ 2.1816e+00,  1.0439e+00, -1.4873e+00],\n",
       "         [ 3.6602e+00,  3.5596e-01, -3.1777e+00],\n",
       "         [ 1.1973e+00,  2.5898e+00,  8.1982e-01],\n",
       "         [ 1.8926e+00, -1.5186e+00, -1.7305e+00],\n",
       "         [ 2.6973e+00, -7.2656e-01, -1.1748e+00],\n",
       "         [ 2.7637e+00,  9.4482e-01, -7.8076e-01],\n",
       "         [-7.7686e-01,  6.5967e-01, -1.4294e-01],\n",
       "         [ 9.7852e-01, -5.7471e-01,  1.9268e+00],\n",
       "         [-6.1157e-02, -8.1152e-01, -5.5127e-01],\n",
       "         [ 2.2344e+00, -1.7322e-01, -7.5781e-01],\n",
       "         [ 3.1953e+00, -1.3984e+00, -2.3633e+00],\n",
       "         [ 1.4883e+00, -1.3018e+00,  3.4424e-01],\n",
       "         [ 2.9062e+00,  5.3955e-01, -1.8916e+00],\n",
       "         [ 1.9287e+00, -1.3350e+00, -2.1133e+00],\n",
       "         [ 1.7725e+00,  2.5610e-01, -1.9141e+00],\n",
       "         [ 8.5254e-01, -2.1348e+00, -1.2920e+00],\n",
       "         [ 1.3555e+00, -1.1289e+00,  5.7666e-01],\n",
       "         [ 2.7461e+00, -9.5996e-01, -1.1787e+00],\n",
       "         [ 1.2383e+00, -4.7388e-01, -1.6807e+00],\n",
       "         [ 2.1777e-01,  5.0146e-01,  1.0869e+00],\n",
       "         [ 1.6758e+00, -2.2266e-01,  2.3301e+00],\n",
       "         [-2.0020e+00, -1.0693e+00, -1.5225e+00],\n",
       "         [ 3.6328e+00, -1.6445e+00, -1.7607e+00],\n",
       "         [ 2.9180e+00, -1.1191e+00, -1.9229e+00],\n",
       "         [ 2.4277e+00, -4.4043e-01, -2.9961e+00],\n",
       "         [ 2.2754e+00,  9.0479e-01, -1.6533e+00],\n",
       "         [-2.6270e+00, -7.8955e-01, -5.4150e-01],\n",
       "         [ 3.9185e-01,  4.6094e-01, -7.8369e-01],\n",
       "         [ 6.0730e-02,  1.0635e+00, -1.9971e+00],\n",
       "         [ 3.5195e+00, -4.0918e-01, -1.6338e+00],\n",
       "         [ 1.8057e+00,  2.2168e+00,  1.5781e+00],\n",
       "         [ 2.7109e+00,  5.0244e-01, -1.2549e+00],\n",
       "         [ 2.3457e+00, -1.1016e+00,  1.0876e-01],\n",
       "         [-1.1865e+00, -1.7148e+00,  1.8779e+00],\n",
       "         [ 1.2412e+00, -4.5044e-01,  1.8955e+00],\n",
       "         [ 1.7910e+00, -9.9869e-03,  2.6816e+00],\n",
       "         [-8.9648e-01,  1.3184e+00, -9.0527e-01],\n",
       "         [ 1.6523e+00,  8.2764e-01,  1.9324e-01],\n",
       "         [ 1.6963e+00,  9.2590e-02, -1.7002e+00],\n",
       "         [ 2.3145e-01,  1.1660e+00, -3.5645e-01],\n",
       "         [ 5.1953e-01,  3.1567e-01, -6.2988e-01],\n",
       "         [ 1.9463e+00,  6.5869e-01, -1.6572e+00],\n",
       "         [ 4.4849e-01, -1.0859e+00,  1.2732e-01],\n",
       "         [ 1.8477e+00, -3.7476e-01,  1.5498e+00],\n",
       "         [ 2.8066e+00,  6.0791e-01,  1.8721e+00],\n",
       "         [-1.4541e+00, -7.5293e-01, -4.3188e-01],\n",
       "         [ 1.5615e+00, -1.2334e+00, -1.1699e+00]]], device='cuda:1',\n",
       "       dtype=torch.float16, grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [train_data['sentence'][0] , train_data['sentence'][5]]\n",
    "input_sentences = examples\n",
    "encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "model_inputs = encodeds.to('cuda')\n",
    "generated_ids = model(**model_inputs)\n",
    "\n",
    "#gen = OutputGeneration(model, tokenizer, id2label)\n",
    "#pl = gen._create_prediction_list(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5610, -3.7344, -0.5596],\n",
       "        [ 0.6680, -1.0869, -2.2871],\n",
       "        [-2.3242, -2.1172,  1.1387],\n",
       "        [ 2.2754,  1.2021, -1.8037],\n",
       "        [ 0.6587,  1.9824, -2.8145],\n",
       "        [ 2.4980,  0.3228, -3.0859],\n",
       "        [ 1.8848, -1.2773, -3.1465],\n",
       "        [ 1.1963, -0.3071, -0.9565],\n",
       "        [ 3.3926, -1.6904, -1.4746],\n",
       "        [ 1.3389,  0.5669,  1.6436],\n",
       "        [ 1.0381, -0.7432, -0.0577],\n",
       "        [ 1.0088,  0.2610, -0.8071],\n",
       "        [ 0.0112, -1.0391,  0.4905],\n",
       "        [-0.3005, -4.4414, -0.2683],\n",
       "        [-0.8750,  3.0000, -1.0010],\n",
       "        [-0.9966,  2.9434, -1.0312],\n",
       "        [-1.0449,  2.9062, -1.1006],\n",
       "        [-1.0439,  2.9473, -1.0967],\n",
       "        [-1.0664,  2.9902, -1.0869],\n",
       "        [-1.0947,  3.0039, -1.0439],\n",
       "        [-1.1230,  2.9941, -1.0244],\n",
       "        [-1.1230,  2.9629, -1.0596],\n",
       "        [-1.1006,  2.9355, -1.1035],\n",
       "        [-1.0820,  2.9238, -1.1416],\n",
       "        [-1.1025,  2.9941, -1.1328],\n",
       "        [-1.1318,  3.0547, -1.0879],\n",
       "        [-1.1777,  3.1250, -1.0508],\n",
       "        [-1.1592,  3.1738, -1.0088],\n",
       "        [-1.1445,  3.2227, -0.9897],\n",
       "        [-1.1055,  3.2500, -0.9780],\n",
       "        [-1.0938,  3.2051, -1.0000],\n",
       "        [-1.1113,  3.1270, -1.0332],\n",
       "        [-1.1270,  3.0762, -1.0322],\n",
       "        [-1.1348,  3.1152, -1.0049],\n",
       "        [-1.0938,  3.1445, -0.9775],\n",
       "        [-1.0547,  3.2051, -0.9453],\n",
       "        [-1.0361,  3.1855, -0.9468],\n",
       "        [-1.0674,  3.1113, -0.9863],\n",
       "        [-1.1328,  3.0332, -1.0439],\n",
       "        [-1.1436,  3.0352, -1.0439],\n",
       "        [-1.1152,  3.1133, -0.9873],\n",
       "        [-1.0400,  3.2598, -0.9111],\n",
       "        [-0.9966,  3.3438, -0.8735],\n",
       "        [-1.0088,  3.3496, -0.8818],\n",
       "        [-1.0371,  3.2715, -0.9180],\n",
       "        [-1.0879,  3.1855, -1.0117],\n",
       "        [-1.0996,  3.1445, -1.0625],\n",
       "        [-1.0205,  3.2305, -0.9888],\n",
       "        [-0.9424,  3.3242, -0.9121],\n",
       "        [-0.9414,  3.3574, -0.8682],\n",
       "        [-0.9893,  3.2930, -0.8975],\n",
       "        [-1.0928,  3.1738, -1.0156],\n",
       "        [-1.1445,  3.0938, -1.0762],\n",
       "        [-1.1045,  3.1035, -1.0879],\n",
       "        [-0.9878,  3.2227, -0.9917],\n",
       "        [-0.9238,  3.3438, -0.8726],\n",
       "        [-0.9282,  3.3984, -0.7764],\n",
       "        [-0.9888,  3.3418, -0.7896],\n",
       "        [-1.0752,  3.2031, -0.8677],\n",
       "        [-1.1396,  3.1074, -0.9609],\n",
       "        [-1.1025,  3.1348, -0.9644],\n",
       "        [-1.0498,  3.1953, -0.9463],\n",
       "        [-1.0117,  3.2559, -0.8765],\n",
       "        [-1.0303,  3.2578, -0.8433],\n",
       "        [-1.0723,  3.2031, -0.8652],\n",
       "        [-1.0986,  3.1602, -0.8911],\n",
       "        [-1.0801,  3.1445, -0.8950],\n",
       "        [-1.0312,  3.1934, -0.8818],\n",
       "        [-0.9912,  3.2695, -0.8394],\n",
       "        [-0.9746,  3.3281, -0.8022],\n",
       "        [-1.0068,  3.3242, -0.8057],\n",
       "        [-1.0332,  3.2793, -0.8330],\n",
       "        [-1.0732,  3.2129, -0.8838],\n",
       "        [-1.0996,  3.1094, -0.9546],\n",
       "        [-1.1211,  3.0098, -1.0254],\n",
       "        [-1.1475,  2.9336, -1.0576],\n",
       "        [-1.1748,  2.9141, -1.0596],\n",
       "        [-1.1826,  2.9668, -1.0293]], device='cuda:1', dtype=torch.float16,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids.logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their child acquired walking at the age of 14 months.\n",
      "n words in sentence: 10\n",
      "len_ sentence: 53\n",
      "n tokens with labels: 14\n",
      "n  created labels: 78\n",
      "Pertinent laboratory studies included a hemoglobin level of 10 g/dL, platelet count was normal, blood urea of 1,2 g/l (0,18-0,45 g/L), and a creatinine level of 68 mg/L (7-13 mg/L).\n",
      "n words in sentence: 30\n",
      "len_ sentence: 181\n",
      "n tokens with labels: 78\n",
      "n  created labels: 78\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate([0,5]):\n",
    "    print((train_data[s]['sentence']))\n",
    "    print(f\"n words in sentence: {len(train_data[s]['sentence'].split())}\")\n",
    "    print(f\"len_ sentence: {len(train_data[s]['sentence'])}\")\n",
    "    print(f\"n tokens with labels: {len(train_data[s]['labels'])}\")\n",
    "    print(f\"n  created labels: {len(generated_ids['logits'][i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'LlamaForTokenClassification' is not supported for token-classification. Supported models are ['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BioGptForTokenClassification', 'BloomForTokenClassification', 'BrosForTokenClassification', 'CamembertForTokenClassification', 'CanineForTokenClassification', 'ConvBertForTokenClassification', 'Data2VecTextForTokenClassification', 'DebertaForTokenClassification', 'DebertaV2ForTokenClassification', 'DistilBertForTokenClassification', 'ElectraForTokenClassification', 'ErnieForTokenClassification', 'ErnieMForTokenClassification', 'EsmForTokenClassification', 'FalconForTokenClassification', 'FlaubertForTokenClassification', 'FNetForTokenClassification', 'FunnelForTokenClassification', 'GPT2ForTokenClassification', 'GPT2ForTokenClassification', 'GPTBigCodeForTokenClassification', 'GPTNeoForTokenClassification', 'GPTNeoXForTokenClassification', 'IBertForTokenClassification', 'LayoutLMForTokenClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv3ForTokenClassification', 'LiltForTokenClassification', 'LongformerForTokenClassification', 'LukeForTokenClassification', 'MarkupLMForTokenClassification', 'MegaForTokenClassification', 'MegatronBertForTokenClassification', 'MobileBertForTokenClassification', 'MPNetForTokenClassification', 'MptForTokenClassification', 'MraForTokenClassification', 'MT5ForTokenClassification', 'NezhaForTokenClassification', 'NystromformerForTokenClassification', 'PhiForTokenClassification', 'QDQBertForTokenClassification', 'RemBertForTokenClassification', 'RobertaForTokenClassification', 'RobertaPreLayerNormForTokenClassification', 'RoCBertForTokenClassification', 'RoFormerForTokenClassification', 'SqueezeBertForTokenClassification', 'T5ForTokenClassification', 'UMT5ForTokenClassification', 'XLMForTokenClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaXLForTokenClassification', 'XLNetForTokenClassification', 'XmodForTokenClassification', 'YosoForTokenClassification'].\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (14) must match the existing size (4096) at non-singleton dimension 2.  Target sizes: [1, 32, 14, 14].  Tensor sizes: [1, 1, 4096, 14]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m token_classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[1;32m      5\u001b[0m                             tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, \n\u001b[1;32m      6\u001b[0m                             aggregation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtoken_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m l \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m tqdm(token_classifier(KeyDataset(train_data\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m24\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m))):\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:248\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset_mapping:\n\u001b[1;32m    246\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m offset_mapping\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1234\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1149\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1148\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1149\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:285\u001b[0m, in \u001b[0;36mTokenClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     logits \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m: logits,\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecial_tokens_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: special_tokens_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[1;32m    295\u001b[0m }\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/billm/modeling_llama.py:269\u001b[0m, in \u001b[0;36mLlamaForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 269\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    282\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/billm/modeling_llama.py:132\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    121\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    122\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    123\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m         cache_position,\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbi_attention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_bidirectional\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:741\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/LS-LLaMA-E3C/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:671\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    667\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# In case we are not compiling, we may set `causal_mask` to None, which is required to dispatch to SDPA's Flash Attention 2 backend, rather\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# relying on the `is_causal` argument.\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    681\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (14) must match the existing size (4096) at non-singleton dimension 2.  Target sizes: [1, 32, 14, 14].  Tensor sizes: [1, 1, 4096, 14]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\", model=model, \n",
    "                            tokenizer=tokenizer, \n",
    "                            aggregation_strategy=\"simple\", batch_size=12)\n",
    "token_classifier(train_data[0]['sentence'])\n",
    "l = []\n",
    "for out in tqdm(token_classifier(KeyDataset(train_data.select(range(24)), \"sentence\"))):\n",
    "    l.append(out)\n",
    "\n",
    "tmp = train_data.select(range(24)).add_column('model_output', l)\n",
    "tmp[6]['model_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Their', 'child', 'acquired', 'walking', 'at', 'the', 'age', 'of', '14', 'months.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁Their',\n",
       " '▁child',\n",
       " '▁acquired',\n",
       " '▁walking',\n",
       " '▁at',\n",
       " '▁the',\n",
       " '▁age',\n",
       " '▁of',\n",
       " '▁',\n",
       " '1',\n",
       " '4',\n",
       " '▁months',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data[0]['tokens'])\n",
    "example = train_data[0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'LlamaForTokenClassification' is not supported for ner. Supported models are ['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BioGptForTokenClassification', 'BloomForTokenClassification', 'BrosForTokenClassification', 'CamembertForTokenClassification', 'CanineForTokenClassification', 'ConvBertForTokenClassification', 'Data2VecTextForTokenClassification', 'DebertaForTokenClassification', 'DebertaV2ForTokenClassification', 'DistilBertForTokenClassification', 'ElectraForTokenClassification', 'ErnieForTokenClassification', 'ErnieMForTokenClassification', 'EsmForTokenClassification', 'FalconForTokenClassification', 'FlaubertForTokenClassification', 'FNetForTokenClassification', 'FunnelForTokenClassification', 'GPT2ForTokenClassification', 'GPT2ForTokenClassification', 'GPTBigCodeForTokenClassification', 'GPTNeoForTokenClassification', 'GPTNeoXForTokenClassification', 'IBertForTokenClassification', 'LayoutLMForTokenClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv3ForTokenClassification', 'LiltForTokenClassification', 'LongformerForTokenClassification', 'LukeForTokenClassification', 'MarkupLMForTokenClassification', 'MegaForTokenClassification', 'MegatronBertForTokenClassification', 'MobileBertForTokenClassification', 'MPNetForTokenClassification', 'MptForTokenClassification', 'MraForTokenClassification', 'MT5ForTokenClassification', 'NezhaForTokenClassification', 'NystromformerForTokenClassification', 'PhiForTokenClassification', 'QDQBertForTokenClassification', 'RemBertForTokenClassification', 'RobertaForTokenClassification', 'RobertaPreLayerNormForTokenClassification', 'RoCBertForTokenClassification', 'RoFormerForTokenClassification', 'SqueezeBertForTokenClassification', 'T5ForTokenClassification', 'UMT5ForTokenClassification', 'XLMForTokenClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaXLForTokenClassification', 'XLNetForTokenClassification', 'XmodForTokenClassification', 'YosoForTokenClassification'].\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "24it [00:04,  4.83it/s]                      \n",
      "Flattening the indices: 100%|██████████| 24/24 [00:00<00:00, 3808.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 24,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.657,\n",
       "  'start': 7,\n",
       "  'word': 'assessment found'},\n",
       " {'end': 38,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.794,\n",
       "  'start': 32,\n",
       "  'word': 'score'},\n",
       " {'end': 44,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.6616,\n",
       "  'start': 40,\n",
       "  'word': 'GCS)'},\n",
       " {'end': 48, 'entity_group': 'B', 'score': 0.6094, 'start': 47, 'word': ''},\n",
       " {'end': 52, 'entity_group': 'I', 'score': 0.585, 'start': 51, 'word': '1'},\n",
       " {'end': 53, 'entity_group': 'B', 'score': 0.572, 'start': 52, 'word': '5'},\n",
       " {'end': 66,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.824,\n",
       "  'start': 55,\n",
       "  'word': 'eye opening'},\n",
       " {'end': 70, 'entity_group': 'B', 'score': 0.708, 'start': 69, 'word': ''},\n",
       " {'end': 72, 'entity_group': 'B', 'score': 0.4004, 'start': 71, 'word': ','},\n",
       " {'end': 88,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.628,\n",
       "  'start': 76,\n",
       "  'word': 'bal response'},\n",
       " {'end': 93, 'entity_group': 'B', 'score': 0.6816, 'start': 91, 'word': '2'},\n",
       " {'end': 100,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.623,\n",
       "  'start': 94,\n",
       "  'word': 'motor'},\n",
       " {'end': 114, 'entity_group': 'B', 'score': 0.7153, 'start': 112, 'word': '5'},\n",
       " {'end': 135,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.6855,\n",
       "  'start': 132,\n",
       "  'word': 're'},\n",
       " {'end': 148,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.829,\n",
       "  'start': 141,\n",
       "  'word': 'pupils'},\n",
       " {'end': 169,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8335,\n",
       "  'start': 157,\n",
       "  'word': 'feeling-mot'},\n",
       " {'end': 171,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.6196,\n",
       "  'start': 169,\n",
       "  'word': 'or'},\n",
       " {'end': 179,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.65,\n",
       "  'start': 171,\n",
       "  'word': 'deficit'},\n",
       " {'end': 192,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.7686,\n",
       "  'start': 187,\n",
       "  'word': 'oste'},\n",
       " {'end': 209,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.6143,\n",
       "  'start': 194,\n",
       "  'word': 'endinous reflex'},\n",
       " {'end': 211,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.6772,\n",
       "  'start': 209,\n",
       "  'word': 'es'},\n",
       " {'end': 221,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.5474,\n",
       "  'start': 212,\n",
       "  'word': 'slightly'},\n",
       " {'end': 225,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.6074,\n",
       "  'start': 221,\n",
       "  'word': 'pol'},\n",
       " {'end': 231,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.6665,\n",
       "  'start': 225,\n",
       "  'word': 'ypneic'},\n",
       " {'end': 235, 'entity_group': 'B', 'score': 0.9023, 'start': 234, 'word': ''},\n",
       " {'end': 245, 'entity_group': 'I', 'score': 0.6304, 'start': 244, 'word': '/'},\n",
       " {'end': 248,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.498,\n",
       "  'start': 245,\n",
       "  'word': 'min'},\n",
       " {'end': 251, 'entity_group': 'I', 'score': 0.346, 'start': 249, 'word': 'p'},\n",
       " {'end': 254,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8604,\n",
       "  'start': 251,\n",
       "  'word': 'uls'},\n",
       " {'end': 258, 'entity_group': 'B', 'score': 0.4985, 'start': 256, 'word': 'o'},\n",
       " {'end': 282,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8027,\n",
       "  'start': 263,\n",
       "  'word': 'saturation (SpO 2)'},\n",
       " {'end': 286, 'entity_group': 'B', 'score': 0.6333, 'start': 285, 'word': ''},\n",
       " {'end': 304,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.61,\n",
       "  'start': 292,\n",
       "  'word': 'ambient air'},\n",
       " {'end': 308, 'entity_group': 'B', 'score': 0.737, 'start': 305, 'word': 'he'},\n",
       " {'end': 318,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.867,\n",
       "  'start': 312,\n",
       "  'word': 'tachy'},\n",
       " {'end': 324,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.7837,\n",
       "  'start': 322,\n",
       "  'word': 'ic'},\n",
       " {'end': 328, 'entity_group': 'B', 'score': 0.5366, 'start': 327, 'word': ''},\n",
       " {'end': 335, 'entity_group': 'B', 'score': 0.499, 'start': 333, 'word': 'pm'},\n",
       " {'end': 352,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8047,\n",
       "  'start': 339,\n",
       "  'word': 'hypertensive'},\n",
       " {'end': 356, 'entity_group': 'B', 'score': 0.4436, 'start': 355, 'word': ''},\n",
       " {'end': 360, 'entity_group': 'I', 'score': 0.843, 'start': 359, 'word': '/'},\n",
       " {'end': 366,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.684,\n",
       "  'start': 362,\n",
       "  'word': 'mmH'},\n",
       " {'end': 367, 'entity_group': 'B', 'score': 0.419, 'start': 366, 'word': 'g'},\n",
       " {'end': 379,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.745,\n",
       "  'start': 372,\n",
       "  'word': 'capill'},\n",
       " {'end': 393,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.541,\n",
       "  'start': 388,\n",
       "  'word': 'gluc'},\n",
       " {'end': 396,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.617,\n",
       "  'start': 393,\n",
       "  'word': 'ose'},\n",
       " {'end': 400, 'entity_group': 'B', 'score': 0.7466, 'start': 399, 'word': ''},\n",
       " {'end': 402, 'entity_group': 'I', 'score': 0.541, 'start': 401, 'word': '.'},\n",
       " {'end': 407,\n",
       "  'entity_group': 'I',\n",
       "  'score': 0.7344,\n",
       "  'start': 404,\n",
       "  'word': 'g/'},\n",
       " {'end': 408, 'entity_group': 'B', 'score': 0.5786, 'start': 407, 'word': 'L'},\n",
       " {'end': 415, 'entity_group': 'B', 'score': 0.676, 'start': 413, 'word': 'g'},\n",
       " {'end': 424,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.673,\n",
       "  'start': 417,\n",
       "  'word': 'cosuria'},\n",
       " {'end': 434,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.5312,\n",
       "  'start': 431,\n",
       "  'word': 'ur'},\n",
       " {'end': 451,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.7393,\n",
       "  'start': 443,\n",
       "  'word': 'ick test'},\n",
       " {'end': 469,\n",
       "  'entity_group': 'B',\n",
       "  'score': 0.8726,\n",
       "  'start': 459,\n",
       "  'word': 'ketonuria'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "token_classifier = pipeline(\"ner\", model=model, \n",
    "                            tokenizer=tokenizer, \n",
    "                            aggregation_strategy=\"simple\", batch_size=12)\n",
    "\n",
    "\n",
    "#token_classifier(train_data[0]['tokens'])\n",
    "l = []\n",
    "for out in tqdm(token_classifier(KeyDataset(train_data.select(range(24)), \"sentence\"))):\n",
    "    l.append(out)\n",
    "\n",
    "tmp = train_data.select(range(24)).add_column('model_output', l)\n",
    "tmp[6]['model_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import evaluate\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "data = load_dataset(\"csv\", data_files=\"data/evaluation/train_data_LS_Mistral-7B-v0.1_adapters_en.layer1_NoQuant_16_32_0.01_2_0.0002.csv\")\n",
    "def helper(example):\n",
    "    example['model_output'] = ast.literal_eval(example['model_output'].replace('\\n', ','))\n",
    "    return example\n",
    "data = data.map(lambda x: helper(x))\n",
    "\n",
    "def compute_metrics(logits, labels):\n",
    "    model_output_logits = logits.cpu().detach().float().numpy()    \n",
    "    predictions = np.argmax(model_output_logits, axis=1)\n",
    "    print(predictions)\n",
    "    print(type(predictions))\n",
    "    print(type(labels))\n",
    "    lista = []\n",
    "    for i in range(len(labels)):\n",
    "        print('pred: ', predictions[i], 'label: ', labels[i])\n",
    "        if labels[i] != -100:\n",
    "         lista.append(label_list[predictions[i]])\n",
    "    print('lista: ', lista)\n",
    "\n",
    "    print( [label_list[prediction] for i, prediction in enumerate(predictions) if labels[i] != -100 ] )\n",
    "\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"soverall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B', 'I']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'O',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'I',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'I',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _create_prediction_list(self, model_output):\n",
    "        model_output_logits = model_output.logits.cpu().detach().float().numpy()\n",
    "        preds = np.argmax(model_output_logits, axis=2)\n",
    "        preds_list = []\n",
    "        for pred in preds:\n",
    "            preds_list.append([self.id2label[label] for label in pred])\n",
    "        return preds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "generated_ids['logits'][0]\n",
    "print(type(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "53\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0]['labels']))\n",
    "print(len(train_data[0]['sentence']))\n",
    "print(len(generated_ids['logits'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'entities', 'original_text', 'original_id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = train_data.select(range(2))\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "53\n",
      "Their child acquired walking at the age of 14 months.\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 2, 1, 1, 0, 0, 0, 0, 0, -100, -100, 0, -100]\n",
      "[-100, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'B': 1, 'I': 2}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((examples[0]['ner_tags']))\n",
    "print(len(examples[0]['sentence']))\n",
    "print((examples[0]['sentence']))\n",
    "print((examples[0]['labels']))\n",
    "#print(len(examples['logits'][0]))\n",
    "print(labels[0])\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1520/1520 [00:00<00:00, 13777.85 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET_CHEKPOINT) #download_mode=\"force_redownload\"\n",
    "dataset = dataset[TRAIN_LAYER]\n",
    "dataset = dataset.shuffle(seed=1234)  \n",
    "dataset_format_converter = DatasetFormatConverter(dataset)\n",
    "dataset_format_converter.apply()\n",
    "ds = dataset_format_converter.dataset\n",
    "label2id = dataset_format_converter.label2id\n",
    "id2label = dataset_format_converter.get_id2label()\n",
    "label_list = dataset_format_converter.get_label_list()\n",
    "dataset = ds.map(lambda x: tokenize_and_align_labels(x), batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentece:  Their child acquired walking at the age of 14 months. \n",
      "labels:  [-100, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "sentece:  An abdominal ultrasound examination was reported as normal. \n",
      "labels:  [-100, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2]\n",
      "sentece:  Her blood pressure was 100/70 mmHg with a pulse rate of 98 beats/min, respiratory rate about 16/min and oral temperature of 37°C. \n",
      "labels:  [-100, 0, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2]\n",
      "sentece:  Emergency neck computed tomography angiography showed a contrast-enhanced abscess cavity posterior to the left retropharyngeal space, and a low-density area surrounded by an area without contrast enhancement in the posterior neck. \n",
      "labels:  [-100, 0, 0, 1, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2]\n",
      "sentece:  The mitotic rate was extremely high (19 mitosis/10 high power field), and atypical mitotic figures were also present. \n",
      "labels:  [-100, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "sentece:  Pertinent laboratory studies included a hemoglobin level of 10 g/dL, platelet count was normal, blood urea of 1,2 g/l (0,18-0,45 g/L), and a creatinine level of 68 mg/L (7-13 mg/L). \n",
      "labels:  [-100, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "sentece:  Initial assessment found Glasgow score (GCS) of 12/15 (eye opening at 5, verbal response at 2, motor response at 5), symmetrical and reactive pupils, without feeling-motor deficit, normal osteotendinous reflexes, slightly polypneic at 24 cycles/min, pulsed oxygen saturation (SpO 2) at 97% in ambient air, he was tachycardic at 115 bpm and hypertensive at 160/95 mmHg, his capillary blood glucose at 2.24 g/L, and glycosuria on the urine dipstick test without ketonuria. \n",
      "labels:  [-100, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 1, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2]\n",
      "sentece:  Lab results showed haemoglobin 10.9 g/dl, packed cell volume 35%, and positive malaria parasites. \n",
      "labels:  [-100, 0, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = preprocessor.split_layer_into_train_val_test_(dataset, TRAIN_LAYER)\n",
    "for i in range(8):\n",
    "    print('sentece: ', train_data[i]['sentence'], '\\nlabels: ', train_data[i]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[1, 1094, 534, 2920, 1475, 9271, 12423, 687, 20976, 403, 5745, 390, 4123, 28723], [1, 21127, 277, 4475, 8289, 302, 272, 16594, 28765, 6642, 369, 23096, 8894, 654, 5278, 354, 264, 9194, 302, 1581, 6752, 1716, 404, 325, 5072, 28731, 325, 5072, 28770, 28781, 28725, 8204, 28740, 28774, 28725, 8204, 28740, 28734, 28725, 8204, 28750, 28750, 304, 19966, 5278, 354, 8204, 28781, 28782, 28731, 8735, 288, 334, 7016, 9237, 3000, 678, 628, 305, 1082, 721, 806, 23096, 297, 2088, 434, 352, 28723]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2], [-100, 0, 1, 2, 2, 0, 1, 2, 2, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2]]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, words_label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        label_ids = []\n",
    "        for k, word_idx in enumerate(word_ids): \n",
    "            same_word_as_previous  = False if (word_idx != word_ids[k-1] or k==0) else True\n",
    "            if word_idx is None:\n",
    "                token_label = -100\n",
    "            elif words_label[word_idx] == label2id['O']:\n",
    "                token_label = label2id['O']\n",
    "            elif same_word_as_previous:\n",
    "                token_label = label2id['I']\n",
    "            elif not same_word_as_previous:\n",
    "                token_label = words_label[word_idx]\n",
    "            label_ids.append(token_label)\n",
    "            # if word_idx is not None:#  and k>12:\n",
    "            #     print(\"word_label: \", words_label[word_idx])\n",
    "            # print(tokenizer.decode(tokenized_inputs[i].ids[k]), \": \",word_idx,  \"\\nassigned_token_label:\",  label_ids[k], '\\n')\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "tokenize_and_align_labels(ds.select(range(2, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.shape=torch.Size([2, 76, 4096])\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0 2 1 1 0 0 1 0 0 1 0\n",
      " 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  2 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  2 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  1 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n",
      "pred:  0 label:  -100\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 76 is out of bounds for axis 0 with size 76",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#gen = OutputGeneration(model, tokenizer, id2label)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#pl = gen._create_prediction_list(generated_ids)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(logits, labels)\u001b[0m\n\u001b[1;32m     17\u001b[0m lista \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels)):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel: \u001b[39m\u001b[38;5;124m'\u001b[39m, labels[i])\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels[i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:\n\u001b[1;32m     21\u001b[0m      lista\u001b[38;5;241m.\u001b[39mappend(label_list[predictions[i]])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 76 is out of bounds for axis 0 with size 76"
     ]
    }
   ],
   "source": [
    "# examples = [train_data['sentence'][0] , train_data['sentence'][5]]\n",
    "# input_sentences = examples\n",
    "# encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "# model_inputs = encodeds.to('cuda')\n",
    "# generated_ids = model(**model_inputs)\n",
    "# model_output_logits = generated_ids.logits.cpu().detach().float().numpy()\n",
    "examples = [train_data['sentence'][0], train_data['sentence'][5]]\n",
    "input_sentences = examples\n",
    "encodeds = tokenizer(input_sentences, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "model_inputs = encodeds.to('cuda')\n",
    "generated_ids = model(**model_inputs)\n",
    "#gen = OutputGeneration(model, tokenizer, id2label)\n",
    "#pl = gen._create_prediction_list(generated_ids)\n",
    "compute_metrics(generated_ids['logits'][0],   train_data[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -100,\n",
       " -100,\n",
       " 0,\n",
       " -100]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence', 'entities', 'original_text', 'original_id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'B', 'O', 'B', 'O', 'B']\n",
      "['An', 'abdominal', 'ultrasound', 'examination', 'was', 'reported', 'as', 'normal.']\n",
      "{'input_ids': [1, 1094, 534, 2920, 1475, 9271, 12423, 687, 20976, 403, 5745, 390, 4123, 28723], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "<s> An abdominal ultrasound examination was reported as normal.\n",
      "[{'end': 8, 'entity_group': 'B', 'score': 0.648, 'start': 5, 'word': 'dom'}, {'end': 15, 'entity_group': 'B', 'score': 0.928, 'start': 12, 'word': 'ul'}, {'end': 35, 'entity_group': 'B', 'score': 0.9463, 'start': 23, 'word': 'examination'}, {'end': 48, 'entity_group': 'B', 'score': 0.8286, 'start': 39, 'word': 'reported'}, {'end': 58, 'entity_group': 'B', 'score': 0.6094, 'start': 51, 'word': 'normal'}]\n"
     ]
    }
   ],
   "source": [
    "example = tmp[1]\n",
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "print(labels)\n",
    "print(example['tokens'])\n",
    "print(tokenizer(example['sentence']))\n",
    "print(tokenizer.decode(tokenizer(example['sentence'])['input_ids']))\n",
    "print(example['model_output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
