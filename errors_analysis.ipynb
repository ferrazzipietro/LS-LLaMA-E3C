{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from utils import Evaluator\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD BEST MODEL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'entities', 'original_text', 'original_id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels', 'predictions', 'ground_truth_labels'],\n",
       "    num_rows: 681\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = \"ferrazzipietro/LS_Llama-2-7b-hf_adapters_en.layer1_NoQuant_16_32_0.05_2_0.0002_3EpochsLast\"\n",
    "data = load_dataset(checkpoint, split=\"test\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "class Evaluator():\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        # self.evaluation_table = pd.DataFrame(columns=['TP', 'FP', 'FN'])\n",
    "        self.evaluation_table = {}\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "     \n",
    "    def _compare_prediction_label_one_example_token_by_token(self, example) -> (int, int, int):\n",
    "        \"\"\"\n",
    "        Compare the prediction with the label of one sentence.\n",
    "        Args:\n",
    "        predictions (list[str]): the list of the predicted labels\n",
    "        labels (list[str]): the list of the true labels\n",
    "        return:\n",
    "        int: the number of false positives\n",
    "        int: the number of false negatives\n",
    "        int: the number of true positives\n",
    "        \"\"\"\n",
    "        predictions = example['predictions']\n",
    "        labels = example['ground_truth_labels']\n",
    "        TP, FP, FN = 0, 0, 0\n",
    "        # labels = ['O'] + labels[:-1] \n",
    "        for pred, lab in zip(predictions, labels):\n",
    "            TP = TP + (1 if pred == lab and lab!='O' else 0)\n",
    "            FP = FP + (1 if pred != lab and lab =='O' else 0)\n",
    "            FN = FN + (1 if pred != lab and pred =='O' else 0)\n",
    "        try:\n",
    "            precision = TP / (TP + FP)\n",
    "        except:\n",
    "            precision = 0\n",
    "        try:\n",
    "            recall = TP / (TP + FN)\n",
    "        except:\n",
    "            recall = 0\n",
    "        try:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        except:\n",
    "            f1 = 0\n",
    "        \n",
    "        example['TP'] = TP\n",
    "        example['FP'] = FP\n",
    "        example['FN'] = FN\n",
    "        example['precision'] = precision\n",
    "        example['recall'] = recall\n",
    "        example['f1'] = f1\n",
    "        return example\n",
    "    \n",
    "    def extract_FP_FN_TP_token_by_token(self) -> (int, int, int):\n",
    "        \"\"\"\n",
    "        Extract the number of False Positives, False Negatives and True Positives from the model output and the ground truth.\n",
    "        Args:\n",
    "        predictions (list[str]): the list of the predicted labels\n",
    "        labels (list[str]): the list of the true labels\n",
    "        return:\n",
    "        int: the number of false positives\n",
    "        int: the number of false negatives\n",
    "        int: the number of true positives\n",
    "        \"\"\"\n",
    "        self.data = self.data.map(self._compare_prediction_label_one_example_token_by_token, batched=False)\n",
    "\n",
    "\n",
    "    def create_evaluation_table(self):\n",
    "        tmp_data = pd.DataFrame(self.data)\n",
    "        TP = tmp_data['TP'].sum()\n",
    "        FP = tmp_data['FP'].sum()\n",
    "        FN = tmp_data['FN'].sum()\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        self.evaluation_table = {'TP': TP, 'FP': FP, 'FN': FN,\n",
    "                                  'precision':precision, 'recall':recall, 'f1':f1}\n",
    "        \n",
    "        return self.evaluation_table\n",
    "    \n",
    "    def get_examples_based_on_metric(self, metric, threshold, lower=False):\n",
    "        \"\"\"\n",
    "        Select the examples based on the metric and the threshold.\n",
    "        Args:\n",
    "        metric (str): the metric to consider\n",
    "        threshold (float): the threshold to consider\n",
    "        return:\n",
    "        list: the list of examples that satisfy the condition\n",
    "        \"\"\"\n",
    "        if lower:\n",
    "            out = [example for example in self.data if example[metric] < threshold]\n",
    "        else:\n",
    "            out = [example for example in self.data if example[metric] > threshold]\n",
    "        return(Dataset.from_pandas(pd.DataFrame(out)))\n",
    "    \n",
    "    def format_data(self, data):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for example in data:\n",
    "            sentence_pred = example['predictions']\n",
    "            sentence = example['sentence']\n",
    "            tokenized_input = self.tokenizer(sentence, add_special_tokens=False)\n",
    "            tokens = self.tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "            print([(t,p, ground_truth_label) for t, p, ground_truth_label in zip(tokens, sentence_pred, example['ground_truth_labels'])])\n",
    "        return data\n",
    "\n",
    "    def print_disallined_Is(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        counter = 0\n",
    "        tot_tokens = 0\n",
    "        print('(token, prediction, ground_truth_label)')\n",
    "        self.disallined_df = pd.DataFrame(columns=['id', 'token', 'prediction', 'ground_truth_label'])\n",
    "        id_sentence = 0\n",
    "        for example in self.data:\n",
    "            sentence_pred = example['predictions']\n",
    "            sentence = example['sentence']\n",
    "            previous = '' \n",
    "            appened = False\n",
    "            for token in sentence_pred:\n",
    "                if token=='I' and previous=='O':\n",
    "                    appened = True\n",
    "                    counter+=1\n",
    "                    # print('token:', token, 'previous:', previous, 'position:', i, 'sentence:', sentence_pred)\n",
    "                previous = token\n",
    "                tot_tokens += 1\n",
    "            if appened:\n",
    "                tokenized_input = self.tokenizer(sentence, add_special_tokens=False)\n",
    "                tokens = self.tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "                self.disallined_df = pd.concat([self.disallined_df, pd.DataFrame([{'id': id_sentence,'token':t, 'prediction': p, 'ground_truth_label': ground_truth_label} for t, p, ground_truth_label in zip(tokens, sentence_pred, example['ground_truth_labels'])])])\n",
    "                print([(t,p, ground_truth_label) for t, p, ground_truth_label in zip(tokens, sentence_pred, example['ground_truth_labels'])])\n",
    "                id_sentence += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 7085, 'FP': 1438, 'FN': 3409, 'precision': 0.8312800657045641, 'recall': 0.6751477034495903, 'f1': 0.7451227848766893}\n"
     ]
    }
   ],
   "source": [
    "eval = Evaluator(data, tokenizer)\n",
    "eval.extract_FP_FN_TP_token_by_token()\n",
    "eval.create_evaluation_table()\n",
    "print(eval.evaluation_table)\n",
    "#eval.print_disallined_Is()\n",
    "#eval.disallined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('▁In', 'O', 'O'), ('▁mut', 'O', 'O'), ('ated', 'I', 'O'), ('▁SER', 'O', 'O'), ('P', 'I', 'O'), ('IN', 'I', 'O'), ('C', 'O', 'O'), ('1', 'O', 'O'), ('▁protein', 'O', 'O'), ('▁a', 'O', 'O'), ('▁new', 'O', 'O'), ('▁N', 'O', 'O'), ('-', 'O', 'O'), ('link', 'O', 'O'), ('ed', 'I', 'O'), ('▁g', 'O', 'O'), ('ly', 'O', 'O'), ('cos', 'O', 'O'), ('yl', 'O', 'O'), ('ation', 'O', 'O'), ('▁site', 'O', 'O'), ('▁is', 'O', 'O'), ('▁formed', 'O', 'B'), (',', 'O', 'I'), ('▁however', 'O', 'O'), (',', 'O', 'O'), ('▁it', 'O', 'O'), ('▁is', 'O', 'O'), ('▁unclear', 'O', 'B'), ('▁if', 'O', 'O'), ('▁the', 'O', 'O'), ('▁g', 'O', 'O'), ('ly', 'O', 'O'), ('cos', 'O', 'O'), ('yl', 'O', 'O'), ('ation', 'O', 'O'), ('▁at', 'O', 'O'), ('▁', 'B', 'O'), ('2', 'I', 'O'), ('1', 'I', 'O'), ('9', 'O', 'O'), ('-', 'I', 'O'), ('2', 'I', 'O'), ('2', 'I', 'O'), ('1', 'O', 'O'), ('▁site', 'O', 'O'), ('▁is', 'O', 'O'), ('▁possible', 'O', 'O'), ('.', 'O', 'O')]\n",
      "[('▁Before', 'O', 'O'), ('▁starting', 'O', 'B'), ('▁cort', 'O', 'B'), ('ic', 'O', 'I'), ('ost', 'O', 'I'), ('ero', 'O', 'I'), ('ids', 'O', 'I'), (',', 'O', 'I'), ('▁we', 'O', 'B'), ('▁analyz', 'O', 'B'), ('ed', 'O', 'I'), ('▁electro', 'O', 'B'), ('ly', 'O', 'I'), ('tes', 'O', 'I'), ('.', 'O', 'I')]\n",
      "[('▁Her', 'O', 'O'), ('▁initial', 'O', 'O'), ('▁men', 'B', 'O'), ('ar', 'I', 'O'), ('che', 'O', 'O'), ('▁was', 'O', 'O'), ('▁at', 'O', 'O'), ('▁the', 'O', 'O'), ('▁age', 'O', 'O'), ('▁of', 'O', 'O'), ('▁', 'O', 'O'), ('1', 'O', 'O'), ('4', 'O', 'O'), ('▁years', 'O', 'O'), ('▁and', 'O', 'O'), ('▁it', 'O', 'O'), ('▁is', 'O', 'O'), ('▁in', 'O', 'O'), ('▁accord', 'O', 'O'), ('ance', 'O', 'O'), ('▁with', 'O', 'O'), ('▁the', 'O', 'O'), ('▁normal', 'O', 'O'), ('▁growth', 'O', 'O'), ('▁of', 'O', 'O'), ('▁a', 'O', 'O'), ('▁child', 'O', 'O'), ('▁at', 'O', 'O'), ('▁her', 'O', 'O'), ('▁age', 'O', 'O'), ('.', 'O', 'O')]\n",
      "[('▁No', 'O', 'O'), ('▁concerns', 'O', 'B'), ('▁were', 'O', 'O'), ('▁present', 'O', 'O'), ('▁in', 'O', 'O'), ('▁the', 'O', 'O'), ('▁ne', 'B', 'O'), ('on', 'I', 'O'), ('atal', 'I', 'O'), ('▁period', 'I', 'O'), ('.', 'I', 'O')]\n",
      "[('▁The', 'O', 'O'), ('▁exc', 'O', 'O'), ('ised', 'O', 'O'), ('▁mass', 'O', 'B'), ('▁was', 'O', 'O'), ('▁sent', 'O', 'B'), ('▁to', 'O', 'O'), ('▁path', 'O', 'O'), ('ology', 'O', 'O'), ('▁labor', 'O', 'O'), ('atory', 'O', 'O'), ('.', 'O', 'O')]\n",
      "[('▁The', 'O', 'O'), ('▁patient', 'I', 'B'), ('▁was', 'O', 'O'), ('▁immediately', 'O', 'O'), ('▁brought', 'B', 'O'), ('▁to', 'O', 'O'), ('▁the', 'O', 'O'), ('▁operating', 'O', 'O'), ('▁theatre', 'O', 'B'), ('.', 'O', 'I')]\n",
      "[('▁Investig', 'O', 'O'), ('ations', 'O', 'O'), ('▁that', 'O', 'O'), ('▁were', 'O', 'O'), ('▁used', 'O', 'O'), ('▁are', 'O', 'O'), ('▁ul', 'O', 'B'), ('tr', 'O', 'I'), ('ason', 'O', 'I'), ('ography', 'O', 'I'), (',', 'O', 'I'), ('▁thor', 'O', 'O'), ('ax', 'O', 'O'), ('▁X', 'O', 'B'), ('-', 'O', 'I'), ('ray', 'O', 'I'), ('▁and', 'O', 'O'), ('▁CT', 'O', 'O'), ('▁Sc', 'O', 'O'), ('an', 'O', 'O'), ('▁Head', 'O', 'B'), ('.', 'O', 'I')]\n",
      "[('▁Pro', 'O', 'O'), ('per', 'O', 'O'), ('▁ble', 'B', 'O'), ('ed', 'I', 'O'), ('ers', 'I', 'O'), ('▁were', 'O', 'O'), ('▁taken', 'O', 'B'), ('▁and', 'O', 'O'), ('▁three', 'O', 'O'), ('▁way', 'O', 'O'), ('▁F', 'O', 'O'), ('ole', 'O', 'O'), ('y', 'O', 'O'), ('▁c', 'O', 'O'), ('ath', 'O', 'O'), ('eter', 'O', 'O'), ('▁was', 'O', 'O'), ('▁applied', 'O', 'B'), ('▁for', 'O', 'O'), ('▁a', 'O', 'O'), ('▁continuous', 'O', 'O'), ('▁ir', 'O', 'B'), ('rig', 'O', 'I'), ('ation', 'O', 'I'), ('.', 'O', 'I')]\n",
      "[('▁The', 'O', 'O'), ('▁?', 'O', 'O')]\n",
      "[('▁His', 'O', 'O'), ('▁birth', 'B', 'O'), ('▁histor', 'O', 'O'), ('ies', 'I', 'O'), (',', 'I', 'O'), ('▁his', 'O', 'O'), ('▁familie', 'O', 'O'), ('▁social', 'O', 'O'), ('▁history', 'O', 'O'), ('▁and', 'O', 'O'), ('▁development', 'B', 'O'), ('al', 'O', 'O'), ('▁mil', 'B', 'O'), ('est', 'O', 'O'), ('ones', 'O', 'O'), ('▁were', 'O', 'O'), ('▁un', 'B', 'O'), ('remark', 'I', 'O'), ('able', 'I', 'O'), ('.', 'I', 'O')]\n",
      "[('▁The', 'O', 'O'), ('▁mass', 'O', 'B'), ('▁was', 'O', 'O'), ('▁firm', 'O', 'O'), (',', 'I', 'O'), ('▁pain', 'O', 'O'), ('less', 'O', 'O'), (',', 'O', 'O'), ('▁and', 'O', 'O'), ('▁mobile', 'B', 'O'), ('▁with', 'O', 'O'), ('▁the', 'O', 'O'), ('▁sw', 'B', 'O'), ('allow', 'I', 'O'), ('ing', 'I', 'O'), ('▁movements', 'O', 'O'), ('.', 'O', 'O')]\n",
      "[('▁My', 'O', 'O'), ('c', 'O', 'O'), ('oph', 'O', 'O'), ('en', 'O', 'O'), ('olate', 'O', 'O'), ('▁m', 'O', 'B'), ('of', 'O', 'I'), ('et', 'O', 'I'), ('il', 'O', 'I'), ('▁', 'O', 'O'), ('2', 'O', 'O'), ('▁g', 'O', 'O'), ('/', 'O', 'O'), ('day', 'O', 'O'), ('▁was', 'O', 'O'), ('▁pres', 'B', 'O'), ('cribed', 'I', 'O'), ('▁as', 'O', 'O'), ('▁a', 'O', 'O'), ('▁maintenance', 'O', 'O'), ('▁ther', 'O', 'B'), ('apy', 'O', 'I'), ('▁of', 'O', 'O'), ('▁l', 'O', 'O'), ('up', 'I', 'O'), ('us', 'O', 'O'), ('▁ne', 'I', 'O'), ('ph', 'I', 'O'), ('rit', 'I', 'O'), ('is', 'I', 'O'), ('▁with', 'O', 'O'), ('▁hydro', 'O', 'B'), ('x', 'O', 'I'), ('ych', 'O', 'I'), ('lor', 'O', 'I'), ('o', 'O', 'I'), ('qu', 'O', 'I'), ('ine', 'O', 'I'), ('▁at', 'O', 'O'), ('▁a', 'O', 'O'), ('▁do', 'O', 'O'), ('se', 'O', 'O'), ('▁of', 'O', 'O'), ('▁', 'O', 'O'), ('4', 'O', 'O'), ('0', 'O', 'O'), ('0', 'O', 'O'), ('▁m', 'O', 'O'), ('g', 'O', 'O'), ('/', 'O', 'O'), ('day', 'O', 'O'), ('.', 'O', 'O')]\n",
      "[('▁She', 'B', 'B'), ('▁received', 'O', 'O'), ('▁a', 'O', 'O'), ('▁chem', 'B', 'O'), ('other', 'O', 'O'), ('apy', 'O', 'O'), ('▁protocol', 'O', 'B'), ('▁made', 'O', 'O'), ('▁of', 'O', 'O'), ('▁hyper', 'O', 'B'), ('alk', 'O', 'I'), ('alin', 'O', 'I'), ('isation', 'O', 'I'), (',', 'O', 'I'), ('▁al', 'O', 'B'), ('lop', 'O', 'I'), ('ur', 'O', 'I'), ('in', 'O', 'I'), ('ol', 'O', 'I'), (',', 'O', 'I'), ('▁hydro', 'O', 'B'), ('xy', 'O', 'I'), ('ure', 'O', 'I'), ('a', 'O', 'I'), ('▁and', 'O', 'O'), ('▁a', 'O', 'O'), ('▁treatment', 'O', 'B'), ('▁based', 'O', 'O'), ('▁on', 'O', 'O'), ('▁im', 'O', 'B'), ('atin', 'O', 'I'), ('ib', 'O', 'I'), ('▁at', 'O', 'O'), ('▁the', 'O', 'O'), ('▁do', 'O', 'O'), ('se', 'O', 'O'), ('▁of', 'O', 'O'), ('▁', 'O', 'O'), ('4', 'O', 'O'), ('0', 'O', 'O'), ('0', 'O', 'O'), ('m', 'O', 'O'), ('g', 'O', 'O'), ('▁per', 'O', 'B'), ('▁day', 'O', 'I'), ('.', 'O', 'I')]\n",
      "[('▁Its', 'O', 'O'), ('▁lower', 'O', 'O'), ('▁end', 'O', 'O'), ('▁pl', 'O', 'O'), ('ung', 'I', 'O'), ('es', 'I', 'O'), ('▁behind', 'O', 'O'), ('▁the', 'O', 'O'), ('▁s', 'I', 'O'), ('ternal', 'I', 'O'), ('▁man', 'I', 'O'), ('ub', 'I', 'O'), ('rium', 'I', 'O'), ('.', 'I', 'O')]\n",
      "[('▁The', 'O', 'O'), ('▁treat', 'O', 'B'), ('ments', 'O', 'I'), ('▁were', 'O', 'O'), ('▁based', 'O', 'O'), ('▁on', 'O', 'O'), ('▁o', 'O', 'O'), ('xy', 'O', 'O'), ('to', 'O', 'O'), ('cin', 'O', 'O'), (',', 'O', 'O'), ('▁tran', 'O', 'O'), ('ex', 'O', 'O'), ('am', 'O', 'O'), ('ic', 'O', 'O'), ('▁acid', 'O', 'O'), (',', 'O', 'O'), ('▁et', 'O', 'O'), ('ams', 'O', 'O'), ('yl', 'O', 'O'), ('ate', 'O', 'O'), ('▁and', 'O', 'O'), ('▁strict', 'O', 'O'), ('▁regular', 'O', 'O'), ('▁monitoring', 'O', 'B'), ('.', 'O', 'I')]\n",
      "[('▁A', 'O', 'O'), ('▁new', 'O', 'O'), ('▁gen', 'O', 'O'), ('etic', 'O', 'O'), ('▁variant', 'O', 'O'), ('▁c', 'B', 'O'), ('.', 'O', 'O'), ('6', 'I', 'O'), ('6', 'I', 'O'), ('2', 'I', 'O'), ('G', 'O', 'O'), ('\\u2009', 'I', 'O'), ('>', 'I', 'O'), ('\\u2009', 'I', 'O'), ('C', 'O', 'O'), ('▁(', 'B', 'O'), ('p', 'I', 'O'), ('.', 'I', 'O'), ('W', 'B', 'O'), ('2', 'I', 'O'), ('2', 'O', 'O'), ('1', 'O', 'O'), ('S', 'O', 'O'), (')', 'O', 'O'), ('▁in', 'O', 'O'), ('▁the', 'O', 'O'), ('▁SER', 'O', 'O'), ('P', 'O', 'O'), ('IN', 'O', 'O'), ('C', 'O', 'O'), ('1', 'O', 'O'), ('▁gene', 'O', 'B'), ('▁was', 'O', 'O'), ('▁detected', 'O', 'O'), ('▁in', 'O', 'O'), ('▁prob', 'B', 'O'), ('and', 'I', 'B'), ('▁and', 'O', 'I'), ('▁affected', 'I', 'O'), ('▁father', 'I', 'O'), ('▁but', 'O', 'B'), ('▁was', 'O', 'O'), ('▁absent', 'B', 'B'), ('▁in', 'O', 'I'), ('▁health', 'B', 'I'), ('y', 'O', 'I')]\n",
      "[('▁The', 'O', 'O'), ('▁inc', 'O', 'B'), ('ision', 'O', 'I'), ('▁performed', 'O', 'O'), ('▁was', 'O', 'O'), ('▁a', 'O', 'O'), ('▁Koch', 'O', 'O'), ('er', 'O', 'O'), ('▁cer', 'O', 'O'), ('vic', 'O', 'O'), ('ot', 'O', 'O'), ('omy', 'O', 'O'), ('.', 'O', 'O')]\n",
      "[('▁X', 'O', 'B'), ('ray', 'O', 'I'), ('▁Ch', 'O', 'O'), ('est', 'O', 'O'), ('▁was', 'O', 'O'), ('▁normal', 'B', 'O'), ('.', 'O', 'O')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'entities', 'original_text', 'original_id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels', 'predictions', 'ground_truth_labels', 'TP', 'FP', 'FN', 'precision', 'recall', 'f1'],\n",
       "    num_rows: 18\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_f1Lower30 = eval.get_examples_based_on_metric('f1', 0.1, lower=True)\n",
    "eval.format_data(data_f1Lower30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
